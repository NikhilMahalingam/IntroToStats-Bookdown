<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>4 Lecture 4: Inference for means continued | Intro to Statistics Notes</title>
  <meta name="description" content="Intro to Stats notes for Nandini Dendukuri - Nikhil Mahalingam" />
  <meta name="generator" content="bookdown 0.28 and GitBook 2.6.7" />

  <meta property="og:title" content="4 Lecture 4: Inference for means continued | Intro to Statistics Notes" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Intro to Stats notes for Nandini Dendukuri - Nikhil Mahalingam" />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="4 Lecture 4: Inference for means continued | Intro to Statistics Notes" />
  
  <meta name="twitter:description" content="Intro to Stats notes for Nandini Dendukuri - Nikhil Mahalingam" />
  




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="lecture-3-central-limit-theorem-and-inference-for-means.html"/>
<link rel="next" href="lecture-5-sample-size-calculations-to-plan-for-hypothesis-tests-of-means.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
<link href="libs/bsTable-3.3.7/bootstrapTable.min.css" rel="stylesheet" />
<script src="libs/bsTable-3.3.7/bootstrapTable.js"></script>




<link rel="stylesheet" href="Styling/ims-style.css" type="text/css" />
<link rel="stylesheet" href="Styling/bs4_style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Intro to Statistics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Schedule</a></li>
<li class="chapter" data-level="" data-path="course-details.html"><a href="course-details.html"><i class="fa fa-check"></i>Course Details</a>
<ul>
<li class="chapter" data-level="" data-path="course-details.html"><a href="course-details.html#project"><i class="fa fa-check"></i>Project</a></li>
<li class="chapter" data-level="" data-path="course-details.html"><a href="course-details.html#suggested-references"><i class="fa fa-check"></i>Suggested References</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="lecture-1.html"><a href="lecture-1.html"><i class="fa fa-check"></i><b>1</b> Lecture 1</a>
<ul>
<li class="chapter" data-level="1.1" data-path="lecture-1.html"><a href="lecture-1.html#introduction"><i class="fa fa-check"></i><b>1.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="lecture-1.html"><a href="lecture-1.html#what-is-statistics"><i class="fa fa-check"></i><b>1.1.1</b> What is Statistics?</a></li>
<li class="chapter" data-level="1.1.2" data-path="lecture-1.html"><a href="lecture-1.html#a-motivating-example"><i class="fa fa-check"></i><b>1.1.2</b> A Motivating Example</a></li>
<li class="chapter" data-level="1.1.3" data-path="lecture-1.html"><a href="lecture-1.html#what-was-the-evidence-behind-this-optimistic-headline"><i class="fa fa-check"></i><b>1.1.3</b> What was the evidence behind this optimistic headline?</a></li>
<li class="chapter" data-level="1.1.4" data-path="lecture-1.html"><a href="lecture-1.html#what-would-a-data-detective-ask"><i class="fa fa-check"></i><b>1.1.4</b> What would a data detective ask?</a></li>
<li class="chapter" data-level="1.1.5" data-path="lecture-1.html"><a href="lecture-1.html#results-reported-in-the-study"><i class="fa fa-check"></i><b>1.1.5</b> Results reported in the study</a></li>
<li class="chapter" data-level="1.1.6" data-path="lecture-1.html"><a href="lecture-1.html#evaluating-the-quality-of-the-statistical-methods"><i class="fa fa-check"></i><b>1.1.6</b> Evaluating the quality of the statistical methods</a></li>
<li class="chapter" data-level="1.1.7" data-path="lecture-1.html"><a href="lecture-1.html#what-if-the-sample-size-were-smaller"><i class="fa fa-check"></i><b>1.1.7</b> What if the sample size were smaller?</a></li>
<li class="chapter" data-level="1.1.8" data-path="lecture-1.html"><a href="lecture-1.html#what-if-the-sample-size-were-larger"><i class="fa fa-check"></i><b>1.1.8</b> What if the sample size were larger?</a></li>
<li class="chapter" data-level="1.1.9" data-path="lecture-1.html"><a href="lecture-1.html#sample-size-and-precision"><i class="fa fa-check"></i><b>1.1.9</b> Sample Size and Precision</a></li>
<li class="chapter" data-level="1.1.10" data-path="lecture-1.html"><a href="lecture-1.html#evaluating-the-quality-of-the-statistical-methods-1"><i class="fa fa-check"></i><b>1.1.10</b> Evaluating the quality of the statistical methods</a></li>
<li class="chapter" data-level="1.1.11" data-path="lecture-1.html"><a href="lecture-1.html#evaluating-the-quality-of-the-study-design"><i class="fa fa-check"></i><b>1.1.11</b> Evaluating the quality of the study design</a></li>
<li class="chapter" data-level="1.1.12" data-path="lecture-1.html"><a href="lecture-1.html#the-role-of-external-or-prior-information"><i class="fa fa-check"></i><b>1.1.12</b> The role of external (or prior) information</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="lecture-1.html"><a href="lecture-1.html#reducing-bias-in-research-studies"><i class="fa fa-check"></i><b>1.2</b> Reducing Bias in Research Studies</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="lecture-1.html"><a href="lecture-1.html#bias-vs.-precision"><i class="fa fa-check"></i><b>1.2.1</b> Bias vs. Precision</a></li>
<li class="chapter" data-level="1.2.2" data-path="lecture-1.html"><a href="lecture-1.html#common-study-designs-used-in-clinical-research"><i class="fa fa-check"></i><b>1.2.2</b> Common study designs used in clinical research</a></li>
<li class="chapter" data-level="1.2.3" data-path="lecture-1.html"><a href="lecture-1.html#randomized-controlled-trial"><i class="fa fa-check"></i><b>1.2.3</b> Randomized Controlled Trial</a></li>
<li class="chapter" data-level="1.2.4" data-path="lecture-1.html"><a href="lecture-1.html#reducing-bias-in-research-studies-1"><i class="fa fa-check"></i><b>1.2.4</b> Reducing bias in research studies</a></li>
<li class="chapter" data-level="1.2.5" data-path="lecture-1.html"><a href="lecture-1.html#a-second-motivating-example-renal-denervation"><i class="fa fa-check"></i><b>1.2.5</b> A second motivating example: Renal Denervation</a></li>
<li class="chapter" data-level="1.2.6" data-path="lecture-1.html"><a href="lecture-1.html#example-4a-results-from-a-cohort-study-of-renal-denervation"><i class="fa fa-check"></i><b>1.2.6</b> Example 4a: Results from a cohort study of renal denervation<span class="math inline">\(^*\)</span></a></li>
<li class="chapter" data-level="1.2.7" data-path="lecture-1.html"><a href="lecture-1.html#example-4b-results-compared-to-a-control-group"><i class="fa fa-check"></i><b>1.2.7</b> Example 4b: Results compared to a control group<span class="math inline">\(^*\)</span></a></li>
<li class="chapter" data-level="1.2.8" data-path="lecture-1.html"><a href="lecture-1.html#example-4c-results-from-a-randomized-controlled-trial-rct-of-renal-denervation"><i class="fa fa-check"></i><b>1.2.8</b> Example 4c: Results from a randomized controlled trial (RCT) of renal denervation<span class="math inline">\(^*\)</span></a></li>
<li class="chapter" data-level="1.2.9" data-path="lecture-1.html"><a href="lecture-1.html#example-4d-results-from-a-second-randomized-controlled-trial-of-renal-denervation"><i class="fa fa-check"></i><b>1.2.9</b> Example 4d: Results from a second randomized controlled trial of renal denervation<span class="math inline">\(^*\)</span></a></li>
<li class="chapter" data-level="1.2.10" data-path="lecture-1.html"><a href="lecture-1.html#example-4-renal-denervation-as-a-treatment-for-resistant-hypertension"><i class="fa fa-check"></i><b>1.2.10</b> Example 4: Renal Denervation as a treatment for resistant hypertension</a></li>
<li class="chapter" data-level="1.2.11" data-path="lecture-1.html"><a href="lecture-1.html#lessons-learnt-from-renal-denervation-example"><i class="fa fa-check"></i><b>1.2.11</b> Lessons learnt from renal denervation example</a></li>
<li class="chapter" data-level="1.2.12" data-path="lecture-1.html"><a href="lecture-1.html#health-technology-assessment-of-renal-denervation"><i class="fa fa-check"></i><b>1.2.12</b> Health Technology Assessment of Renal Denervation</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="lecture-1.html"><a href="lecture-1.html#random-sampling-and-randomization"><i class="fa fa-check"></i><b>1.3</b> Random sampling and Randomization</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="lecture-1.html"><a href="lecture-1.html#sample-surveys"><i class="fa fa-check"></i><b>1.3.1</b> Sample surveys</a></li>
<li class="chapter" data-level="1.3.2" data-path="lecture-1.html"><a href="lecture-1.html#simple-random-sample"><i class="fa fa-check"></i><b>1.3.2</b> Simple random sample</a></li>
<li class="chapter" data-level="1.3.3" data-path="lecture-1.html"><a href="lecture-1.html#sample-surveys-1"><i class="fa fa-check"></i><b>1.3.3</b> Sample surveys*</a></li>
<li class="chapter" data-level="1.3.4" data-path="lecture-1.html"><a href="lecture-1.html#margin-of-error"><i class="fa fa-check"></i><b>1.3.4</b> Margin of error</a></li>
<li class="chapter" data-level="1.3.5" data-path="lecture-1.html"><a href="lecture-1.html#how-to-choose-a-simple-random-sample"><i class="fa fa-check"></i><b>1.3.5</b> How to choose a simple random sample</a></li>
<li class="chapter" data-level="1.3.6" data-path="lecture-1.html"><a href="lecture-1.html#example-drawing-a-random-sample"><i class="fa fa-check"></i><b>1.3.6</b> Example: Drawing a random sample</a></li>
<li class="chapter" data-level="1.3.7" data-path="lecture-1.html"><a href="lecture-1.html#practical-concerns-when-random-sampling"><i class="fa fa-check"></i><b>1.3.7</b> Practical concerns when random sampling</a></li>
<li class="chapter" data-level="1.3.8" data-path="lecture-1.html"><a href="lecture-1.html#some-typical-biases-that-can-arise-during-a-survey"><i class="fa fa-check"></i><b>1.3.8</b> Some typical biases that can arise during a survey</a></li>
<li class="chapter" data-level="1.3.9" data-path="lecture-1.html"><a href="lecture-1.html#randomization"><i class="fa fa-check"></i><b>1.3.9</b> Randomization</a></li>
<li class="chapter" data-level="1.3.10" data-path="lecture-1.html"><a href="lecture-1.html#simple-randomization"><i class="fa fa-check"></i><b>1.3.10</b> Simple randomization</a></li>
<li class="chapter" data-level="1.3.11" data-path="lecture-1.html"><a href="lecture-1.html#relevance-of-statistical-methods-to-researchers-in-the-life-sciences"><i class="fa fa-check"></i><b>1.3.11</b> Relevance of statistical methods to researchers in the life sciences</a></li>
<li class="chapter" data-level="1.3.12" data-path="lecture-1.html"><a href="lecture-1.html#organizations-supporting-transparent-reporting-of-biomedical-research-evidence-based-decision-making"><i class="fa fa-check"></i><b>1.3.12</b> Organizations supporting transparent reporting of biomedical research &amp; evidence-based decision making</a></li>
<li class="chapter" data-level="1.3.13" data-path="lecture-1.html"><a href="lecture-1.html#biomedical-journals-are-insisting-on-appropriate-statistical-methods"><i class="fa fa-check"></i><b>1.3.13</b> Biomedical journals are insisting on appropriate statistical methods</a></li>
<li class="chapter" data-level="1.3.14" data-path="lecture-1.html"><a href="lecture-1.html#fev-example-dataset"><i class="fa fa-check"></i><b>1.3.14</b> FEV Example: Dataset</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html"><i class="fa fa-check"></i><b>2</b> Lecture 2: Types of Variables, Probability and Probability Distributions</a>
<ul>
<li class="chapter" data-level="2.1" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#types-of-variables"><i class="fa fa-check"></i><b>2.1</b> Types of variables</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#some-questions-on-types-of-variables"><i class="fa fa-check"></i><b>2.1.1</b> Some questions on types of variables</a></li>
<li class="chapter" data-level="2.1.2" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#qualitative-variables"><i class="fa fa-check"></i><b>2.1.2</b> Qualitative variables</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#probability"><i class="fa fa-check"></i><b>2.2</b> Probability</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#definitions"><i class="fa fa-check"></i><b>2.2.1</b> Definitions</a></li>
<li class="chapter" data-level="2.2.2" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#example-1-coin-tossing"><i class="fa fa-check"></i><b>2.2.2</b> Example 1: Coin Tossing</a></li>
<li class="chapter" data-level="2.2.3" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#example-2-coin-tossing-again"><i class="fa fa-check"></i><b>2.2.3</b> Example 2: Coin Tossing again</a></li>
<li class="chapter" data-level="2.2.4" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#interpretation-of-probability"><i class="fa fa-check"></i><b>2.2.4</b> Interpretation of probability</a></li>
<li class="chapter" data-level="2.2.5" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#relative-frequency-interpretation-of-probability"><i class="fa fa-check"></i><b>2.2.5</b> Relative frequency interpretation of probability</a></li>
<li class="chapter" data-level="2.2.6" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#subjective-interpretation-of-probability"><i class="fa fa-check"></i><b>2.2.6</b> Subjective interpretation of probability</a></li>
<li class="chapter" data-level="2.2.7" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#compound-events"><i class="fa fa-check"></i><b>2.2.7</b> Compound events</a></li>
<li class="chapter" data-level="2.2.8" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#some-questions-on-probability"><i class="fa fa-check"></i><b>2.2.8</b> Some questions on probability</a></li>
<li class="chapter" data-level="2.2.9" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#combining-probabilities-addition-rules"><i class="fa fa-check"></i><b>2.2.9</b> Combining probabilities: Addition rules</a></li>
<li class="chapter" data-level="2.2.10" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#combining-probabilities-multiplication-rules"><i class="fa fa-check"></i><b>2.2.10</b> Combining probabilities: Multiplication rules</a></li>
<li class="chapter" data-level="2.2.11" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#conditional-probability"><i class="fa fa-check"></i><b>2.2.11</b> Conditional probability</a></li>
<li class="chapter" data-level="2.2.12" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#probability-trees"><i class="fa fa-check"></i><b>2.2.12</b> Probability Trees</a></li>
<li class="chapter" data-level="2.2.13" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#example-3-independent-events"><i class="fa fa-check"></i><b>2.2.13</b> Example 3: Independent events</a></li>
<li class="chapter" data-level="2.2.14" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#albinism-example"><i class="fa fa-check"></i><b>2.2.14</b> Albinism example</a></li>
<li class="chapter" data-level="2.2.15" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#albinism-example-sample-space-and-probabilities"><i class="fa fa-check"></i><b>2.2.15</b> Albinism example: Sample space and probabilities</a></li>
<li class="chapter" data-level="2.2.16" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#example-4-medical-testing"><i class="fa fa-check"></i><b>2.2.16</b> Example 4: Medical testing</a></li>
<li class="chapter" data-level="2.2.17" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#medical-testing-example"><i class="fa fa-check"></i><b>2.2.17</b> Medical testing example</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#probability-distributions"><i class="fa fa-check"></i><b>2.3</b> Probability Distributions</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#population-and-sample"><i class="fa fa-check"></i><b>2.3.1</b> Population and sample<span class="math inline">\(^*\)</span></a></li>
<li class="chapter" data-level="2.3.2" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#notation"><i class="fa fa-check"></i><b>2.3.2</b> Notation</a></li>
<li class="chapter" data-level="2.3.3" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#parameters-statistics-probability-distributions"><i class="fa fa-check"></i><b>2.3.3</b> Parameters, Statistics, Probability Distributions</a></li>
<li class="chapter" data-level="2.3.4" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#binomial-distribution"><i class="fa fa-check"></i><b>2.3.4</b> Binomial Distribution</a></li>
<li class="chapter" data-level="2.3.5" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#binomial-distribution-function"><i class="fa fa-check"></i><b>2.3.5</b> Binomial Distribution Function</a></li>
<li class="chapter" data-level="2.3.6" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#albinism-example-for-a-couple-with-5-children-sample-space-and-probabilities"><i class="fa fa-check"></i><b>2.3.6</b> Albinism example for a couple with 5 children: Sample space and probabilities</a></li>
<li class="chapter" data-level="2.3.7" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#probability-distributions-in-r"><i class="fa fa-check"></i><b>2.3.7</b> Probability distributions in R</a></li>
<li class="chapter" data-level="2.3.8" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#example-binomial-distribution-in-practice"><i class="fa fa-check"></i><b>2.3.8</b> Example: Binomial distribution in practice<span class="math inline">\(^*\)</span></a></li>
<li class="chapter" data-level="2.3.9" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#mean-and-variance-of-random-variables"><i class="fa fa-check"></i><b>2.3.9</b> Mean and variance of random variables</a></li>
<li class="chapter" data-level="2.3.10" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#mean-and-variance-for-a-binomial-distribution"><i class="fa fa-check"></i><b>2.3.10</b> Mean and variance for a Binomial distribution</a></li>
<li class="chapter" data-level="2.3.11" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#probability-of-a-continuous-variable"><i class="fa fa-check"></i><b>2.3.11</b> Probability of a continuous variable</a></li>
<li class="chapter" data-level="2.3.12" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#probability-density-function-for-a-continuous-variable"><i class="fa fa-check"></i><b>2.3.12</b> Probability density function for a continuous variable</a></li>
<li class="chapter" data-level="2.3.13" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#normal-distribution"><i class="fa fa-check"></i><b>2.3.13</b> Normal Distribution</a></li>
<li class="chapter" data-level="2.3.14" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#normal-probability-density-function"><i class="fa fa-check"></i><b>2.3.14</b> Normal probability density function</a></li>
<li class="chapter" data-level="2.3.15" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#three-normal-curves-with-different-means-and-standard-deviations"><i class="fa fa-check"></i><b>2.3.15</b> Three normal curves with different means and standard deviations</a></li>
<li class="chapter" data-level="2.3.16" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#area-under-the-normal-curve"><i class="fa fa-check"></i><b>2.3.16</b> Area under the normal curve</a></li>
<li class="chapter" data-level="2.3.17" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#example-distribution-of-serum-cholesterol-values"><i class="fa fa-check"></i><b>2.3.17</b> Example: Distribution of serum cholesterol values</a></li>
<li class="chapter" data-level="2.3.18" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#area-under-the-normal-curve-1"><i class="fa fa-check"></i><b>2.3.18</b> Area under the normal curve</a></li>
<li class="chapter" data-level="2.3.19" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#mean-and-variance-of-the-normal-distribution"><i class="fa fa-check"></i><b>2.3.19</b> Mean and variance of the normal distribution</a></li>
<li class="chapter" data-level="2.3.20" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#examples-of-discrete-distributions"><i class="fa fa-check"></i><b>2.3.20</b> Examples of discrete distributions</a></li>
<li class="chapter" data-level="2.3.21" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#bernoulli-distribution"><i class="fa fa-check"></i><b>2.3.21</b> Bernoulli distribution</a></li>
<li class="chapter" data-level="2.3.22" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#binomial-distribution-1"><i class="fa fa-check"></i><b>2.3.22</b> Binomial distribution</a></li>
<li class="chapter" data-level="2.3.23" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#poisson-distribution"><i class="fa fa-check"></i><b>2.3.23</b> Poisson distribution</a></li>
<li class="chapter" data-level="2.3.24" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#example-transcriptomic-analyses"><i class="fa fa-check"></i><b>2.3.24</b> Example: Transcriptomic Analyses<span class="math inline">\(^*\)</span></a></li>
<li class="chapter" data-level="2.3.25" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#underlying-statistical-principles-of-commonly-used-packages"><i class="fa fa-check"></i><b>2.3.25</b> Underlying statistical principles of commonly used packages</a></li>
<li class="chapter" data-level="2.3.26" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#how-it-works"><i class="fa fa-check"></i><b>2.3.26</b> How it works</a></li>
<li class="chapter" data-level="2.3.27" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#what-would-be-a-suitable-probability-distribution"><i class="fa fa-check"></i><b>2.3.27</b> What would be a suitable probability distribution?</a></li>
<li class="chapter" data-level="2.3.28" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#poisson-distribution-is-limiting"><i class="fa fa-check"></i><b>2.3.28</b> Poisson Distribution is limiting</a></li>
<li class="chapter" data-level="2.3.29" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#negative-binomial-distribution"><i class="fa fa-check"></i><b>2.3.29</b> Negative Binomial Distribution</a></li>
<li class="chapter" data-level="2.3.30" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#conceptual-justification"><i class="fa fa-check"></i><b>2.3.30</b> Conceptual Justification</a></li>
<li class="chapter" data-level="2.3.31" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#additional-notes-and-practical-implications"><i class="fa fa-check"></i><b>2.3.31</b> Additional Notes and Practical Implications</a></li>
<li class="chapter" data-level="2.3.32" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#examples-of-continuous-distributions"><i class="fa fa-check"></i><b>2.3.32</b> Examples of continuous distributions</a></li>
<li class="chapter" data-level="2.3.33" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#normal-distribution-1"><i class="fa fa-check"></i><b>2.3.33</b> Normal distribution</a></li>
<li class="chapter" data-level="2.3.34" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#uniform-distribution"><i class="fa fa-check"></i><b>2.3.34</b> Uniform distribution</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html"><i class="fa fa-check"></i><b>3</b> Lecture 3: Central Limit Theorem and Inference for Means</a>
<ul>
<li class="chapter" data-level="3.1" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#mean-and-standard-deviation"><i class="fa fa-check"></i><b>3.1</b> Mean and Standard Deviation</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#descriptive-statistics-vs.-inferential-statistics"><i class="fa fa-check"></i><b>3.1.1</b> Descriptive statistics vs. Inferential Statistics</a></li>
<li class="chapter" data-level="3.1.2" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#some-commonly-encountered-shapes-of-distributions-of-a-variable"><i class="fa fa-check"></i><b>3.1.2</b> Some commonly encountered shapes of distributions of a variable</a></li>
<li class="chapter" data-level="3.1.3" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#descriptive-statistics-notation"><i class="fa fa-check"></i><b>3.1.3</b> Descriptive statistics: Notation</a></li>
<li class="chapter" data-level="3.1.4" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#histogram-of-fev"><i class="fa fa-check"></i><b>3.1.4</b> Histogram of FEV</a></li>
<li class="chapter" data-level="3.1.5" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#measures-of-central-tendency"><i class="fa fa-check"></i><b>3.1.5</b> Measures of central tendency</a></li>
<li class="chapter" data-level="3.1.6" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#summary-of-fev-variable"><i class="fa fa-check"></i><b>3.1.6</b> Summary of FEV variable</a></li>
<li class="chapter" data-level="3.1.7" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#robustness"><i class="fa fa-check"></i><b>3.1.7</b> Robustness</a></li>
<li class="chapter" data-level="3.1.8" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#mean-vs.-median"><i class="fa fa-check"></i><b>3.1.8</b> Mean vs. Median</a></li>
<li class="chapter" data-level="3.1.9" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#quantiles"><i class="fa fa-check"></i><b>3.1.9</b> Quantiles</a></li>
<li class="chapter" data-level="3.1.10" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#measures-of-spread"><i class="fa fa-check"></i><b>3.1.10</b> Measures of spread</a></li>
<li class="chapter" data-level="3.1.11" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#summary-of-fev-variable-1"><i class="fa fa-check"></i><b>3.1.11</b> Summary of FEV variable</a></li>
<li class="chapter" data-level="3.1.12" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#comparison-of-measures-of-spread"><i class="fa fa-check"></i><b>3.1.12</b> Comparison of measures of spread</a></li>
<li class="chapter" data-level="3.1.13" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#variance-and-standard-deviation"><i class="fa fa-check"></i><b>3.1.13</b> Variance and Standard Deviation</a></li>
<li class="chapter" data-level="3.1.14" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#why-n-1-rather-than-n"><i class="fa fa-check"></i><b>3.1.14</b> Why n-1 rather than n?<span class="math inline">\(^*\)</span></a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#central-limit-theorem"><i class="fa fa-check"></i><b>3.2</b> Central Limit Theorem</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#example-1-serum-cholesterol-in-children"><i class="fa fa-check"></i><b>3.2.1</b> Example 1: Serum cholesterol in children</a></li>
<li class="chapter" data-level="3.2.2" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#the-sampling-distribution-of-bar-y"><i class="fa fa-check"></i><b>3.2.2</b> The sampling distribution of <span class="math inline">\(\bar Y\)</span></a></li>
<li class="chapter" data-level="3.2.3" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#example-sampling-distribution-of-bar-y-when-n10"><i class="fa fa-check"></i><b>3.2.3</b> Example: Sampling distribution of <span class="math inline">\(\bar Y\)</span> when n=10</a></li>
<li class="chapter" data-level="3.2.4" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#example-sampling-distribution-of-bar-y-when-n30"><i class="fa fa-check"></i><b>3.2.4</b> Example: Sampling distribution of <span class="math inline">\(\bar Y\)</span> when n=30</a></li>
<li class="chapter" data-level="3.2.5" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#example-sampling-distribution-of-bar-y-when-n100"><i class="fa fa-check"></i><b>3.2.5</b> Example: Sampling distribution of <span class="math inline">\(\bar Y\)</span> when n=100</a></li>
<li class="chapter" data-level="3.2.6" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#example-sampling-distribution-of-bar-y-when-n1000"><i class="fa fa-check"></i><b>3.2.6</b> Example: Sampling distribution of <span class="math inline">\(\bar Y\)</span> when n=1000</a></li>
<li class="chapter" data-level="3.2.7" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#example-1"><i class="fa fa-check"></i><b>3.2.7</b> Example 1</a></li>
<li class="chapter" data-level="3.2.8" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#the-sampling-distribution-of-bar-y-1"><i class="fa fa-check"></i><b>3.2.8</b> The sampling distribution of <span class="math inline">\(\bar Y\)</span></a></li>
<li class="chapter" data-level="3.2.9" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#central-limit-theorem-1"><i class="fa fa-check"></i><b>3.2.9</b> Central Limit Theorem</a></li>
<li class="chapter" data-level="3.2.10" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#example-1-1"><i class="fa fa-check"></i><b>3.2.10</b> Example 1</a></li>
<li class="chapter" data-level="3.2.11" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#theory-related-to-the-sums-of-random-variables"><i class="fa fa-check"></i><b>3.2.11</b> Theory related to the sums of random variables</a></li>
<li class="chapter" data-level="3.2.12" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#some-examples-related-to-the-sums-of-independent-random-variables"><i class="fa fa-check"></i><b>3.2.12</b> Some examples related to the sums of independent random variables</a></li>
<li class="chapter" data-level="3.2.13" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#example-2-central-limit-theorem-in-action"><i class="fa fa-check"></i><b>3.2.13</b> Example 2: Central Limit Theorem in action</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#confidence-intervals-for-means"><i class="fa fa-check"></i><b>3.3</b> Confidence intervals for means</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#confidence-interval-estimation-for-a-single-mean"><i class="fa fa-check"></i><b>3.3.1</b> Confidence interval estimation for a single mean</a></li>
<li class="chapter" data-level="3.3.2" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#t-distribution"><i class="fa fa-check"></i><b>3.3.2</b> t-distribution</a></li>
<li class="chapter" data-level="3.3.3" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#example-1-serum-potassium-concentration"><i class="fa fa-check"></i><b>3.3.3</b> Example 1: Serum Potassium Concentration</a></li>
<li class="chapter" data-level="3.3.4" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#example-1-histogram-of-the-data"><i class="fa fa-check"></i><b>3.3.4</b> Example 1: Histogram of the data</a></li>
<li class="chapter" data-level="3.3.5" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#verifying-assumptions-behind-the-t-distribution-confidence-interval"><i class="fa fa-check"></i><b>3.3.5</b> Verifying assumptions behind the t-distribution confidence interval</a></li>
<li class="chapter" data-level="3.3.6" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#example-1-standard-error-and-95-confidence-interval"><i class="fa fa-check"></i><b>3.3.6</b> Example 1: Standard Error and 95% confidence interval</a></li>
<li class="chapter" data-level="3.3.7" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#interpretation-of-the-95-confidence-interval"><i class="fa fa-check"></i><b>3.3.7</b> Interpretation of the 95% confidence interval</a></li>
<li class="chapter" data-level="3.3.8" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#confidence-level"><i class="fa fa-check"></i><b>3.3.8</b> Confidence level</a></li>
<li class="chapter" data-level="3.3.9" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#example-1-distribution-of-the-data-with-intervals"><i class="fa fa-check"></i><b>3.3.9</b> Example 1: Distribution of the data (with intervals)</a></li>
<li class="chapter" data-level="3.3.10" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#interpreting-the-confidence-interval"><i class="fa fa-check"></i><b>3.3.10</b> Interpreting the confidence interval</a></li>
<li class="chapter" data-level="3.3.11" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#standard-error-vs-standard-deviation"><i class="fa fa-check"></i><b>3.3.11</b> Standard error vs Standard deviation</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#confidence-interval-for-the-difference-between-two-means"><i class="fa fa-check"></i><b>3.4</b> Confidence interval for the difference between two means</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#example-2-nck1-deficiency-and-adipogenesis"><i class="fa fa-check"></i><b>3.4.1</b> Example 2: Nck1 deficiency and adipogenesis</a></li>
<li class="chapter" data-level="3.4.2" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#confidence-interval-for-the-difference-between-means-from-two-independent-samples"><i class="fa fa-check"></i><b>3.4.2</b> Confidence interval for the difference between means from two independent samples</a></li>
<li class="chapter" data-level="3.4.3" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#variance-of-the-difference-in-means"><i class="fa fa-check"></i><b>3.4.3</b> Variance of the difference in means</a></li>
<li class="chapter" data-level="3.4.4" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#calculating-degrees-of-freedom-of-the-t-distribution-when-variances-are-not-equal"><i class="fa fa-check"></i><b>3.4.4</b> Calculating degrees of freedom of the t-distribution when variances are not equal</a></li>
<li class="chapter" data-level="3.4.5" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#example-2-nck1-deficiency-and-adipogenesis-1"><i class="fa fa-check"></i><b>3.4.5</b> Example 2: Nck1 deficiency and adipogenesis</a></li>
<li class="chapter" data-level="3.4.6" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#calculating-the-pooled-variance-for-body-weight"><i class="fa fa-check"></i><b>3.4.6</b> Calculating the pooled variance for body weight</a></li>
<li class="chapter" data-level="3.4.7" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#confidence-interval-for-difference-in-body-weight"><i class="fa fa-check"></i><b>3.4.7</b> Confidence interval for difference in body weight</a></li>
<li class="chapter" data-level="3.4.8" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#confidence-intervals-comparing-the-two-groups"><i class="fa fa-check"></i><b>3.4.8</b> Confidence intervals comparing the two groups</a></li>
<li class="chapter" data-level="3.4.9" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#interpreting-the-confidence-interval-1"><i class="fa fa-check"></i><b>3.4.9</b> Interpreting the confidence interval</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#sample-size-calculations"><i class="fa fa-check"></i><b>3.5</b> Sample size calculations</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#an-illustration"><i class="fa fa-check"></i><b>3.5.1</b> An illustration</a></li>
<li class="chapter" data-level="3.5.2" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#sample-size-calculation"><i class="fa fa-check"></i><b>3.5.2</b> Sample size calculation</a></li>
<li class="chapter" data-level="3.5.3" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#sample-size-calculation-for-reporting-a-confidence-interval"><i class="fa fa-check"></i><b>3.5.3</b> Sample size calculation for reporting a confidence interval</a></li>
<li class="chapter" data-level="3.5.4" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#example-method-for-a-single-mean"><i class="fa fa-check"></i><b>3.5.4</b> Example: Method for a single mean</a></li>
<li class="chapter" data-level="3.5.5" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#the-desired-precision-is-much-smaller-than-the-standard-deviation-of-the-variable"><i class="fa fa-check"></i><b>3.5.5</b> The desired precision is much smaller than the standard deviation of the variable</a></li>
<li class="chapter" data-level="3.5.6" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#example-method-for-a-single-mean-1"><i class="fa fa-check"></i><b>3.5.6</b> Example: Method for a single mean</a></li>
<li class="chapter" data-level="3.5.7" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#alternative-values-of-α-s-and-δ"><i class="fa fa-check"></i><b>3.5.7</b> Alternative values of α, s and δ</a></li>
<li class="chapter" data-level="3.5.8" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#example-sample-size-calculation-for-comparing-two-means"><i class="fa fa-check"></i><b>3.5.8</b> Example: Sample size calculation for comparing two means</a></li>
<li class="chapter" data-level="3.5.9" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#example-comparison-of-two-means"><i class="fa fa-check"></i><b>3.5.9</b> Example: Comparison of two means</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html"><i class="fa fa-check"></i><b>4</b> Lecture 4: Inference for means continued</a>
<ul>
<li class="chapter" data-level="4.1" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#hypothesis-testing"><i class="fa fa-check"></i><b>4.1</b> Hypothesis testing</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#example-1-nck1-and-adipogenesis-continued"><i class="fa fa-check"></i><b>4.1.1</b> Example 1: Nck1 and adipogenesis continued</a></li>
<li class="chapter" data-level="4.1.2" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#hypothesis-testing-1"><i class="fa fa-check"></i><b>4.1.2</b> Hypothesis testing</a></li>
<li class="chapter" data-level="4.1.3" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#hypothesis-testing-for-a-single-mean"><i class="fa fa-check"></i><b>4.1.3</b> Hypothesis testing for a single mean</a></li>
<li class="chapter" data-level="4.1.4" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#mobility-after-stroke-two-sided-alternative-hypothesis"><i class="fa fa-check"></i><b>4.1.4</b> Mobility after stroke: two-sided alternative hypothesis</a></li>
<li class="chapter" data-level="4.1.5" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#mobility-after-stroke-one-sided-alternative-hypothesis-i"><i class="fa fa-check"></i><b>4.1.5</b> Mobility after stroke: one-sided alternative hypothesis I</a></li>
<li class="chapter" data-level="4.1.6" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#mobility-after-stroke-one-sided-alternative-hypothesis-ii"><i class="fa fa-check"></i><b>4.1.6</b> Mobility after stroke: one-sided alternative hypothesis II</a></li>
<li class="chapter" data-level="4.1.7" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#more-generally-the-hypothesis-test-for-a-single-mean-may-be-stated-as-follows"><i class="fa fa-check"></i><b>4.1.7</b> More generally, the hypothesis test for a single mean may be stated as follows</a></li>
<li class="chapter" data-level="4.1.8" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#example-mobility-after-stroke"><i class="fa fa-check"></i><b>4.1.8</b> Example: Mobility after stroke</a></li>
<li class="chapter" data-level="4.1.9" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#defining-the-test-statistic-and-the-rejection-region"><i class="fa fa-check"></i><b>4.1.9</b> Defining the test statistic and the rejection region</a></li>
<li class="chapter" data-level="4.1.10" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#defining-the-t-test-statistic"><i class="fa fa-check"></i><b>4.1.10</b> Defining the t-test statistic</a></li>
<li class="chapter" data-level="4.1.11" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#rejection-region-for-the-t-test"><i class="fa fa-check"></i><b>4.1.11</b> Rejection region for the t-test</a></li>
<li class="chapter" data-level="4.1.12" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#comparison-to-confidence-interval"><i class="fa fa-check"></i><b>4.1.12</b> Comparison to confidence interval</a></li>
<li class="chapter" data-level="4.1.13" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#determining-the-rejection-region-using-r"><i class="fa fa-check"></i><b>4.1.13</b> Determining the rejection region using R</a></li>
<li class="chapter" data-level="4.1.14" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#type-i-and-type-ii-errors"><i class="fa fa-check"></i><b>4.1.14</b> Type I and Type II errors</a></li>
<li class="chapter" data-level="4.1.15" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#hypothesis-testing-a-summary"><i class="fa fa-check"></i><b>4.1.15</b> Hypothesis testing: A summary</a></li>
<li class="chapter" data-level="4.1.16" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#similarity-between-diagnostic-testing-and-hypothesis-testing"><i class="fa fa-check"></i><b>4.1.16</b> Similarity between diagnostic testing and hypothesis testing</a></li>
<li class="chapter" data-level="4.1.17" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#defining-the-t-test-statistic-for-a-one-sided-test"><i class="fa fa-check"></i><b>4.1.17</b> Defining the t-test statistic, for a one-sided test</a></li>
<li class="chapter" data-level="4.1.18" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#why-did-the-test-statistic-not-change-for-the-one-sided-hypothesis-test"><i class="fa fa-check"></i><b>4.1.18</b> Why did the test statistic not change for the one-sided hypothesis test?</a></li>
<li class="chapter" data-level="4.1.19" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#what-is-statistical-significance"><i class="fa fa-check"></i><b>4.1.19</b> What is statistical significance?</a></li>
<li class="chapter" data-level="4.1.20" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#what-is-a-p-value"><i class="fa fa-check"></i><b>4.1.20</b> What is a p-value?</a></li>
<li class="chapter" data-level="4.1.21" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#p-value-illustrated"><i class="fa fa-check"></i><b>4.1.21</b> p-value illustrated</a></li>
<li class="chapter" data-level="4.1.22" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#type-i-and-type-ii-errors-1"><i class="fa fa-check"></i><b>4.1.22</b> Type I and Type II errors</a></li>
<li class="chapter" data-level="4.1.23" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#t-test"><i class="fa fa-check"></i><b>4.1.23</b> t-test</a></li>
<li class="chapter" data-level="4.1.24" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#a-bit-of-history-pearson-vs.-fisher"><i class="fa fa-check"></i><b>4.1.24</b> A bit of history: Pearson vs. Fisher</a></li>
<li class="chapter" data-level="4.1.25" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#inference-for-comparing-two-means"><i class="fa fa-check"></i><b>4.1.25</b> Inference for comparing two means</a></li>
<li class="chapter" data-level="4.1.26" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#stroke-study-question-2-two-sided-alternative-hypothesis"><i class="fa fa-check"></i><b>4.1.26</b> Stroke study: Question 2, two-sided alternative hypothesis</a></li>
<li class="chapter" data-level="4.1.27" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#stroke-study-question-2-one-sided-hypothesis-i"><i class="fa fa-check"></i><b>4.1.27</b> Stroke study: Question 2, one-sided hypothesis I</a></li>
<li class="chapter" data-level="4.1.28" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#stroke-study-question-2-one-sided-hypothesis-ii"><i class="fa fa-check"></i><b>4.1.28</b> Stroke study: Question 2, one-sided hypothesis II</a></li>
<li class="chapter" data-level="4.1.29" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#example-one-sided-or-two-sided-test"><i class="fa fa-check"></i><b>4.1.29</b> Example: One-sided or two-sided test?</a></li>
<li class="chapter" data-level="4.1.30" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#difference-in-change-in-mobility-between-men-and-women"><i class="fa fa-check"></i><b>4.1.30</b> Difference in change in mobility between men and women</a></li>
<li class="chapter" data-level="4.1.31" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#comparing-change-in-mobility-between-men-and-women"><i class="fa fa-check"></i><b>4.1.31</b> Comparing change in mobility between men and women</a></li>
<li class="chapter" data-level="4.1.32" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#what-if-our-alternative-hypothesis-was-one-sided-instead"><i class="fa fa-check"></i><b>4.1.32</b> What if our alternative hypothesis was one-sided instead?</a></li>
<li class="chapter" data-level="4.1.33" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#what-if-our-alternative-hypothesis-was-one-sided-in-the-other-direction"><i class="fa fa-check"></i><b>4.1.33</b> What if our alternative hypothesis was one-sided in the other direction?</a></li>
<li class="chapter" data-level="4.1.34" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#what-if-our-null-hypothesis-was-one-sided-instead"><i class="fa fa-check"></i><b>4.1.34</b> What if our null hypothesis was one-sided instead?</a></li>
<li class="chapter" data-level="4.1.35" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#why-did-our-conclusion-change-when-we-moved-from-a-two-sided-to-a-one-sided-hypothesis"><i class="fa fa-check"></i><b>4.1.35</b> Why did our conclusion change when we moved from a two-sided to a one-sided hypothesis?</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#hypothesis-testing-vs.-confidence-interval-estimation"><i class="fa fa-check"></i><b>4.2</b> Hypothesis testing vs. confidence interval estimation</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#what-is-statistics-1"><i class="fa fa-check"></i><b>4.2.1</b> What is statistics?</a></li>
<li class="chapter" data-level="4.2.2" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#quantifying-uncertainty-vs.-decision-making"><i class="fa fa-check"></i><b>4.2.2</b> Quantifying uncertainty vs. decision making</a></li>
<li class="chapter" data-level="4.2.3" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#interpreting-confidence-intervals-vs.-hypothesis-tests"><i class="fa fa-check"></i><b>4.2.3</b> Interpreting Confidence Intervals vs. Hypothesis Tests<span class="math inline">\(^*\)</span></a></li>
<li class="chapter" data-level="4.2.4" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#notes-on-significance-tests"><i class="fa fa-check"></i><b>4.2.4</b> Notes on significance tests<span class="math inline">\(^*\)</span></a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#sample-size-calculations-for-studies-of-one-or-two-means"><i class="fa fa-check"></i><b>4.3</b> Sample size calculations for studies of one or two means</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#sample-size-for-hypothesis-tests"><i class="fa fa-check"></i><b>4.3.1</b> Sample size for hypothesis tests</a></li>
<li class="chapter" data-level="4.3.2" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#example"><i class="fa fa-check"></i><b>4.3.2</b> Example</a></li>
<li class="chapter" data-level="4.3.3" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#we-are-interested-in-detecting-a-shift-in-the-mean-of-the-distribution"><i class="fa fa-check"></i><b>4.3.3</b> We are interested in detecting a shift in the mean of the distribution</a></li>
<li class="chapter" data-level="4.3.4" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#sample-size-required-for-a-hypothesis-test-of-a-single-mean"><i class="fa fa-check"></i><b>4.3.4</b> Sample size required for a hypothesis test of a single mean</a></li>
<li class="chapter" data-level="4.3.5" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#sample-size-required-under-different-scenarios"><i class="fa fa-check"></i><b>4.3.5</b> Sample size required under different scenarios</a></li>
<li class="chapter" data-level="4.3.6" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#example-serum-cholesterol"><i class="fa fa-check"></i><b>4.3.6</b> Example: Serum cholesterol</a></li>
<li class="chapter" data-level="4.3.7" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#summary-what-do-you-need-to-calculate-the-sample-size-required"><i class="fa fa-check"></i><b>4.3.7</b> Summary: What do you need to calculate the sample size required?</a></li>
<li class="chapter" data-level="4.3.8" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#sample-size-calculation-comparing-two-means"><i class="fa fa-check"></i><b>4.3.8</b> Sample size calculation: Comparing two means</a></li>
<li class="chapter" data-level="4.3.9" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#example-2"><i class="fa fa-check"></i><b>4.3.9</b> Example</a></li>
<li class="chapter" data-level="4.3.10" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#sample-size-required-to-test-h_0mu_1mu_2"><i class="fa fa-check"></i><b>4.3.10</b> Sample size required to test <span class="math inline">\(H_0:\mu_1=\mu_2\)</span></a></li>
<li class="chapter" data-level="4.3.11" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#example-in-vivo-efficacy-of-p1.40"><i class="fa fa-check"></i><b>4.3.11</b> Example: In-vivo efficacy of P1.40</a></li>
<li class="chapter" data-level="4.3.12" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#power"><i class="fa fa-check"></i><b>4.3.12</b> Power</a></li>
<li class="chapter" data-level="4.3.13" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#calculating-the-power-in-r"><i class="fa fa-check"></i><b>4.3.13</b> Calculating the power in R</a></li>
<li class="chapter" data-level="4.3.14" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#example-power-function"><i class="fa fa-check"></i><b>4.3.14</b> Example: Power function</a></li>
<li class="chapter" data-level="4.3.15" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#what-is-the-impact-of-equal-or-unequal-group-sizes-on-the-precision"><i class="fa fa-check"></i><b>4.3.15</b> What is the impact of equal or unequal group sizes on the precision?</a></li>
<li class="chapter" data-level="4.3.16" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#an-r-package-for-sample-size-and-power-calculations"><i class="fa fa-check"></i><b>4.3.16</b> An R package for sample size and power calculations</a></li>
<li class="chapter" data-level="4.3.17" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#installing-a-package-in-r"><i class="fa fa-check"></i><b>4.3.17</b> Installing a package in R</a></li>
<li class="chapter" data-level="4.3.18" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#sample-size-for-comparing-two-means"><i class="fa fa-check"></i><b>4.3.18</b> Sample size for comparing two means</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#extra-problems"><i class="fa fa-check"></i><b>4.4</b> Extra Problems</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#section"><i class="fa fa-check"></i><b>4.4.1</b> 1.</a></li>
<li class="chapter" data-level="4.4.2" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#section-1"><i class="fa fa-check"></i><b>4.4.2</b> 2.</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="lecture-5-sample-size-calculations-to-plan-for-hypothesis-tests-of-means.html"><a href="lecture-5-sample-size-calculations-to-plan-for-hypothesis-tests-of-means.html"><i class="fa fa-check"></i><b>5</b> Lecture 5: Sample size calculations to plan for hypothesis tests of means</a>
<ul>
<li class="chapter" data-level="5.1" data-path="lecture-5-sample-size-calculations-to-plan-for-hypothesis-tests-of-means.html"><a href="lecture-5-sample-size-calculations-to-plan-for-hypothesis-tests-of-means.html#sample-size-calculation-1"><i class="fa fa-check"></i><b>5.1</b> Sample size calculation</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="lecture-5-sample-size-calculations-to-plan-for-hypothesis-tests-of-means.html"><a href="lecture-5-sample-size-calculations-to-plan-for-hypothesis-tests-of-means.html#type-i-and-type-ii-errors-2"><i class="fa fa-check"></i><b>5.1.1</b> Type I and Type II errors</a></li>
<li class="chapter" data-level="5.1.2" data-path="lecture-5-sample-size-calculations-to-plan-for-hypothesis-tests-of-means.html"><a href="lecture-5-sample-size-calculations-to-plan-for-hypothesis-tests-of-means.html#similarity-between-diagnostic-testing-and-hypothesis-testing-1"><i class="fa fa-check"></i><b>5.1.2</b> Similarity between diagnostic testing and hypothesis testing</a></li>
<li class="chapter" data-level="5.1.3" data-path="lecture-5-sample-size-calculations-to-plan-for-hypothesis-tests-of-means.html"><a href="lecture-5-sample-size-calculations-to-plan-for-hypothesis-tests-of-means.html#example-3"><i class="fa fa-check"></i><b>5.1.3</b> Example</a></li>
<li class="chapter" data-level="5.1.4" data-path="lecture-5-sample-size-calculations-to-plan-for-hypothesis-tests-of-means.html"><a href="lecture-5-sample-size-calculations-to-plan-for-hypothesis-tests-of-means.html#we-are-interested-in-detecting-a-shift-in-the-mean-of-the-distribution-1"><i class="fa fa-check"></i><b>5.1.4</b> We are interested in detecting a shift in the mean of the distribution</a></li>
<li class="chapter" data-level="5.1.5" data-path="lecture-5-sample-size-calculations-to-plan-for-hypothesis-tests-of-means.html"><a href="lecture-5-sample-size-calculations-to-plan-for-hypothesis-tests-of-means.html#sample-size-required-for-a-hypothesis-test-of-a-single-mean-1"><i class="fa fa-check"></i><b>5.1.5</b> Sample size required for a hypothesis test of a single mean</a></li>
<li class="chapter" data-level="5.1.6" data-path="lecture-5-sample-size-calculations-to-plan-for-hypothesis-tests-of-means.html"><a href="lecture-5-sample-size-calculations-to-plan-for-hypothesis-tests-of-means.html#sample-size-required-under-different-scenarios-for-a-one-sided-test"><i class="fa fa-check"></i><b>5.1.6</b> Sample size required under different scenarios for a one-sided test</a></li>
<li class="chapter" data-level="5.1.7" data-path="lecture-5-sample-size-calculations-to-plan-for-hypothesis-tests-of-means.html"><a href="lecture-5-sample-size-calculations-to-plan-for-hypothesis-tests-of-means.html#example-serum-cholesterol-1"><i class="fa fa-check"></i><b>5.1.7</b> Example: Serum cholesterol</a></li>
<li class="chapter" data-level="5.1.8" data-path="lecture-5-sample-size-calculations-to-plan-for-hypothesis-tests-of-means.html"><a href="lecture-5-sample-size-calculations-to-plan-for-hypothesis-tests-of-means.html#summary-input-needed-to-calculate-sample-size-for-single-mean"><i class="fa fa-check"></i><b>5.1.8</b> Summary: Input needed to calculate sample size for single mean</a></li>
<li class="chapter" data-level="5.1.9" data-path="lecture-5-sample-size-calculations-to-plan-for-hypothesis-tests-of-means.html"><a href="lecture-5-sample-size-calculations-to-plan-for-hypothesis-tests-of-means.html#example-planning-a-study-to-compare-means-using-a-hypothesis-test"><i class="fa fa-check"></i><b>5.1.9</b> Example: Planning a study to compare means using a hypothesis test</a></li>
<li class="chapter" data-level="5.1.10" data-path="lecture-5-sample-size-calculations-to-plan-for-hypothesis-tests-of-means.html"><a href="lecture-5-sample-size-calculations-to-plan-for-hypothesis-tests-of-means.html#sample-size-required-to-compare-means"><i class="fa fa-check"></i><b>5.1.10</b> Sample size required to compare means</a></li>
<li class="chapter" data-level="5.1.11" data-path="lecture-5-sample-size-calculations-to-plan-for-hypothesis-tests-of-means.html"><a href="lecture-5-sample-size-calculations-to-plan-for-hypothesis-tests-of-means.html#example-sample-size-required-to-compare-nck1-wt-and-ko-mice"><i class="fa fa-check"></i><b>5.1.11</b> Example: Sample size required to compare Nck1 WT and KO mice</a></li>
<li class="chapter" data-level="5.1.12" data-path="lecture-5-sample-size-calculations-to-plan-for-hypothesis-tests-of-means.html"><a href="lecture-5-sample-size-calculations-to-plan-for-hypothesis-tests-of-means.html#power-1"><i class="fa fa-check"></i><b>5.1.12</b> Power</a></li>
<li class="chapter" data-level="5.1.13" data-path="lecture-5-sample-size-calculations-to-plan-for-hypothesis-tests-of-means.html"><a href="lecture-5-sample-size-calculations-to-plan-for-hypothesis-tests-of-means.html#calculating-the-power-in-r-1"><i class="fa fa-check"></i><b>5.1.13</b> Calculating the power in R</a></li>
<li class="chapter" data-level="5.1.14" data-path="lecture-5-sample-size-calculations-to-plan-for-hypothesis-tests-of-means.html"><a href="lecture-5-sample-size-calculations-to-plan-for-hypothesis-tests-of-means.html#example-power-function-1"><i class="fa fa-check"></i><b>5.1.14</b> Example: Power function</a></li>
<li class="chapter" data-level="5.1.15" data-path="lecture-5-sample-size-calculations-to-plan-for-hypothesis-tests-of-means.html"><a href="lecture-5-sample-size-calculations-to-plan-for-hypothesis-tests-of-means.html#what-is-the-impact-of-equal-or-unequal-group-sizes-on-the-precision-1"><i class="fa fa-check"></i><b>5.1.15</b> What is the impact of equal or unequal group sizes on the precision?<span class="math inline">\(^*\)</span></a></li>
<li class="chapter" data-level="5.1.16" data-path="lecture-5-sample-size-calculations-to-plan-for-hypothesis-tests-of-means.html"><a href="lecture-5-sample-size-calculations-to-plan-for-hypothesis-tests-of-means.html#an-r-package-for-sample-size-and-power-calculations-1"><i class="fa fa-check"></i><b>5.1.16</b> An R package for sample size and power calculations</a></li>
<li class="chapter" data-level="5.1.17" data-path="lecture-5-sample-size-calculations-to-plan-for-hypothesis-tests-of-means.html"><a href="lecture-5-sample-size-calculations-to-plan-for-hypothesis-tests-of-means.html#installing-a-package-in-r-1"><i class="fa fa-check"></i><b>5.1.17</b> Installing a package in R</a></li>
<li class="chapter" data-level="5.1.18" data-path="lecture-5-sample-size-calculations-to-plan-for-hypothesis-tests-of-means.html"><a href="lecture-5-sample-size-calculations-to-plan-for-hypothesis-tests-of-means.html#sample-size-for-comparing-two-means-1"><i class="fa fa-check"></i><b>5.1.18</b> Sample size for comparing two means</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html"><i class="fa fa-check"></i><b>6</b> Lecture 6: Bayesian inference for means</a>
<ul>
<li class="chapter" data-level="6.1" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#example-beach-water-quality"><i class="fa fa-check"></i><b>6.1</b> Example: Beach Water Quality</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#descriptive-statistics"><i class="fa fa-check"></i><b>6.1.1</b> Descriptive Statistics</a></li>
<li class="chapter" data-level="6.1.2" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#frequentist-inference"><i class="fa fa-check"></i><b>6.1.2</b> Frequentist inference</a></li>
<li class="chapter" data-level="6.1.3" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#p-value"><i class="fa fa-check"></i><b>6.1.3</b> p-value</a></li>
<li class="chapter" data-level="6.1.4" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#confidence-interval"><i class="fa fa-check"></i><b>6.1.4</b> 95% confidence interval</a></li>
<li class="chapter" data-level="6.1.5" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#bayesian-analysis"><i class="fa fa-check"></i><b>6.1.5</b> Bayesian analysis</a></li>
<li class="chapter" data-level="6.1.6" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#what-is-the-true-mean-e.-coli-count-µ"><i class="fa fa-check"></i><b>6.1.6</b> What is the true mean E. coli count (µ)?</a></li>
<li class="chapter" data-level="6.1.7" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#bayesian-inductive-vs.-frequentist-deductive-thinking"><i class="fa fa-check"></i><b>6.1.7</b> Bayesian (inductive) vs. Frequentist (deductive) thinking</a></li>
<li class="chapter" data-level="6.1.8" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#principal-elements-of-a-bayesian-analysis"><i class="fa fa-check"></i><b>6.1.8</b> Principal elements of a Bayesian analysis</a></li>
<li class="chapter" data-level="6.1.9" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#the-prior-distribution"><i class="fa fa-check"></i><b>6.1.9</b> The prior distribution</a></li>
<li class="chapter" data-level="6.1.10" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#beach-water-quality-bayesian-analysis"><i class="fa fa-check"></i><b>6.1.10</b> Beach Water Quality: Bayesian analysis</a></li>
<li class="chapter" data-level="6.1.11" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#two-possible-prior-distributions"><i class="fa fa-check"></i><b>6.1.11</b> Two possible prior distributions</a></li>
<li class="chapter" data-level="6.1.12" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#illustration-of-the-two-prior-distributions"><i class="fa fa-check"></i><b>6.1.12</b> Illustration of the two prior distributions</a></li>
<li class="chapter" data-level="6.1.13" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#applying-bayes-theorem"><i class="fa fa-check"></i><b>6.1.13</b> Applying Bayes Theorem</a></li>
<li class="chapter" data-level="6.1.14" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#the-normal-posterior-distribution"><i class="fa fa-check"></i><b>6.1.14</b> The normal posterior distribution</a></li>
<li class="chapter" data-level="6.1.15" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#beach-water-quality-example-non-informative-prior"><i class="fa fa-check"></i><b>6.1.15</b> Beach Water Quality Example: Non-informative prior</a></li>
<li class="chapter" data-level="6.1.16" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#bayesian-analysis-using-r"><i class="fa fa-check"></i><b>6.1.16</b> Bayesian analysis using R</a></li>
<li class="chapter" data-level="6.1.17" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#posterior-distribution-compared-to-likelihood-and-non-informative-prior"><i class="fa fa-check"></i><b>6.1.17</b> Posterior distribution compared to likelihood and non-informative prior</a></li>
<li class="chapter" data-level="6.1.18" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#prior-and-posterior-distribution-plot-from-r"><i class="fa fa-check"></i><b>6.1.18</b> Prior and posterior distribution plot from R</a></li>
<li class="chapter" data-level="6.1.19" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#statistics-typically-reported-in-a-bayesian-analysis"><i class="fa fa-check"></i><b>6.1.19</b> Statistics typically reported in a Bayesian analysis</a></li>
<li class="chapter" data-level="6.1.20" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#interpretation-of-the-bayesian-credible-interval-cri"><i class="fa fa-check"></i><b>6.1.20</b> Interpretation of the Bayesian credible interval (CrI)</a></li>
<li class="chapter" data-level="6.1.21" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#mean-e.-coli-counts-hypothesis-testing-vs.-confidence-interval-vs.-bayesian-inference"><i class="fa fa-check"></i><b>6.1.21</b> Mean E. coli counts: Hypothesis testing vs. confidence interval vs. Bayesian inference</a></li>
<li class="chapter" data-level="6.1.22" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#beach-water-quality-informative-prior-distribution"><i class="fa fa-check"></i><b>6.1.22</b> Beach Water Quality: Informative prior distribution</a></li>
<li class="chapter" data-level="6.1.23" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#expressing-the-95-ci-from-earlier-data-as-a-normal-distribution"><i class="fa fa-check"></i><b>6.1.23</b> Expressing the 95% CI from earlier data as a normal distribution</a></li>
<li class="chapter" data-level="6.1.24" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#beach-water-quality-example-informative-prior"><i class="fa fa-check"></i><b>6.1.24</b> Beach Water Quality Example: Informative prior</a></li>
<li class="chapter" data-level="6.1.25" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#non-informative-prior"><i class="fa fa-check"></i><b>6.1.25</b> Non-informative prior</a></li>
<li class="chapter" data-level="6.1.26" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#results-with-non-informative-vs.-informative-prior"><i class="fa fa-check"></i><b>6.1.26</b> Results with non-informative vs. informative prior</a></li>
<li class="chapter" data-level="6.1.27" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#r-code-for-bayesian-analysis"><i class="fa fa-check"></i><b>6.1.27</b> R code for Bayesian analysis</a></li>
<li class="chapter" data-level="6.1.28" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#beach-water-quality-example"><i class="fa fa-check"></i><b>6.1.28</b> Beach Water Quality Example</a></li>
<li class="chapter" data-level="6.1.29" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#example-renal-denervation"><i class="fa fa-check"></i><b>6.1.29</b> Example: Renal Denervation</a></li>
<li class="chapter" data-level="6.1.30" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#re-analysis-of-renal-denervation-data-using-a-bayesian-approach"><i class="fa fa-check"></i><b>6.1.30</b> Re-analysis of Renal Denervation data using a Bayesian approach</a></li>
<li class="chapter" data-level="6.1.31" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#posterior-distributions"><i class="fa fa-check"></i><b>6.1.31</b> Posterior distributions</a></li>
<li class="chapter" data-level="6.1.32" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#posterior-distribution-of-the-difference-between-the-two-groups"><i class="fa fa-check"></i><b>6.1.32</b> Posterior distribution of the difference between the two groups</a></li>
<li class="chapter" data-level="6.1.33" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#posterior-distribution-of-the-difference-between-the-two-groups-1"><i class="fa fa-check"></i><b>6.1.33</b> Posterior distribution of the difference between the two groups</a></li>
<li class="chapter" data-level="6.1.34" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#summary-of-results-hypothesis-testing-vs.-confidence-interval-vs.-bayesian-inference"><i class="fa fa-check"></i><b>6.1.34</b> Summary of results: Hypothesis testing vs. confidence interval vs. Bayesian inference</a></li>
<li class="chapter" data-level="6.1.35" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#update-on-the-renal-denervation-story"><i class="fa fa-check"></i><b>6.1.35</b> Update on the renal denervation story</a></li>
<li class="chapter" data-level="6.1.36" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#why-is-bayesian-inference-not-used-more-widely"><i class="fa fa-check"></i><b>6.1.36</b> Why is Bayesian inference not used more widely?</a></li>
<li class="chapter" data-level="6.1.37" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#are-bayesian-methods-worth-the-effort"><i class="fa fa-check"></i><b>6.1.37</b> Are Bayesian methods worth the effort?</a></li>
<li class="chapter" data-level="6.1.38" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#are-bayesian-methods-complex"><i class="fa fa-check"></i><b>6.1.38</b> Are Bayesian methods complex?</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#risk-of-incorrect-conclusions-with-hypothesis-testing"><i class="fa fa-check"></i><b>6.2</b> Risk of incorrect conclusions with hypothesis testing</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#concerns-with-hypothesis-testing"><i class="fa fa-check"></i><b>6.2.1</b> Concerns with hypothesis testing</a></li>
<li class="chapter" data-level="6.2.2" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#optimizing-decision-making"><i class="fa fa-check"></i><b>6.2.2</b> Optimizing decision making<span class="math inline">\(^*\)</span></a></li>
<li class="chapter" data-level="6.2.3" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#concerns-with-p-values"><i class="fa fa-check"></i><b>6.2.3</b> Concerns with p-values</a></li>
<li class="chapter" data-level="6.2.4" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#factors-that-influence-the-accuracy-of-hypothesis-testing"><i class="fa fa-check"></i><b>6.2.4</b> Factors that influence the accuracy of hypothesis testing</a></li>
<li class="chapter" data-level="6.2.5" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#probabilities-of-true-and-false-reporting"><i class="fa fa-check"></i><b>6.2.5</b> Probabilities of true and false reporting<span class="math inline">\(^*\)</span></a></li>
<li class="chapter" data-level="6.2.6" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#illustration-from-nuzzo-et-al."><i class="fa fa-check"></i><b>6.2.6</b> Illustration from Nuzzo et al.</a></li>
<li class="chapter" data-level="6.2.7" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#illustration-of-true-and-false-reporting-probabilities"><i class="fa fa-check"></i><b>6.2.7</b> Illustration of true and false reporting probabilities</a></li>
<li class="chapter" data-level="6.2.8" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#pre-study-odds-of-h0h1"><i class="fa fa-check"></i><b>6.2.8</b> Pre-study odds of H0:H1</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html"><i class="fa fa-check"></i><b>7</b> Lecture 7: Statistical inference for proportions</a>
<ul>
<li class="chapter" data-level="7.1" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#when-is-a-single-proportion-used"><i class="fa fa-check"></i><b>7.1</b> When is a single proportion used?</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#central-limit-theorem-2"><i class="fa fa-check"></i><b>7.1.1</b> Central Limit Theorem</a></li>
<li class="chapter" data-level="7.1.2" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#application-of-the-central-limit-theorem-normal-approximation-to-the-binomial-distribution"><i class="fa fa-check"></i><b>7.1.2</b> Application of the Central Limit Theorem: Normal Approximation to the Binomial Distribution</a></li>
<li class="chapter" data-level="7.1.3" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#sampling-distributions-when-π0.1"><i class="fa fa-check"></i><b>7.1.3</b> Sampling distributions when π=0.1</a></li>
<li class="chapter" data-level="7.1.4" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#sampling-distributions-when-π0.5"><i class="fa fa-check"></i><b>7.1.4</b> Sampling distributions when π=0.5</a></li>
<li class="chapter" data-level="7.1.5" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#sampling-distributions-when-π0.9"><i class="fa fa-check"></i><b>7.1.5</b> Sampling distributions when π=0.9</a></li>
<li class="chapter" data-level="7.1.6" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#sampling-distribution-of-a-binomial-variable"><i class="fa fa-check"></i><b>7.1.6</b> Sampling distribution of a Binomial variable</a></li>
<li class="chapter" data-level="7.1.7" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#normal-approximation-to-the-binomial-distribution"><i class="fa fa-check"></i><b>7.1.7</b> Normal approximation to the Binomial distribution</a></li>
<li class="chapter" data-level="7.1.8" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#example-4-estimating-the-number-of-true-positives"><i class="fa fa-check"></i><b>7.1.8</b> Example 4: Estimating the number of true positives</a></li>
<li class="chapter" data-level="7.1.9" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#example-4-applying-a-continuity-correction"><i class="fa fa-check"></i><b>7.1.9</b> Example 4: Applying a continuity correction</a></li>
<li class="chapter" data-level="7.1.10" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#continuity-correction"><i class="fa fa-check"></i><b>7.1.10</b> Continuity correction</a></li>
<li class="chapter" data-level="7.1.11" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#example-4"><i class="fa fa-check"></i><b>7.1.11</b> Example</a></li>
<li class="chapter" data-level="7.1.12" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#comparison-with-the-exact-results-based-on-the-binomial-distribution"><i class="fa fa-check"></i><b>7.1.12</b> Comparison with the exact results based on the Binomial distribution</a></li>
<li class="chapter" data-level="7.1.13" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#example-asymptomatic-colonization-with-clostridium-difficile"><i class="fa fa-check"></i><b>7.1.13</b> Example: Asymptomatic colonization with Clostridium difficile</a></li>
<li class="chapter" data-level="7.1.14" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#asymptomatic-colonization-with-clostridium-difficile-selected-results"><i class="fa fa-check"></i><b>7.1.14</b> Asymptomatic colonization with Clostridium difficile: Selected results</a></li>
<li class="chapter" data-level="7.1.15" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#example-asymptomatic-colonization-with-clostridium-difficile-1"><i class="fa fa-check"></i><b>7.1.15</b> Example: Asymptomatic colonization with Clostridium difficile</a></li>
<li class="chapter" data-level="7.1.16" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#methods-for-means-vs.-proportions"><i class="fa fa-check"></i><b>7.1.16</b> Methods for means vs. proportions</a></li>
<li class="chapter" data-level="7.1.17" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#analogy-between-calculation-of-means-and-proportions"><i class="fa fa-check"></i><b>7.1.17</b> Analogy between calculation of means and proportions</a></li>
<li class="chapter" data-level="7.1.18" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#frequentist-confidence-interval-for-a-single-proportion"><i class="fa fa-check"></i><b>7.1.18</b> Frequentist confidence interval for a single proportion</a></li>
<li class="chapter" data-level="7.1.19" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#large-sample-confidence-interval-for-a-proportion"><i class="fa fa-check"></i><b>7.1.19</b> Large sample confidence interval for a proportion</a></li>
<li class="chapter" data-level="7.1.20" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#exact-confidence-interval-for-a-proportion"><i class="fa fa-check"></i><b>7.1.20</b> Exact confidence interval for a proportion</a></li>
<li class="chapter" data-level="7.1.21" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#clopper-pearson-exact-confidence-interval-for-a-proportion-biometrika-1934"><i class="fa fa-check"></i><b>7.1.21</b> Clopper-Pearson exact confidence interval for a proportion (Biometrika, 1934)</a></li>
<li class="chapter" data-level="7.1.22" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#exact-confidence-interval-for-a-proportion-1"><i class="fa fa-check"></i><b>7.1.22</b> Exact confidence interval for a proportion<span class="math inline">\(^*\)</span></a></li>
<li class="chapter" data-level="7.1.23" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#r-function-to-obtain-a-confidence-interval-for-a-small-proportion"><i class="fa fa-check"></i><b>7.1.23</b> R function to obtain a confidence interval for a small proportion</a></li>
<li class="chapter" data-level="7.1.24" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#exact-confidence-interval-for-a-proportion-2"><i class="fa fa-check"></i><b>7.1.24</b> Exact confidence interval for a proportion</a></li>
<li class="chapter" data-level="7.1.25" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#how-do-you-determine-if-your-sample-is-sufficiently-large"><i class="fa fa-check"></i><b>7.1.25</b> How do you determine if your sample is sufficiently large?</a></li>
<li class="chapter" data-level="7.1.26" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#example-zero-proportion"><i class="fa fa-check"></i><b>7.1.26</b> Example: Zero proportion</a></li>
<li class="chapter" data-level="7.1.27" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#example-binom.test"><i class="fa fa-check"></i><b>7.1.27</b> Example: binom.test()</a></li>
<li class="chapter" data-level="7.1.28" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#example-asymptomatic-colonization-with-c.-difficile"><i class="fa fa-check"></i><b>7.1.28</b> Example: Asymptomatic colonization with C. difficile</a></li>
<li class="chapter" data-level="7.1.29" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#exact-or-approximate-ci"><i class="fa fa-check"></i><b>7.1.29</b> Exact or approximate CI?</a></li>
<li class="chapter" data-level="7.1.30" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#ci-for-proportion"><i class="fa fa-check"></i><b>7.1.30</b> 95% CI for proportion</a></li>
<li class="chapter" data-level="7.1.31" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#exact-or-approximate-ci-1"><i class="fa fa-check"></i><b>7.1.31</b> Exact or approximate CI?</a></li>
<li class="chapter" data-level="7.1.32" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#exact-95-equal-tailed-confidence-interval-for-proportion-of-probiotic-use"><i class="fa fa-check"></i><b>7.1.32</b> Exact 95% equal-tailed confidence interval for proportion of probiotic use</a></li>
<li class="chapter" data-level="7.1.33" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#confidence-intervals-for-proportion-of-patients-with-risk-factor-among-patients-asymptomatically-colonized-with-c.-difficile"><i class="fa fa-check"></i><b>7.1.33</b> 95% confidence intervals for proportion of patients with risk factor among patients asymptomatically colonized with C. difficile</a></li>
<li class="chapter" data-level="7.1.34" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#statistics-used-to-compare-two-proportions-p_1-and-p_2"><i class="fa fa-check"></i><b>7.1.34</b> Statistics used to compare two proportions <span class="math inline">\(p_1\)</span> and <span class="math inline">\(p_2\)</span></a></li>
<li class="chapter" data-level="7.1.35" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#example-probiotics-for-prevention-of-cdad"><i class="fa fa-check"></i><b>7.1.35</b> Example: Probiotics for prevention of CDAD</a></li>
<li class="chapter" data-level="7.1.36" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#results-from-two-randomized-controlled-trials"><i class="fa fa-check"></i><b>7.1.36</b> Results from two randomized controlled trials</a></li>
<li class="chapter" data-level="7.1.37" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#forest-plot-of-relative-risk-from-10-studies"><i class="fa fa-check"></i><b>7.1.37</b> Forest plot of relative risk from 10 studies<span class="math inline">\(^*\)</span></a></li>
<li class="chapter" data-level="7.1.38" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#results-from-two-randomized-controlled-trials-1"><i class="fa fa-check"></i><b>7.1.38</b> Results from two randomized controlled trials</a></li>
<li class="chapter" data-level="7.1.39" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#confidence-interval-for-the-difference-between-two-proportions"><i class="fa fa-check"></i><b>7.1.39</b> Confidence Interval for the difference between two proportions</a></li>
<li class="chapter" data-level="7.1.40" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#hypothesis-test-for-comparing-two-proportions"><i class="fa fa-check"></i><b>7.1.40</b> Hypothesis test for comparing two proportions</a></li>
<li class="chapter" data-level="7.1.41" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#probiotics-example-confidence-interval-for-difference-in-proportions"><i class="fa fa-check"></i><b>7.1.41</b> Probiotics example: Confidence interval for difference in proportions</a></li>
<li class="chapter" data-level="7.1.42" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#probiotics-example-hypothesis-test"><i class="fa fa-check"></i><b>7.1.42</b> Probiotics example: Hypothesis test</a></li>
<li class="chapter" data-level="7.1.43" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#probiotics-example-results-for-both-studies"><i class="fa fa-check"></i><b>7.1.43</b> Probiotics example: Results for both studies</a></li>
<li class="chapter" data-level="7.1.44" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#comparing-two-proportions-in-r"><i class="fa fa-check"></i><b>7.1.44</b> Comparing two proportions in R</a></li>
<li class="chapter" data-level="7.1.45" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#probiotics-example-obtaining-the-results-in-r"><i class="fa fa-check"></i><b>7.1.45</b> Probiotics example: Obtaining the results in R</a></li>
<li class="chapter" data-level="7.1.46" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#number-needed-to-treat"><i class="fa fa-check"></i><b>7.1.46</b> Number needed to treat</a></li>
<li class="chapter" data-level="7.1.47" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#probiotics-example-number-needed-to-treat"><i class="fa fa-check"></i><b>7.1.47</b> Probiotics example: Number needed to treat</a></li>
<li class="chapter" data-level="7.1.48" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#confidence-interval-for-number-needed-to-treat"><i class="fa fa-check"></i><b>7.1.48</b> Confidence interval for number needed to treat</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#sample-size-determination-for-studies-of-proportions"><i class="fa fa-check"></i><b>7.2</b> Sample size determination for studies of proportions</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#sample-size-for-desired-margin-of-error"><i class="fa fa-check"></i><b>7.2.1</b> Sample Size For Desired Margin Of Error</a></li>
<li class="chapter" data-level="7.2.2" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#sample-size-for-desired-power-and-type-i-error"><i class="fa fa-check"></i><b>7.2.2</b> Sample Size For Desired Power And Type I Error</a></li>
<li class="chapter" data-level="7.2.3" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#example-5"><i class="fa fa-check"></i><b>7.2.3</b> Example</a></li>
<li class="chapter" data-level="7.2.4" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#planning-a-study-to-compare-proportions"><i class="fa fa-check"></i><b>7.2.4</b> Planning a study to compare proportions</a></li>
<li class="chapter" data-level="7.2.5" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#sample-size-formulae"><i class="fa fa-check"></i><b>7.2.5</b> Sample size formulae</a></li>
<li class="chapter" data-level="7.2.6" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#example-6"><i class="fa fa-check"></i><b>7.2.6</b> Example</a></li>
<li class="chapter" data-level="7.2.7" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#inputs-for-the-sample-size-calculation"><i class="fa fa-check"></i><b>7.2.7</b> Inputs for the sample size calculation</a></li>
<li class="chapter" data-level="7.2.8" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#example-7"><i class="fa fa-check"></i><b>7.2.8</b> Example</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html"><a href="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html"><i class="fa fa-check"></i><b>8</b> Lecture 8: Other statistics for comparing proportions and methods for contingency tables</a>
<ul>
<li class="chapter" data-level="8.1" data-path="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html"><a href="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html#odds"><i class="fa fa-check"></i><b>8.1</b> Odds</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html"><a href="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html#odds-ratio-and-relative-risk"><i class="fa fa-check"></i><b>8.1.1</b> Odds Ratio and Relative Risk</a></li>
<li class="chapter" data-level="8.1.2" data-path="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html"><a href="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html#confidence-interval-for-an-odds-ratio"><i class="fa fa-check"></i><b>8.1.2</b> Confidence interval for an odds ratio</a></li>
<li class="chapter" data-level="8.1.3" data-path="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html"><a href="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html#confidence-interval-for-the-relative-risk"><i class="fa fa-check"></i><b>8.1.3</b> Confidence interval for the relative risk</a></li>
<li class="chapter" data-level="8.1.4" data-path="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html"><a href="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html#probiotics-example-results-for-both-studies-1"><i class="fa fa-check"></i><b>8.1.4</b> Probiotics example: Results for both studies</a></li>
<li class="chapter" data-level="8.1.5" data-path="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html"><a href="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html#probiotics-and-cdad-rearranging-the-data"><i class="fa fa-check"></i><b>8.1.5</b> Probiotics and CDAD: Rearranging the data</a></li>
<li class="chapter" data-level="8.1.6" data-path="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html"><a href="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html#r-function-for-odds-ratio-and-relative-risk"><i class="fa fa-check"></i><b>8.1.6</b> R function for odds ratio and relative risk</a></li>
<li class="chapter" data-level="8.1.7" data-path="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html"><a href="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html#example-probiotics-and-cdad"><i class="fa fa-check"></i><b>8.1.7</b> Example: Probiotics and CDAD</a></li>
<li class="chapter" data-level="8.1.8" data-path="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html"><a href="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html#example-95-confidence-intervals-for-gao-et-al."><i class="fa fa-check"></i><b>8.1.8</b> Example: 95% confidence intervals for Gao et al.</a></li>
<li class="chapter" data-level="8.1.9" data-path="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html"><a href="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html#example-95-confidence-intervals-for-otitis-data"><i class="fa fa-check"></i><b>8.1.9</b> Example: 95% confidence intervals for otitis data</a></li>
<li class="chapter" data-level="8.1.10" data-path="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html"><a href="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html#example-probiotics-and-cdad-1"><i class="fa fa-check"></i><b>8.1.10</b> Example: Probiotics and CDAD</a></li>
<li class="chapter" data-level="8.1.11" data-path="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html"><a href="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html#risk-ratio-vs.-risk-difference"><i class="fa fa-check"></i><b>8.1.11</b> Risk ratio vs. risk difference</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html"><a href="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html#methods-for-contingency-tables"><i class="fa fa-check"></i><b>8.2</b> Methods for contingency tables</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html"><a href="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html#comparing-two-or-more-proportions-the-generic-setup"><i class="fa fa-check"></i><b>8.2.1</b> Comparing Two or More Proportions: The generic setup</a></li>
<li class="chapter" data-level="8.2.2" data-path="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html"><a href="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html#examples-from-two-randomized-controlled-trials"><i class="fa fa-check"></i><b>8.2.2</b> Examples from two randomized controlled trials</a></li>
<li class="chapter" data-level="8.2.3" data-path="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html"><a href="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html#r-code-to-examine-an-r-c-table"><i class="fa fa-check"></i><b>8.2.3</b> R code to examine an r × c table</a></li>
<li class="chapter" data-level="8.2.4" data-path="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html"><a href="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html#output-from-r"><i class="fa fa-check"></i><b>8.2.4</b> Output from R</a></li>
<li class="chapter" data-level="8.2.5" data-path="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html"><a href="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html#hypothesis-tests-to-compare-two-or-more-proportions"><i class="fa fa-check"></i><b>8.2.5</b> Hypothesis tests to compare two or more proportions</a></li>
<li class="chapter" data-level="8.2.6" data-path="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html"><a href="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html#methods-to-compare-two-or-more-proportions"><i class="fa fa-check"></i><b>8.2.6</b> Methods to Compare Two or More Proportions</a></li>
<li class="chapter" data-level="8.2.7" data-path="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html"><a href="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html#examples-from-two-randomized-controlled-trials-1"><i class="fa fa-check"></i><b>8.2.7</b> Examples from two randomized controlled trials</a></li>
<li class="chapter" data-level="8.2.8" data-path="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html"><a href="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html#methods-to-compare-two-or-more-proportions-1"><i class="fa fa-check"></i><b>8.2.8</b> Methods to Compare Two or More Proportions</a></li>
<li class="chapter" data-level="8.2.9" data-path="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html"><a href="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html#which-method-do-we-use"><i class="fa fa-check"></i><b>8.2.9</b> Which method do we use?</a></li>
<li class="chapter" data-level="8.2.10" data-path="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html"><a href="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html#hypothesis-test-for-comparing-two-or-more-proportions"><i class="fa fa-check"></i><b>8.2.10</b> Hypothesis test for comparing two or more proportions</a></li>
<li class="chapter" data-level="8.2.11" data-path="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html"><a href="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html#example-one-sample-chi2-test"><i class="fa fa-check"></i><b>8.2.11</b> Example: One Sample <span class="math inline">\(\chi^2\)</span> test</a></li>
<li class="chapter" data-level="8.2.12" data-path="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html"><a href="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html#calculating-the-p-value-under-a-chi-square-distribution"><i class="fa fa-check"></i><b>8.2.12</b> Calculating the p-value under a chi-square distribution</a></li>
<li class="chapter" data-level="8.2.13" data-path="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html"><a href="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html#example-two-sample-chi2-test"><i class="fa fa-check"></i><b>8.2.13</b> Example: Two sample <span class="math inline">\(\chi^2\)</span> Test</a></li>
<li class="chapter" data-level="8.2.14" data-path="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html"><a href="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html#example-chi2-test-for-the-2-x-3-table"><i class="fa fa-check"></i><b>8.2.14</b> Example: <span class="math inline">\(\chi^2\)</span> test for the 2 x 3 Table</a></li>
<li class="chapter" data-level="8.2.15" data-path="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html"><a href="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html#some-more-notes-on-the-chi-square-test"><i class="fa fa-check"></i><b>8.2.15</b> Some more notes on the chi-square test</a></li>
<li class="chapter" data-level="8.2.16" data-path="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html"><a href="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html#chi-square-test-in-r"><i class="fa fa-check"></i><b>8.2.16</b> Chi-square test in R</a></li>
<li class="chapter" data-level="8.2.17" data-path="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html"><a href="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html#chi-square-test-for-a-single-proportion"><i class="fa fa-check"></i><b>8.2.17</b> Chi-square test for a single proportion</a></li>
<li class="chapter" data-level="8.2.18" data-path="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html"><a href="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html#two-sample-chi2-test-in-r"><i class="fa fa-check"></i><b>8.2.18</b> Two sample <span class="math inline">\(\chi^2\)</span> Test in R</a></li>
<li class="chapter" data-level="8.2.19" data-path="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html"><a href="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html#three-sample-chi2-test-in-r"><i class="fa fa-check"></i><b>8.2.19</b> Three sample <span class="math inline">\(\chi^2\)</span> Test in R</a></li>
<li class="chapter" data-level="8.2.20" data-path="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html"><a href="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html#example-ecmo"><i class="fa fa-check"></i><b>8.2.20</b> Example: ECMO<span class="math inline">\(^*\)</span></a></li>
<li class="chapter" data-level="8.2.21" data-path="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html"><a href="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html#example-fishers-exact-test"><i class="fa fa-check"></i><b>8.2.21</b> Example: Fisher’s Exact Test</a></li>
<li class="chapter" data-level="8.2.22" data-path="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html"><a href="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html#fishers-exact-test"><i class="fa fa-check"></i><b>8.2.22</b> Fisher’s exact test</a></li>
<li class="chapter" data-level="8.2.23" data-path="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html"><a href="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html#example-fishers-exact-test-1"><i class="fa fa-check"></i><b>8.2.23</b> Example: Fisher’s exact test</a></li>
<li class="chapter" data-level="8.2.24" data-path="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html"><a href="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html#calculation-of-p-value-for-fishers-exact-test"><i class="fa fa-check"></i><b>8.2.24</b> Calculation of p-value for Fisher’s exact test</a></li>
<li class="chapter" data-level="8.2.25" data-path="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html"><a href="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html#fishers-exact-test-1"><i class="fa fa-check"></i><b>8.2.25</b> Fisher’s exact test</a></li>
<li class="chapter" data-level="8.2.26" data-path="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html"><a href="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html#carrying-out-fishers-exact-test-in-r---two-sided-alternative"><i class="fa fa-check"></i><b>8.2.26</b> Carrying out Fisher’s exact test in R - two-sided alternative</a></li>
<li class="chapter" data-level="8.2.27" data-path="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html"><a href="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html#carrying-out-fishers-exact-test-in-r---one--sided-alternative"><i class="fa fa-check"></i><b>8.2.27</b> Carrying out Fisher’s exact test in R - one -sided alternative</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="lecture-9-non-parametric-methods.html"><a href="lecture-9-non-parametric-methods.html"><i class="fa fa-check"></i><b>9</b> Lecture 9: Non-parametric methods</a>
<ul>
<li class="chapter" data-level="9.1" data-path="lecture-9-non-parametric-methods.html"><a href="lecture-9-non-parametric-methods.html#parametric-inference"><i class="fa fa-check"></i><b>9.1</b> Parametric Inference</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="lecture-9-non-parametric-methods.html"><a href="lecture-9-non-parametric-methods.html#examples"><i class="fa fa-check"></i><b>9.1.1</b> Examples<span class="math inline">\(^*\)</span></a></li>
<li class="chapter" data-level="9.1.2" data-path="lecture-9-non-parametric-methods.html"><a href="lecture-9-non-parametric-methods.html#non-parametric-inference"><i class="fa fa-check"></i><b>9.1.2</b> Non-Parametric Inference</a></li>
<li class="chapter" data-level="9.1.3" data-path="lecture-9-non-parametric-methods.html"><a href="lecture-9-non-parametric-methods.html#hypothesis-testing-procedure"><i class="fa fa-check"></i><b>9.1.3</b> Hypothesis testing procedure</a></li>
<li class="chapter" data-level="9.1.4" data-path="lecture-9-non-parametric-methods.html"><a href="lecture-9-non-parametric-methods.html#example-comparison-of-two-matched-samples"><i class="fa fa-check"></i><b>9.1.4</b> Example: Comparison of Two Matched Samples</a></li>
<li class="chapter" data-level="9.1.5" data-path="lecture-9-non-parametric-methods.html"><a href="lecture-9-non-parametric-methods.html#example-8"><i class="fa fa-check"></i><b>9.1.5</b> Example</a></li>
<li class="chapter" data-level="9.1.6" data-path="lecture-9-non-parametric-methods.html"><a href="lecture-9-non-parametric-methods.html#comparison-of-two-matched-samples-the-sign-test"><i class="fa fa-check"></i><b>9.1.6</b> Comparison of Two Matched Samples: The Sign Test</a></li>
<li class="chapter" data-level="9.1.7" data-path="lecture-9-non-parametric-methods.html"><a href="lecture-9-non-parametric-methods.html#the-sign-test-the-test-statistic"><i class="fa fa-check"></i><b>9.1.7</b> The Sign Test: The test statistic</a></li>
<li class="chapter" data-level="9.1.8" data-path="lecture-9-non-parametric-methods.html"><a href="lecture-9-non-parametric-methods.html#the-sign-test-calculating-the-p-value"><i class="fa fa-check"></i><b>9.1.8</b> The Sign Test: Calculating the p-value</a></li>
<li class="chapter" data-level="9.1.9" data-path="lecture-9-non-parametric-methods.html"><a href="lecture-9-non-parametric-methods.html#example-9"><i class="fa fa-check"></i><b>9.1.9</b> Example</a></li>
<li class="chapter" data-level="9.1.10" data-path="lecture-9-non-parametric-methods.html"><a href="lecture-9-non-parametric-methods.html#carrying-out-the-sign-test-in-r"><i class="fa fa-check"></i><b>9.1.10</b> Carrying out the Sign Test in R</a></li>
<li class="chapter" data-level="9.1.11" data-path="lecture-9-non-parametric-methods.html"><a href="lecture-9-non-parametric-methods.html#are-non-parameteric-methods-really-distribution-free"><i class="fa fa-check"></i><b>9.1.11</b> Are non-parameteric methods really “distribution free”?</a></li>
<li class="chapter" data-level="9.1.12" data-path="lecture-9-non-parametric-methods.html"><a href="lecture-9-non-parametric-methods.html#comparison-of-two-matched-samples-the-wilcoxon-signed-rank-test"><i class="fa fa-check"></i><b>9.1.12</b> Comparison of Two Matched Samples: The Wilcoxon Signed Rank Test</a></li>
<li class="chapter" data-level="9.1.13" data-path="lecture-9-non-parametric-methods.html"><a href="lecture-9-non-parametric-methods.html#example-wilcoxon-signed-rank-test"><i class="fa fa-check"></i><b>9.1.13</b> Example: Wilcoxon Signed Rank Test</a></li>
<li class="chapter" data-level="9.1.14" data-path="lecture-9-non-parametric-methods.html"><a href="lecture-9-non-parametric-methods.html#wilcoxon-signed-rank-test-in-r"><i class="fa fa-check"></i><b>9.1.14</b> Wilcoxon Signed Rank Test in R</a></li>
<li class="chapter" data-level="9.1.15" data-path="lecture-9-non-parametric-methods.html"><a href="lecture-9-non-parametric-methods.html#normal-approximation-to-the-sign-and-wilcoxon-signed-rank-tests"><i class="fa fa-check"></i><b>9.1.15</b> Normal approximation to the Sign and Wilcoxon Signed Rank Tests</a></li>
<li class="chapter" data-level="9.1.16" data-path="lecture-9-non-parametric-methods.html"><a href="lecture-9-non-parametric-methods.html#normal-approximation-to-the-wilcoxon-signed-rank-test"><i class="fa fa-check"></i><b>9.1.16</b> Normal approximation to the Wilcoxon Signed Rank Test</a></li>
<li class="chapter" data-level="9.1.17" data-path="lecture-9-non-parametric-methods.html"><a href="lecture-9-non-parametric-methods.html#comparison-of-two-unmatched-samples"><i class="fa fa-check"></i><b>9.1.17</b> Comparison of two unmatched samples</a></li>
<li class="chapter" data-level="9.1.18" data-path="lecture-9-non-parametric-methods.html"><a href="lecture-9-non-parametric-methods.html#wilcoxon-rank-sum-test"><i class="fa fa-check"></i><b>9.1.18</b> Wilcoxon Rank Sum Test</a></li>
<li class="chapter" data-level="9.1.19" data-path="lecture-9-non-parametric-methods.html"><a href="lecture-9-non-parametric-methods.html#wilcoxon-rank-sum-test-calculation-of-the-test-statistic"><i class="fa fa-check"></i><b>9.1.19</b> Wilcoxon Rank Sum Test: Calculation of the test statistic</a></li>
<li class="chapter" data-level="9.1.20" data-path="lecture-9-non-parametric-methods.html"><a href="lecture-9-non-parametric-methods.html#exact-wilcoxon-rank-sum-test"><i class="fa fa-check"></i><b>9.1.20</b> Exact Wilcoxon Rank Sum Test</a></li>
<li class="chapter" data-level="9.1.21" data-path="lecture-9-non-parametric-methods.html"><a href="lecture-9-non-parametric-methods.html#example-wilcoxon-rank-sum-test"><i class="fa fa-check"></i><b>9.1.21</b> Example: Wilcoxon Rank Sum Test</a></li>
<li class="chapter" data-level="9.1.22" data-path="lecture-9-non-parametric-methods.html"><a href="lecture-9-non-parametric-methods.html#approximate-wilcoxon-rank-sum-test"><i class="fa fa-check"></i><b>9.1.22</b> Approximate Wilcoxon Rank Sum Test</a></li>
<li class="chapter" data-level="9.1.23" data-path="lecture-9-non-parametric-methods.html"><a href="lecture-9-non-parametric-methods.html#wilcoxon-rank-sum-test-in-r"><i class="fa fa-check"></i><b>9.1.23</b> Wilcoxon Rank Sum Test in R</a></li>
<li class="chapter" data-level="9.1.24" data-path="lecture-9-non-parametric-methods.html"><a href="lecture-9-non-parametric-methods.html#summary-of-hypothesis-tests-covered-in-this-course"><i class="fa fa-check"></i><b>9.1.24</b> Summary of hypothesis tests covered in this course</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="lecture-9-non-parametric-methods.html"><a href="lecture-9-non-parametric-methods.html#bootstrap-confidence-interval"><i class="fa fa-check"></i><b>9.2</b> Bootstrap confidence interval</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="lecture-9-non-parametric-methods.html"><a href="lecture-9-non-parametric-methods.html#confidence-intervals-vs.-hypothesis-testing"><i class="fa fa-check"></i><b>9.2.1</b> Confidence intervals vs. Hypothesis Testing</a></li>
<li class="chapter" data-level="9.2.2" data-path="lecture-9-non-parametric-methods.html"><a href="lecture-9-non-parametric-methods.html#bootstrap-confidence-intervals"><i class="fa fa-check"></i><b>9.2.2</b> Bootstrap confidence intervals</a></li>
<li class="chapter" data-level="9.2.3" data-path="lecture-9-non-parametric-methods.html"><a href="lecture-9-non-parametric-methods.html#bootstrap-example"><i class="fa fa-check"></i><b>9.2.3</b> Bootstrap: Example<span class="math inline">\(^*\)</span></a></li>
<li class="chapter" data-level="9.2.4" data-path="lecture-9-non-parametric-methods.html"><a href="lecture-9-non-parametric-methods.html#the-empirical-bootstrap"><i class="fa fa-check"></i><b>9.2.4</b> The empirical bootstrap</a></li>
<li class="chapter" data-level="9.2.5" data-path="lecture-9-non-parametric-methods.html"><a href="lecture-9-non-parametric-methods.html#example-10"><i class="fa fa-check"></i><b>9.2.5</b> Example</a></li>
<li class="chapter" data-level="9.2.6" data-path="lecture-9-non-parametric-methods.html"><a href="lecture-9-non-parametric-methods.html#r-code-for-bootstrap"><i class="fa fa-check"></i><b>9.2.6</b> R code for bootstrap</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="lecture-10-analysis-of-variance-anova.html"><a href="lecture-10-analysis-of-variance-anova.html"><i class="fa fa-check"></i><b>10</b> Lecture 10: Analysis of Variance (ANOVA)</a>
<ul>
<li class="chapter" data-level="10.1" data-path="lecture-10-analysis-of-variance-anova.html"><a href="lecture-10-analysis-of-variance-anova.html#introduction-1"><i class="fa fa-check"></i><b>10.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="10.1.1" data-path="lecture-10-analysis-of-variance-anova.html"><a href="lecture-10-analysis-of-variance-anova.html#example-mao-and-schizophrenia"><i class="fa fa-check"></i><b>10.1.1</b> Example: MAO and Schizophrenia</a></li>
<li class="chapter" data-level="10.1.2" data-path="lecture-10-analysis-of-variance-anova.html"><a href="lecture-10-analysis-of-variance-anova.html#why-not-answer-these-questions-with-repeated-t-tests"><i class="fa fa-check"></i><b>10.1.2</b> Why not answer these questions with repeated t-tests?</a></li>
<li class="chapter" data-level="10.1.3" data-path="lecture-10-analysis-of-variance-anova.html"><a href="lecture-10-analysis-of-variance-anova.html#graphical-perspective-on-anova"><i class="fa fa-check"></i><b>10.1.3</b> Graphical perspective on ANOVA</a></li>
<li class="chapter" data-level="10.1.4" data-path="lecture-10-analysis-of-variance-anova.html"><a href="lecture-10-analysis-of-variance-anova.html#one-way-anova"><i class="fa fa-check"></i><b>10.1.4</b> One-way ANOVA</a></li>
<li class="chapter" data-level="10.1.5" data-path="lecture-10-analysis-of-variance-anova.html"><a href="lecture-10-analysis-of-variance-anova.html#one-way-anova-assumptions"><i class="fa fa-check"></i><b>10.1.5</b> One-way ANOVA: Assumptions</a></li>
<li class="chapter" data-level="10.1.6" data-path="lecture-10-analysis-of-variance-anova.html"><a href="lecture-10-analysis-of-variance-anova.html#one-way-anova-notation"><i class="fa fa-check"></i><b>10.1.6</b> One-way ANOVA: Notation</a></li>
<li class="chapter" data-level="10.1.7" data-path="lecture-10-analysis-of-variance-anova.html"><a href="lecture-10-analysis-of-variance-anova.html#one-way-anova-mao-and-schizophrenia"><i class="fa fa-check"></i><b>10.1.7</b> One-way ANOVA: MAO and Schizophrenia</a></li>
<li class="chapter" data-level="10.1.8" data-path="lecture-10-analysis-of-variance-anova.html"><a href="lecture-10-analysis-of-variance-anova.html#anova-within-group-variation"><i class="fa fa-check"></i><b>10.1.8</b> ANOVA: Within-group variation</a></li>
<li class="chapter" data-level="10.1.9" data-path="lecture-10-analysis-of-variance-anova.html"><a href="lecture-10-analysis-of-variance-anova.html#mao-within-group-variation"><i class="fa fa-check"></i><b>10.1.9</b> MAO: Within-group variation</a></li>
<li class="chapter" data-level="10.1.10" data-path="lecture-10-analysis-of-variance-anova.html"><a href="lecture-10-analysis-of-variance-anova.html#anova-between-group-variation"><i class="fa fa-check"></i><b>10.1.10</b> ANOVA: Between-group variation</a></li>
<li class="chapter" data-level="10.1.11" data-path="lecture-10-analysis-of-variance-anova.html"><a href="lecture-10-analysis-of-variance-anova.html#mao-between-group-variation"><i class="fa fa-check"></i><b>10.1.11</b> MAO: Between-group variation</a></li>
<li class="chapter" data-level="10.1.12" data-path="lecture-10-analysis-of-variance-anova.html"><a href="lecture-10-analysis-of-variance-anova.html#a-fundamental-relationship-of-anova"><i class="fa fa-check"></i><b>10.1.12</b> A fundamental relationship of ANOVA</a></li>
<li class="chapter" data-level="10.1.13" data-path="lecture-10-analysis-of-variance-anova.html"><a href="lecture-10-analysis-of-variance-anova.html#anova-table"><i class="fa fa-check"></i><b>10.1.13</b> ANOVA table</a></li>
<li class="chapter" data-level="10.1.14" data-path="lecture-10-analysis-of-variance-anova.html"><a href="lecture-10-analysis-of-variance-anova.html#mao-example-anova-table"><i class="fa fa-check"></i><b>10.1.14</b> MAO Example: ANOVA table</a></li>
<li class="chapter" data-level="10.1.15" data-path="lecture-10-analysis-of-variance-anova.html"><a href="lecture-10-analysis-of-variance-anova.html#the-f-test"><i class="fa fa-check"></i><b>10.1.15</b> The F-test</a></li>
<li class="chapter" data-level="10.1.16" data-path="lecture-10-analysis-of-variance-anova.html"><a href="lecture-10-analysis-of-variance-anova.html#mao-example-the-f-test"><i class="fa fa-check"></i><b>10.1.16</b> MAO example: The F-test</a></li>
<li class="chapter" data-level="10.1.17" data-path="lecture-10-analysis-of-variance-anova.html"><a href="lecture-10-analysis-of-variance-anova.html#the-f-distribution"><i class="fa fa-check"></i><b>10.1.17</b> The F-distribution</a></li>
<li class="chapter" data-level="10.1.18" data-path="lecture-10-analysis-of-variance-anova.html"><a href="lecture-10-analysis-of-variance-anova.html#rejection-region"><i class="fa fa-check"></i><b>10.1.18</b> Rejection region</a></li>
<li class="chapter" data-level="10.1.19" data-path="lecture-10-analysis-of-variance-anova.html"><a href="lecture-10-analysis-of-variance-anova.html#mao-example-conclusion"><i class="fa fa-check"></i><b>10.1.19</b> MAO example: Conclusion</a></li>
<li class="chapter" data-level="10.1.20" data-path="lecture-10-analysis-of-variance-anova.html"><a href="lecture-10-analysis-of-variance-anova.html#anova-in-r"><i class="fa fa-check"></i><b>10.1.20</b> ANOVA in R</a></li>
<li class="chapter" data-level="10.1.21" data-path="lecture-10-analysis-of-variance-anova.html"><a href="lecture-10-analysis-of-variance-anova.html#checking-the-assumptions-of-anova"><i class="fa fa-check"></i><b>10.1.21</b> Checking the assumptions of ANOVA</a></li>
<li class="chapter" data-level="10.1.22" data-path="lecture-10-analysis-of-variance-anova.html"><a href="lecture-10-analysis-of-variance-anova.html#residuals-for-mao-example"><i class="fa fa-check"></i><b>10.1.22</b> Residuals for MAO example</a></li>
<li class="chapter" data-level="10.1.23" data-path="lecture-10-analysis-of-variance-anova.html"><a href="lecture-10-analysis-of-variance-anova.html#quantile-quantile-plot-to-check-for-normality"><i class="fa fa-check"></i><b>10.1.23</b> Quantile-quantile plot to check for normality</a></li>
<li class="chapter" data-level="10.1.24" data-path="lecture-10-analysis-of-variance-anova.html"><a href="lecture-10-analysis-of-variance-anova.html#quantile-quantile-qq-plot-for-mao-data"><i class="fa fa-check"></i><b>10.1.24</b> Quantile-quantile (QQ) plot for MAO data</a></li>
<li class="chapter" data-level="10.1.25" data-path="lecture-10-analysis-of-variance-anova.html"><a href="lecture-10-analysis-of-variance-anova.html#residual-plot-to-evaluate-constant-variance-across-groups"><i class="fa fa-check"></i><b>10.1.25</b> Residual plot to evaluate constant variance across groups</a></li>
<li class="chapter" data-level="10.1.26" data-path="lecture-10-analysis-of-variance-anova.html"><a href="lecture-10-analysis-of-variance-anova.html#residuals-for-mao-example-1"><i class="fa fa-check"></i><b>10.1.26</b> Residuals for MAO example</a></li>
<li class="chapter" data-level="10.1.27" data-path="lecture-10-analysis-of-variance-anova.html"><a href="lecture-10-analysis-of-variance-anova.html#multiple-comparisons"><i class="fa fa-check"></i><b>10.1.27</b> Multiple comparisons</a></li>
<li class="chapter" data-level="10.1.28" data-path="lecture-10-analysis-of-variance-anova.html"><a href="lecture-10-analysis-of-variance-anova.html#multiple-comparisons-solutions"><i class="fa fa-check"></i><b>10.1.28</b> Multiple comparisons: Solutions</a></li>
<li class="chapter" data-level="10.1.29" data-path="lecture-10-analysis-of-variance-anova.html"><a href="lecture-10-analysis-of-variance-anova.html#bonferroni-correction"><i class="fa fa-check"></i><b>10.1.29</b> Bonferroni correction</a></li>
<li class="chapter" data-level="10.1.30" data-path="lecture-10-analysis-of-variance-anova.html"><a href="lecture-10-analysis-of-variance-anova.html#bonferroni-correction-for-the-mao-example"><i class="fa fa-check"></i><b>10.1.30</b> Bonferroni correction for the MAO example</a></li>
<li class="chapter" data-level="10.1.31" data-path="lecture-10-analysis-of-variance-anova.html"><a href="lecture-10-analysis-of-variance-anova.html#bonferroni-correction-1"><i class="fa fa-check"></i><b>10.1.31</b> Bonferroni correction</a></li>
<li class="chapter" data-level="10.1.32" data-path="lecture-10-analysis-of-variance-anova.html"><a href="lecture-10-analysis-of-variance-anova.html#tukeys-confidence-interval"><i class="fa fa-check"></i><b>10.1.32</b> Tukey’s confidence interval</a></li>
<li class="chapter" data-level="10.1.33" data-path="lecture-10-analysis-of-variance-anova.html"><a href="lecture-10-analysis-of-variance-anova.html#results-for-the-mao-data"><i class="fa fa-check"></i><b>10.1.33</b> Results for the MAO data</a></li>
<li class="chapter" data-level="10.1.34" data-path="lecture-10-analysis-of-variance-anova.html"><a href="lecture-10-analysis-of-variance-anova.html#multiple-comparisons-the-debate"><i class="fa fa-check"></i><b>10.1.34</b> Multiple comparisons: The debate</a></li>
<li class="chapter" data-level="10.1.35" data-path="lecture-10-analysis-of-variance-anova.html"><a href="lecture-10-analysis-of-variance-anova.html#steps-involved-in-anova"><i class="fa fa-check"></i><b>10.1.35</b> Steps involved in ANOVA</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="lecture-11-analysis-of-variance-anova-2.html"><a href="lecture-11-analysis-of-variance-anova-2.html"><i class="fa fa-check"></i><b>11</b> Lecture 11: Analysis of Variance (ANOVA) 2</a>
<ul>
<li class="chapter" data-level="11.1" data-path="lecture-11-analysis-of-variance-anova-2.html"><a href="lecture-11-analysis-of-variance-anova-2.html#way-anova-model"><i class="fa fa-check"></i><b>11.1</b> 1-way ANOVA model</a>
<ul>
<li class="chapter" data-level="11.1.1" data-path="lecture-11-analysis-of-variance-anova-2.html"><a href="lecture-11-analysis-of-variance-anova-2.html#extending-the-1-way-anova-model"><i class="fa fa-check"></i><b>11.1.1</b> Extending the 1-way ANOVA model</a></li>
<li class="chapter" data-level="11.1.2" data-path="lecture-11-analysis-of-variance-anova-2.html"><a href="lecture-11-analysis-of-variance-anova-2.html#study-designs-handled-with-2-way-anova-models"><i class="fa fa-check"></i><b>11.1.2</b> Study designs handled with 2-way ANOVA models</a></li>
<li class="chapter" data-level="11.1.3" data-path="lecture-11-analysis-of-variance-anova-2.html"><a href="lecture-11-analysis-of-variance-anova-2.html#example-repeated-measures-design"><i class="fa fa-check"></i><b>11.1.3</b> Example: Repeated Measures Design</a></li>
<li class="chapter" data-level="11.1.4" data-path="lecture-11-analysis-of-variance-anova-2.html"><a href="lecture-11-analysis-of-variance-anova-2.html#number-of-study-units-from-3rs-website-of-michael-festing"><i class="fa fa-check"></i><b>11.1.4</b> Number of study units (from 3rs website of Michael Festing<span class="math inline">\(^*\)</span>)</a></li>
<li class="chapter" data-level="11.1.5" data-path="lecture-11-analysis-of-variance-anova-2.html"><a href="lecture-11-analysis-of-variance-anova-2.html#example-repeated-measures-design-1"><i class="fa fa-check"></i><b>11.1.5</b> Example: Repeated Measures Design</a></li>
<li class="chapter" data-level="11.1.6" data-path="lecture-11-analysis-of-variance-anova-2.html"><a href="lecture-11-analysis-of-variance-anova-2.html#example-2-way-anova-model"><i class="fa fa-check"></i><b>11.1.6</b> Example: 2-way ANOVA model</a></li>
<li class="chapter" data-level="11.1.7" data-path="lecture-11-analysis-of-variance-anova-2.html"><a href="lecture-11-analysis-of-variance-anova-2.html#example-visualizing-the-patient-effects"><i class="fa fa-check"></i><b>11.1.7</b> Example: Visualizing the patient-effects</a></li>
<li class="chapter" data-level="11.1.8" data-path="lecture-11-analysis-of-variance-anova-2.html"><a href="lecture-11-analysis-of-variance-anova-2.html#example-1-way-anova-model"><i class="fa fa-check"></i><b>11.1.8</b> Example: 1-way ANOVA model</a></li>
<li class="chapter" data-level="11.1.9" data-path="lecture-11-analysis-of-variance-anova-2.html"><a href="lecture-11-analysis-of-variance-anova-2.html#example-2-way-anova-model-1"><i class="fa fa-check"></i><b>11.1.9</b> Example: 2-way ANOVA model</a></li>
<li class="chapter" data-level="11.1.10" data-path="lecture-11-analysis-of-variance-anova-2.html"><a href="lecture-11-analysis-of-variance-anova-2.html#way-anova-in-r"><i class="fa fa-check"></i><b>11.1.10</b> 2-way ANOVA in R</a></li>
<li class="chapter" data-level="11.1.11" data-path="lecture-11-analysis-of-variance-anova-2.html"><a href="lecture-11-analysis-of-variance-anova-2.html#example-factorial-design"><i class="fa fa-check"></i><b>11.1.11</b> Example: Factorial Design<span class="math inline">\(^*\)</span></a></li>
<li class="chapter" data-level="11.1.12" data-path="lecture-11-analysis-of-variance-anova-2.html"><a href="lecture-11-analysis-of-variance-anova-2.html#example-2-way-anova-model-2"><i class="fa fa-check"></i><b>11.1.12</b> Example: 2-way ANOVA model</a></li>
<li class="chapter" data-level="11.1.13" data-path="lecture-11-analysis-of-variance-anova-2.html"><a href="lecture-11-analysis-of-variance-anova-2.html#example-2-way-anova-table"><i class="fa fa-check"></i><b>11.1.13</b> Example: 2-way ANOVA table</a></li>
<li class="chapter" data-level="11.1.14" data-path="lecture-11-analysis-of-variance-anova-2.html"><a href="lecture-11-analysis-of-variance-anova-2.html#example-2-way-anova-table-in-r"><i class="fa fa-check"></i><b>11.1.14</b> Example: 2-way ANOVA table in R</a></li>
<li class="chapter" data-level="11.1.15" data-path="lecture-11-analysis-of-variance-anova-2.html"><a href="lecture-11-analysis-of-variance-anova-2.html#example-pairwise-comparisons"><i class="fa fa-check"></i><b>11.1.15</b> Example: Pairwise comparisons</a></li>
<li class="chapter" data-level="11.1.16" data-path="lecture-11-analysis-of-variance-anova-2.html"><a href="lecture-11-analysis-of-variance-anova-2.html#assumptions-behind-2-way-anova"><i class="fa fa-check"></i><b>11.1.16</b> Assumptions behind 2-way ANOVA</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="lecture-11-analysis-of-variance-anova-2.html"><a href="lecture-11-analysis-of-variance-anova-2.html#correlation"><i class="fa fa-check"></i><b>11.2</b> Correlation</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="lecture-11-analysis-of-variance-anova-2.html"><a href="lecture-11-analysis-of-variance-anova-2.html#association-between-age-bp"><i class="fa fa-check"></i><b>11.2.1</b> Association between age &amp; BP</a></li>
<li class="chapter" data-level="11.2.2" data-path="lecture-11-analysis-of-variance-anova-2.html"><a href="lecture-11-analysis-of-variance-anova-2.html#the-correlation-coefficient"><i class="fa fa-check"></i><b>11.2.2</b> The correlation coefficient</a></li>
<li class="chapter" data-level="11.2.3" data-path="lecture-11-analysis-of-variance-anova-2.html"><a href="lecture-11-analysis-of-variance-anova-2.html#pearsons-correlation-coefficient"><i class="fa fa-check"></i><b>11.2.3</b> Pearson’s correlation coefficient</a></li>
<li class="chapter" data-level="11.2.4" data-path="lecture-11-analysis-of-variance-anova-2.html"><a href="lecture-11-analysis-of-variance-anova-2.html#properties-of-rho"><i class="fa fa-check"></i><b>11.2.4</b> Properties of <span class="math inline">\(\rho\)</span></a></li>
<li class="chapter" data-level="11.2.5" data-path="lecture-11-analysis-of-variance-anova-2.html"><a href="lecture-11-analysis-of-variance-anova-2.html#scatterplots-of-data-with-a-variety-of-sample-correlation-values"><i class="fa fa-check"></i><b>11.2.5</b> Scatterplots of data with a variety of sample correlation values</a></li>
<li class="chapter" data-level="11.2.6" data-path="lecture-11-analysis-of-variance-anova-2.html"><a href="lecture-11-analysis-of-variance-anova-2.html#example-length-and-weight-of-snakes"><i class="fa fa-check"></i><b>11.2.6</b> Example: Length and weight of snakes</a></li>
<li class="chapter" data-level="11.2.7" data-path="lecture-11-analysis-of-variance-anova-2.html"><a href="lecture-11-analysis-of-variance-anova-2.html#scatterplot-of-weight-vs.-length-of-snakes"><i class="fa fa-check"></i><b>11.2.7</b> Scatterplot of weight vs. length of snakes</a></li>
<li class="chapter" data-level="11.2.8" data-path="lecture-11-analysis-of-variance-anova-2.html"><a href="lecture-11-analysis-of-variance-anova-2.html#how-strong-is-the-linear-relationship-between-snake-length-and-weight"><i class="fa fa-check"></i><b>11.2.8</b> How strong is the linear relationship between snake length and weight?</a></li>
<li class="chapter" data-level="11.2.9" data-path="lecture-11-analysis-of-variance-anova-2.html"><a href="lecture-11-analysis-of-variance-anova-2.html#scatterplot-of-standardized-values-of-weight-vs.-length-of-snakes"><i class="fa fa-check"></i><b>11.2.9</b> Scatterplot of standardized values of weight vs. length of snakes</a></li>
<li class="chapter" data-level="11.2.10" data-path="lecture-11-analysis-of-variance-anova-2.html"><a href="lecture-11-analysis-of-variance-anova-2.html#example-calculating-the-correlation-coefficient"><i class="fa fa-check"></i><b>11.2.10</b> Example: Calculating the correlation coefficient</a></li>
<li class="chapter" data-level="11.2.11" data-path="lecture-11-analysis-of-variance-anova-2.html"><a href="lecture-11-analysis-of-variance-anova-2.html#inference-about-rho-test-for-a-zero-population-correlation"><i class="fa fa-check"></i><b>11.2.11</b> Inference about <span class="math inline">\(\rho\)</span> : Test For A Zero Population Correlation</a></li>
<li class="chapter" data-level="11.2.12" data-path="lecture-11-analysis-of-variance-anova-2.html"><a href="lecture-11-analysis-of-variance-anova-2.html#example-blood-pressure-and-platelet-calcium"><i class="fa fa-check"></i><b>11.2.12</b> Example: Blood pressure and platelet calcium</a></li>
<li class="chapter" data-level="11.2.13" data-path="lecture-11-analysis-of-variance-anova-2.html"><a href="lecture-11-analysis-of-variance-anova-2.html#inferences-on-rho-1-α-confidence-interval"><i class="fa fa-check"></i><b>11.2.13</b> Inferences on <span class="math inline">\(\rho\)</span>: (1-α)% confidence interval</a></li>
<li class="chapter" data-level="11.2.14" data-path="lecture-11-analysis-of-variance-anova-2.html"><a href="lecture-11-analysis-of-variance-anova-2.html#example-blood-pressure-and-platelet-calcium-1"><i class="fa fa-check"></i><b>11.2.14</b> Example: Blood pressure and platelet calcium</a></li>
<li class="chapter" data-level="11.2.15" data-path="lecture-11-analysis-of-variance-anova-2.html"><a href="lecture-11-analysis-of-variance-anova-2.html#correlation-coefficient-in-r"><i class="fa fa-check"></i><b>11.2.15</b> Correlation coefficient in R</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html"><i class="fa fa-check"></i><b>12</b> Lecture 12: Simple and Multiple Linear Regression</a>
<ul>
<li class="chapter" data-level="12.1" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#correlation-and-simple-linear-regression"><i class="fa fa-check"></i><b>12.1</b> Correlation and Simple Linear Regression</a>
<ul>
<li class="chapter" data-level="12.1.1" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#simple-and-multiple-linear-regression"><i class="fa fa-check"></i><b>12.1.1</b> Simple and Multiple Linear Regression</a></li>
<li class="chapter" data-level="12.1.2" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#research-question"><i class="fa fa-check"></i><b>12.1.2</b> Research question</a></li>
<li class="chapter" data-level="12.1.3" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#terminologies"><i class="fa fa-check"></i><b>12.1.3</b> Terminologies</a></li>
<li class="chapter" data-level="12.1.4" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#finch-mayo-dataset"><i class="fa fa-check"></i><b>12.1.4</b> Finch-Mayo Dataset</a></li>
<li class="chapter" data-level="12.1.5" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#knowing-the-type-of-outcome-measure-can-help-specify-the-theoretical-model"><i class="fa fa-check"></i><b>12.1.5</b> Knowing the type of outcome measure can help specify the theoretical model</a></li>
<li class="chapter" data-level="12.1.6" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#research-question-1"><i class="fa fa-check"></i><b>12.1.6</b> Research question</a></li>
<li class="chapter" data-level="12.1.7" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#measurement-scale"><i class="fa fa-check"></i><b>12.1.7</b> Measurement scale</a></li>
<li class="chapter" data-level="12.1.8" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#walking-capacity---physical-function"><i class="fa fa-check"></i><b>12.1.8</b> Walking capacity &lt;- Physical Function?</a></li>
<li class="chapter" data-level="12.1.9" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#descriptive-statistics-and-graphs"><i class="fa fa-check"></i><b>12.1.9</b> Descriptive statistics and graphs</a></li>
<li class="chapter" data-level="12.1.10" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#histogram-of-walking-capacity"><i class="fa fa-check"></i><b>12.1.10</b> Histogram of walking capacity</a></li>
<li class="chapter" data-level="12.1.11" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#walking-capacity-vs.-physical-function"><i class="fa fa-check"></i><b>12.1.11</b> Walking capacity vs. Physical Function</a></li>
<li class="chapter" data-level="12.1.12" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#correlation-between-physical-function-and-walking-capacity"><i class="fa fa-check"></i><b>12.1.12</b> Correlation between physical function and walking capacity</a></li>
<li class="chapter" data-level="12.1.13" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#results-of-simple-linear-regression-walking-capacity---pfi"><i class="fa fa-check"></i><b>12.1.13</b> Results of simple linear regression: Walking capacity &lt;- PFI</a></li>
<li class="chapter" data-level="12.1.14" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#simple-linear-regression"><i class="fa fa-check"></i><b>12.1.14</b> Simple Linear Regression</a></li>
<li class="chapter" data-level="12.1.15" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#comparison-of-regression-lines"><i class="fa fa-check"></i><b>12.1.15</b> Comparison of Regression Lines</a></li>
<li class="chapter" data-level="12.1.16" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#simple-linear-regression-model"><i class="fa fa-check"></i><b>12.1.16</b> Simple Linear Regression Model</a></li>
<li class="chapter" data-level="12.1.17" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#illustration-of-assumptions-behind-simple-linear-regression"><i class="fa fa-check"></i><b>12.1.17</b> Illustration of assumptions behind Simple Linear Regression</a></li>
<li class="chapter" data-level="12.1.18" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#assumptions-involved-in-simple-linear-regression"><i class="fa fa-check"></i><b>12.1.18</b> Assumptions involved in Simple Linear Regression</a></li>
<li class="chapter" data-level="12.1.19" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#simple-linear-regression-1"><i class="fa fa-check"></i><b>12.1.19</b> Simple Linear Regression</a></li>
<li class="chapter" data-level="12.1.20" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#residual"><i class="fa fa-check"></i><b>12.1.20</b> Residual</a></li>
<li class="chapter" data-level="12.1.21" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#simple-linear-regression-2"><i class="fa fa-check"></i><b>12.1.21</b> Simple Linear Regression</a></li>
<li class="chapter" data-level="12.1.22" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#estimating-a-and-b-using-the-method-of-least-squares"><i class="fa fa-check"></i><b>12.1.22</b> Estimating a and b using the method of least squares</a></li>
<li class="chapter" data-level="12.1.23" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#relation-between-slope-and-correlation-coefficient"><i class="fa fa-check"></i><b>12.1.23</b> Relation between slope and correlation coefficient</a></li>
<li class="chapter" data-level="12.1.24" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#estimating-the-error-variance"><i class="fa fa-check"></i><b>12.1.24</b> Estimating the error variance</a></li>
<li class="chapter" data-level="12.1.25" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#expressions-for-standard-errors-and-confidence-intervals-for-parameter-estimates"><i class="fa fa-check"></i><b>12.1.25</b> Expressions for standard errors and confidence intervals for parameter estimates</a></li>
<li class="chapter" data-level="12.1.26" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#hypothesis-tests-for-regression-coefficients"><i class="fa fa-check"></i><b>12.1.26</b> Hypothesis tests for regression coefficients</a></li>
<li class="chapter" data-level="12.1.27" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#estimating-the-regression-line"><i class="fa fa-check"></i><b>12.1.27</b> Estimating the regression line</a></li>
<li class="chapter" data-level="12.1.28" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#best-fitting-straight-line"><i class="fa fa-check"></i><b>12.1.28</b> Best fitting straight line</a></li>
<li class="chapter" data-level="12.1.29" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#confidence-interval-for-b"><i class="fa fa-check"></i><b>12.1.29</b> Confidence interval for b</a></li>
<li class="chapter" data-level="12.1.30" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#change-in-walking-capacity-for-a-1-sd-change-in-physical-function"><i class="fa fa-check"></i><b>12.1.30</b> Change in walking capacity for a 1 SD change in physical function</a></li>
<li class="chapter" data-level="12.1.31" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#estimating-average-walking-capacity-for-patients-with-physical-function50"><i class="fa fa-check"></i><b>12.1.31</b> Estimating average Walking Capacity for patients with Physical Function=50</a></li>
<li class="chapter" data-level="12.1.32" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#ci-for-average-walking-capacity-among-patients-with-pf50"><i class="fa fa-check"></i><b>12.1.32</b> 95% CI for average Walking Capacity among patients with PF=50</a></li>
<li class="chapter" data-level="12.1.33" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#ci-for-predicted-walking-capacity-in-an-individual-patient-with-pf50"><i class="fa fa-check"></i><b>12.1.33</b> 95% CI for predicted Walking Capacity in an individual patient with PF=50</a></li>
<li class="chapter" data-level="12.1.34" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#regression-diagnostics-using-residuals"><i class="fa fa-check"></i><b>12.1.34</b> Regression diagnostics using residuals</a></li>
<li class="chapter" data-level="12.1.35" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#plot-of-residuals-vs.-predicted-value-haty-or-exposure-x"><i class="fa fa-check"></i><b>12.1.35</b> Plot of residuals vs. predicted value <span class="math inline">\((\hat{y})\)</span> or exposure (X)</a></li>
<li class="chapter" data-level="12.1.36" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#residual-plot-prototype-a-ideal-situation-no-apparent-pattern"><i class="fa fa-check"></i><b>12.1.36</b> Residual plot: Prototype (a), Ideal Situation: No apparent pattern</a></li>
<li class="chapter" data-level="12.1.37" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#residual-plot-prototype-b-suggests-that-the-linear-model-is-inappropriate.-quadratic-model-with-x2-may-be-needed"><i class="fa fa-check"></i><b>12.1.37</b> Residual plot: Prototype (b), Suggests that the linear model is inappropriate. Quadratic model (with <span class="math inline">\(x^2\)</span>) may be needed</a></li>
<li class="chapter" data-level="12.1.38" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#how-does-the-non-linear-pattern-arise"><i class="fa fa-check"></i><b>12.1.38</b> How does the non-linear pattern arise?</a></li>
<li class="chapter" data-level="12.1.39" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#residual-plot-prototype-c-plot-suggests-variance-is-not-constant.-transformation-may-help."><i class="fa fa-check"></i><b>12.1.39</b> Residual plot: Prototype (c), Plot suggests variance is not constant. Transformation may help.</a></li>
<li class="chapter" data-level="12.1.40" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#residual-plot-for-walking-capacity-vs.-physical-function-model"><i class="fa fa-check"></i><b>12.1.40</b> Residual plot for Walking Capacity vs. Physical Function model</a></li>
<li class="chapter" data-level="12.1.41" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#what-is-the-impact-of-an-outlier"><i class="fa fa-check"></i><b>12.1.41</b> What is the impact of an outlier?</a></li>
<li class="chapter" data-level="12.1.42" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#what-should-we-do-with-an-outlier"><i class="fa fa-check"></i><b>12.1.42</b> What should we do with an outlier?</a></li>
<li class="chapter" data-level="12.1.43" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#qq-plot-to-see-if-residuals-are-normally-distributed"><i class="fa fa-check"></i><b>12.1.43</b> QQ-plot to see if residuals are normally distributed</a></li>
<li class="chapter" data-level="12.1.44" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#q-q-plot-for-walking-capacity-vs.-physical-function-model"><i class="fa fa-check"></i><b>12.1.44</b> Q-Q plot for Walking Capacity vs. Physical Function model</a></li>
<li class="chapter" data-level="12.1.45" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#what-does-the-qq-plot-tell-us"><i class="fa fa-check"></i><b>12.1.45</b> What does the QQ plot tell us?</a></li>
<li class="chapter" data-level="12.1.46" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#goodness-of-fit"><i class="fa fa-check"></i><b>12.1.46</b> Goodness of fit</a></li>
<li class="chapter" data-level="12.1.47" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#multiple-linear-regression-conceptual-model"><i class="fa fa-check"></i><b>12.1.47</b> Multiple Linear Regression: Conceptual Model</a></li>
<li class="chapter" data-level="12.1.48" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#self-perceived-health---physical-function-covariates"><i class="fa fa-check"></i><b>12.1.48</b> Self-Perceived Health &lt;- Physical Function + covariates</a></li>
<li class="chapter" data-level="12.1.49" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#exploratory-analyses"><i class="fa fa-check"></i><b>12.1.49</b> Exploratory analyses</a></li>
<li class="chapter" data-level="12.1.50" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#multiple-linear-regression-model"><i class="fa fa-check"></i><b>12.1.50</b> Multiple Linear Regression Model</a></li>
<li class="chapter" data-level="12.1.51" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#results-of-simple-and-multiple-linear-regression-models"><i class="fa fa-check"></i><b>12.1.51</b> Results<span class="math inline">\(^*\)</span> of simple and multiple linear regression models</a></li>
<li class="chapter" data-level="12.1.52" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#interpretation-of-regression-coefficients-in-a-model-with-interaction-terms"><i class="fa fa-check"></i><b>12.1.52</b> Interpretation of regression coefficients in a model with interaction terms</a></li>
<li class="chapter" data-level="12.1.53" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#interpretation-of-coefficients-of-interaction-terms"><i class="fa fa-check"></i><b>12.1.53</b> Interpretation of coefficients of interaction terms</a></li>
<li class="chapter" data-level="12.1.54" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#model-checking"><i class="fa fa-check"></i><b>12.1.54</b> Model checking</a></li>
<li class="chapter" data-level="12.1.55" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#residuals-vs.-fitted-values-for-our-example"><i class="fa fa-check"></i><b>12.1.55</b> Residuals vs. Fitted values for our example</a></li>
<li class="chapter" data-level="12.1.56" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#standardized-residuals-vs.-fitted-values"><i class="fa fa-check"></i><b>12.1.56</b> Standardized Residuals vs. Fitted Values</a></li>
<li class="chapter" data-level="12.1.57" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#qq-normal-plot-of-standardized-residuals"><i class="fa fa-check"></i><b>12.1.57</b> QQ (normal)-plot of standardized residuals</a></li>
<li class="chapter" data-level="12.1.58" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#vif-for-our-example"><i class="fa fa-check"></i><b>12.1.58</b> VIF for our example</a></li>
<li class="chapter" data-level="12.1.59" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#model-with-centred-pfi-and-mhi-notice-change-in-slopes-of-these-variables"><i class="fa fa-check"></i><b>12.1.59</b> Model with centred PFI and MHI (notice change in slopes of these variables!)</a></li>
<li class="chapter" data-level="12.1.60" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#results-of-multiple-linear-regression-model-before-and-after-centering"><i class="fa fa-check"></i><b>12.1.60</b> Results<span class="math inline">\(^*\)</span> of multiple linear regression model before and after centering</a></li>
<li class="chapter" data-level="12.1.61" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#revised-interpretation-of-interaction-terms"><i class="fa fa-check"></i><b>12.1.61</b> Revised interpretation of interaction terms</a></li>
<li class="chapter" data-level="12.1.62" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#interpretation-of-regression-coefficients-in-a-model-with-centred-explanatory-variables"><i class="fa fa-check"></i><b>12.1.62</b> Interpretation of regression coefficients in a model with centred explanatory variables</a></li>
<li class="chapter" data-level="12.1.63" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#inference-for-slopes"><i class="fa fa-check"></i><b>12.1.63</b> Inference for slopes</a></li>
<li class="chapter" data-level="12.1.64" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#example-inference-for-slope-of-pfi-when-mhi90"><i class="fa fa-check"></i><b>12.1.64</b> Example: Inference for slope of PFI when MHI=90</a></li>
<li class="chapter" data-level="12.1.65" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#anova-table-for-multiple-linear-regression-model"><i class="fa fa-check"></i><b>12.1.65</b> ANOVA table for Multiple Linear Regression Model<span class="math inline">\(^*\)</span></a></li>
<li class="chapter" data-level="12.1.66" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#adjusted-r-squared"><i class="fa fa-check"></i><b>12.1.66</b> Adjusted R-squared</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://nandinidendukuri.com" target="blank">Nandini Dendukuri</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Intro to Statistics Notes</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="lecture-4-inference-for-means-continued" class="section level1 hasAnchor" number="4">
<h1><span class="header-section-number">4</span> Lecture 4: Inference for means continued<a href="lecture-4-inference-for-means-continued.html#lecture-4-inference-for-means-continued" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="hypothesis-testing" class="section level2 hasAnchor" number="4.1">
<h2><span class="header-section-number">4.1</span> Hypothesis testing<a href="lecture-4-inference-for-means-continued.html#hypothesis-testing" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="example-1-nck1-and-adipogenesis-continued" class="section level3 hasAnchor" number="4.1.1">
<h3><span class="header-section-number">4.1.1</span> Example 1: Nck1 and adipogenesis continued<a href="lecture-4-inference-for-means-continued.html#example-1-nck1-and-adipogenesis-continued" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>Whereas in the previous lecture we saw how to carry out statistical inference about the differences between Nck1 wild type and Nck1 knock out mice using confidence intervals, the manuscript relied on hypothesis testing</li>
</ul>
</div>
<div id="hypothesis-testing-1" class="section level3 hasAnchor" number="4.1.2">
<h3><span class="header-section-number">4.1.2</span> Hypothesis testing<a href="lecture-4-inference-for-means-continued.html#hypothesis-testing-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>Hypothesis testing is an alternative approach to statistical inference that also relies on the Central Limit Theorem</li>
<li>The research question takes the form of a decision making problem, e.g. 
<ul>
<li>Does mobility improve 3-months after a stroke?</li>
<li>Is there a difference in the improvement in mobility between men and women after a stroke?</li>
<li>Does Treatment A improve life-expectancy compared to Treatment B?</li>
</ul></li>
<li>Each of these questions can be answered yes or no. Each response can be expressed as a specific statement</li>
<li>We can view the response to the stroke mobility problem as a choice between the following two statements or hypotheses
<ul>
<li><span class="math inline">\(H_0\)</span>: There is no improvement in mobility 3 months after stroke</li>
<li><span class="math inline">\(H_A\)</span>: There is improvement in mobility 3 months after stroke</li>
</ul></li>
<li>In general, a decision-making problem can be framed in terms of a null hypothesis <span class="math inline">\((H_0)\)</span> and an alternative hypothesis <span class="math inline">\((H_A)\)</span>. The <span class="math inline">\(H_A\)</span> is the complement of the null hypothesis</li>
<li>We typically focus on the null hypothesis, which is usually simpler than the alternative hypothesis, and decide whether or not to reject it.</li>
<li>To this end, we examine the evidence that the observed data provide against the null hypothesis <span class="math inline">\(H_0\)</span></li>
<li>If the evidence against <span class="math inline">\(H_0\)</span> is strong, <strong>we reject <span class="math inline">\(H_0\)</span></strong></li>
<li>If not, we state that the evidence provided by the data is not strong enough, and <strong>we fail to reject <span class="math inline">\(H_0\)</span></strong>.</li>
</ul>
</div>
<div id="hypothesis-testing-for-a-single-mean" class="section level3 hasAnchor" number="4.1.3">
<h3><span class="header-section-number">4.1.3</span> Hypothesis testing for a single mean<a href="lecture-4-inference-for-means-continued.html#hypothesis-testing-for-a-single-mean" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>The hypothesis test may be set up with
<ul>
<li>a two-sided alternative</li>
<li>or a one-sided alternative</li>
</ul></li>
<li>resulting in 3 different possibilities mentioned in
the following slides</li>
</ul>
</div>
<div id="mobility-after-stroke-two-sided-alternative-hypothesis" class="section level3 hasAnchor" number="4.1.4">
<h3><span class="header-section-number">4.1.4</span> Mobility after stroke: two-sided alternative hypothesis<a href="lecture-4-inference-for-means-continued.html#mobility-after-stroke-two-sided-alternative-hypothesis" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<table>
<thead>
<tr>
<th style="text-align:left;">
Null Hypothesis
</th>
<th style="text-align:left;">
Alternative Hypothesis
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
<span class="math inline">\(H_0\)</span>: The <strong>true mean</strong> change in the STREAM score between 3-days and 3 months post stroke <strong>is 0 units</strong>
</td>
<td style="text-align:left;">
<span class="math inline">\(H_A\)</span>: The <strong>true mean</strong> change in the STREAM score between 3-days and 3 months post stroke <strong>is not 0 units</strong>
</td>
</tr>
</tbody>
</table>
</div>
<div id="mobility-after-stroke-one-sided-alternative-hypothesis-i" class="section level3 hasAnchor" number="4.1.5">
<h3><span class="header-section-number">4.1.5</span> Mobility after stroke: one-sided alternative hypothesis I<a href="lecture-4-inference-for-means-continued.html#mobility-after-stroke-one-sided-alternative-hypothesis-i" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<table>
<thead>
<tr>
<th style="text-align:left;">
Null Hypothesis
</th>
<th style="text-align:left;">
Alternative Hypothesis
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
<span class="math inline">\(H_0\)</span>: The <strong>true mean</strong> change in the STREAM score between 3-days and 3 months post stroke <strong>is less than or equal to 0 units</strong>
</td>
<td style="text-align:left;">
<span class="math inline">\(H_A\)</span>: The <strong>true mean</strong> change in the STREAM score between 3-days and 3 months post stroke <strong>is greater than 0 units</strong>
</td>
</tr>
</tbody>
</table>
</div>
<div id="mobility-after-stroke-one-sided-alternative-hypothesis-ii" class="section level3 hasAnchor" number="4.1.6">
<h3><span class="header-section-number">4.1.6</span> Mobility after stroke: one-sided alternative hypothesis II<a href="lecture-4-inference-for-means-continued.html#mobility-after-stroke-one-sided-alternative-hypothesis-ii" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<table>
<thead>
<tr>
<th style="text-align:left;">
Null Hypothesis
</th>
<th style="text-align:left;">
Alternative Hypothesis
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
<span class="math inline">\(H_0\)</span>: The <strong>true mean</strong> change in the STREAM score between 3-days and 3 months post stroke <strong>is greater than or equal to 0 units</strong>
</td>
<td style="text-align:left;">
<span class="math inline">\(H_A\)</span>: The <strong>true mean</strong> change in the STREAM score between 3-days and 3 months post stroke <strong>is less than 0 units</strong>
</td>
</tr>
</tbody>
</table>
</div>
<div id="more-generally-the-hypothesis-test-for-a-single-mean-may-be-stated-as-follows" class="section level3 hasAnchor" number="4.1.7">
<h3><span class="header-section-number">4.1.7</span> More generally, the hypothesis test for a single mean may be stated as follows<a href="lecture-4-inference-for-means-continued.html#more-generally-the-hypothesis-test-for-a-single-mean-may-be-stated-as-follows" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>The null and alternative hypotheses for a two-sided test may be stated as</li>
</ul>
<p><span class="math inline">\(H_0: µ = µ_0\space\space\space\space\space vs \space\space\space\space\space H_A: µ ≠ µ_0\)</span></p>
<p>where µ denotes the true population mean <span class="math inline">\(µ_0\)</span> is a known constant</p>
<ul>
<li>The null and alternative hypotheses for a one-sided test can be stated as follows</li>
</ul>
<p><span class="math inline">\(H_0: µ ≤ µ_0 \space\space\space\space\space vs \space\space\space\space\space H_A: µ &gt; µ_0\)</span></p>
<p>OR</p>
<p><span class="math inline">\(H_0: µ ≥ µ_0\space\space\space\space\space vs \space\space\space\space\space H_A: µ &lt; µ_0\)</span></p>
</div>
<div id="example-mobility-after-stroke" class="section level3 hasAnchor" number="4.1.8">
<h3><span class="header-section-number">4.1.8</span> Example: Mobility after stroke<a href="lecture-4-inference-for-means-continued.html#example-mobility-after-stroke" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<table>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
Three days after stroke
</th>
<th style="text-align:right;">
Three months after stroke
</th>
<th style="text-align:left;">
Difference
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Number of cases
</td>
<td style="text-align:right;">
235.00
</td>
<td style="text-align:right;">
235.00
</td>
<td style="text-align:left;">
235
</td>
</tr>
<tr>
<td style="text-align:left;">
Minimum
</td>
<td style="text-align:right;">
0.00
</td>
<td style="text-align:right;">
0.00
</td>
<td style="text-align:left;">
-22.22
</td>
</tr>
<tr>
<td style="text-align:left;">
Maximum
</td>
<td style="text-align:right;">
100.00
</td>
<td style="text-align:right;">
100.00
</td>
<td style="text-align:left;">
91.67
</td>
</tr>
<tr>
<td style="text-align:left;">
Mean
</td>
<td style="text-align:right;">
68.30
</td>
<td style="text-align:right;">
83.75
</td>
<td style="text-align:left;">
<span class="math inline">\(\bar y = 15.45\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;">
Standard deviation
</td>
<td style="text-align:right;">
30.12
</td>
<td style="text-align:right;">
22.74
</td>
<td style="text-align:left;">
s = 18.97
</td>
</tr>
</tbody>
</table>
</div>
<div id="defining-the-test-statistic-and-the-rejection-region" class="section level3 hasAnchor" number="4.1.9">
<h3><span class="header-section-number">4.1.9</span> Defining the test statistic and the rejection region<a href="lecture-4-inference-for-means-continued.html#defining-the-test-statistic-and-the-rejection-region" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p>Recall that based on the Central Limit Theorem,<br />
<span class="math inline">\(\bar Y\)</span> ~ <span class="math inline">\(N(\mu,\sigma^2/n)\)</span> or <span class="math inline">\(\bar Y\)</span> ~ <span class="math inline">\(N(\mu,\sigma^2/235)\)</span></p></li>
<li><p>We can also express this as <span class="math inline">\(\frac{\bar Y-\mu}{\frac{\sigma}{\sqrt n}}\)</span> follow a standard normal distribution</p></li>
<li><p>We can use our knowledge of the sampling distribution of <span class="math inline">\(\frac{\bar Y-\mu}{\frac{\sigma}{\sqrt n}}\)</span> (the test statistic) to determine which values are likely under the null hypothesis</p></li>
<li><p>We define a rejection region such that if test statistic falls in this region we reject the null hypothesis</p></li>
</ul>
</div>
<div id="defining-the-t-test-statistic" class="section level3 hasAnchor" number="4.1.10">
<h3><span class="header-section-number">4.1.10</span> Defining the t-test statistic<a href="lecture-4-inference-for-means-continued.html#defining-the-t-test-statistic" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>As in the case of the construction of a confidence interval, we are faced, with the problem that we seldom know the true standard deviation.</li>
<li>We can <strong>estimate</strong> the value of the unknown population standard deviation using the sample standard deviation <span class="math inline">\(\hat{\sigma}=s=18.97\)</span></li>
<li>The standardized test statistic is then <span class="math inline">\(\frac{\bar Y-\mu}{\frac{\sigma}{\sqrt n}}=\frac{15.45}{\frac{18.97}{\sqrt{235}}}=12.49\)</span></li>
<li>This statistic is referred to as the <strong>t-statistic</strong> as it follows a t-distribution with n-1 degrees of freedom</li>
<li>The corresponding hypothesis test is called the <strong>t-test</strong>.</li>
</ul>
</div>
<div id="rejection-region-for-the-t-test" class="section level3 hasAnchor" number="4.1.11">
<h3><span class="header-section-number">4.1.11</span> Rejection region for the t-test<a href="lecture-4-inference-for-means-continued.html#rejection-region-for-the-t-test" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><img src="4_15.png" width="50%" /></p>
<ul>
<li>Our goal is to select a rejection region such that it covers values that are unlikely under the null hypothesis</li>
<li>The form of rejection region depends on the statement of the alternative hypothesis. * We first consider the two-sided alternative. Under this alternative hypothesis, the rejection region covers the extremes of the distribution on both sides</li>
<li>The two areas each covering with 0.025 probability in the extremes are unlikely under the null hypothesis as illustrated by the diagram. They correspond to a <strong>Type I error of 0.025+0.025 = 0.05</strong>, which we will define shortly</li>
<li>Under the t-distribution with degrees of freedom = n-1 = 234, these areas may be identified by the quantiles <span class="math inline">\(Q_{0.025} = -1.97\)</span> and <span class="math inline">\(Q_{0.975} = 1.97\)</span>
<ul>
<li>Therefore, if the t-statistic is above 1.97 or less than -1.97 we reject the null hypothesis</li>
</ul></li>
<li>In our example, 12.49 is well above 1.97 so we <strong>reject the null hypothesis</strong></li>
</ul>
</div>
<div id="comparison-to-confidence-interval" class="section level3 hasAnchor" number="4.1.12">
<h3><span class="header-section-number">4.1.12</span> Comparison to confidence interval<a href="lecture-4-inference-for-means-continued.html#comparison-to-confidence-interval" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>The hypothesis testing approach resulted in a similar conclusion to the equal-tailed confidence interval derived earlier in that we concluded that mobility improves 3 months after stroke</li>
<li>In fact, the equal-tailed 95% confidence interval derived previously gives the range of possible values of the null hypothesis that cannot be rejected.
<ul>
<li>All values outside that interval will be rejected</li>
<li>That happens to include the value of 5 units which defines a clinically meaningful improvement</li>
</ul></li>
</ul>
</div>
<div id="determining-the-rejection-region-using-r" class="section level3 hasAnchor" number="4.1.13">
<h3><span class="header-section-number">4.1.13</span> Determining the rejection region using R<a href="lecture-4-inference-for-means-continued.html#determining-the-rejection-region-using-r" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We use the qt() function to obtain the quantiles of a t-distribution corresponding to the desired tail-area probability</p>
<blockquote>
<p>qt(0.025,234)<br />
[1] -1.970154</p>
</blockquote>
<blockquote>
<p>qt(0.975,234)<br />
[1] 1.970154</p>
</blockquote>
<p>The sample size is very large. Therefore, for all practical purposes the t-distribution with degrees of freedom n-1 = 234 is like a normal distribution</p>
<blockquote>
<p>qnorm(0.025)<br />
[1] -1.959964</p>
</blockquote>
<blockquote>
<p>qnorm(0.975)<br />
[1] 1.959964</p>
</blockquote>
</div>
<div id="type-i-and-type-ii-errors" class="section level3 hasAnchor" number="4.1.14">
<h3><span class="header-section-number">4.1.14</span> Type I and Type II errors<a href="lecture-4-inference-for-means-continued.html#type-i-and-type-ii-errors" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>With respect to our decision regarding the null hypothesis we can make two types of errors
<ul>
<li>Type I error (α): We reject <span class="math inline">\(H_0\)</span> when it is true</li>
<li>Type II error (β): We fail to reject <span class="math inline">\(H_0\)</span> when it is not true (i.e. when <span class="math inline">\(H_A\)</span> is true)</li>
</ul></li>
<li>Clearly, we wish to minimize the chance of these errors. Typical values are α=0.05 and β=0.2</li>
</ul>
</div>
<div id="hypothesis-testing-a-summary" class="section level3 hasAnchor" number="4.1.15">
<h3><span class="header-section-number">4.1.15</span> Hypothesis testing: A summary<a href="lecture-4-inference-for-means-continued.html#hypothesis-testing-a-summary" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ol style="list-style-type: decimal">
<li>Define null and alternative hypotheses</li>
<li>Define test statistic</li>
<li>Define rejection region with suitably selected Type I error α</li>
<li>If test statistic lies in the rejection region then reject null hypothesis, otherwise conclude that you do not have enough evidence to reject the null hypothesis</li>
</ol>
</div>
<div id="similarity-between-diagnostic-testing-and-hypothesis-testing" class="section level3 hasAnchor" number="4.1.16">
<h3><span class="header-section-number">4.1.16</span> Similarity between diagnostic testing and hypothesis testing<a href="lecture-4-inference-for-means-continued.html#similarity-between-diagnostic-testing-and-hypothesis-testing" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><img src="4_21a.png" width="50%" /></p>
<ul>
<li>Sensitivity = A / (A+C)</li>
<li>Specificity = D / (B+D)</li>
<li>A, B, C and D are numbers of individuals tested</li>
</ul>
<p><img src="4_21b.png" width="50%" /></p>
<ul>
<li>1-Type II error (Power) = A / (A+C)</li>
<li>1-Type I error = D / (B+D)</li>
<li>A, B, C and D are values of the test statistic observed across repeated experiments</li>
</ul>
</div>
<div id="defining-the-t-test-statistic-for-a-one-sided-test" class="section level3 hasAnchor" number="4.1.17">
<h3><span class="header-section-number">4.1.17</span> Defining the t-test statistic, for a one-sided test<a href="lecture-4-inference-for-means-continued.html#defining-the-t-test-statistic-for-a-one-sided-test" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p>Consider the situation where we pose the null and alternative hypotheses as follows<br />
<span class="math inline">\(H_0: µ ≤ µ_0 \space\space\space\space\space vs \space\space\space\space\space H_A: µ &gt; µ_0\)</span></p></li>
<li><p>The test statistic is still evaluated at <span class="math inline">\(µ = µ_0 = 0\)</span> as before</p></li>
<li><p>However, the rejection region is one-sided. In order to ensure that the rejection region has a 5% probability as in our previous example, we will define it as the region above <span class="math inline">\(Q_{0.95} = 1.65\)</span></p></li>
<li><p>For our example, the t-statistic would remain unchanged at 12.49 and therefore would lie in the rejection region once again, leading to the same conclusion as before</p></li>
</ul>
</div>
<div id="why-did-the-test-statistic-not-change-for-the-one-sided-hypothesis-test" class="section level3 hasAnchor" number="4.1.18">
<h3><span class="header-section-number">4.1.18</span> Why did the test statistic not change for the one-sided hypothesis test?<a href="lecture-4-inference-for-means-continued.html#why-did-the-test-statistic-not-change-for-the-one-sided-hypothesis-test" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>Notice that though our null hypothesis was <span class="math inline">\(H_0: µ ≤ 0\)</span>, we calculated the test-statistic at µ=0</li>
<li>This is because we know that rejection region under smaller values of µ below zero will be shifted to the left compared to <span class="math inline">\(Q_{0.95} = 1.65\)</span></li>
<li>Therefore, if our test statistic results in rejecting µ=0, it will certainly result in rejecting values of µ less than 0</li>
</ul>
</div>
<div id="what-is-statistical-significance" class="section level3 hasAnchor" number="4.1.19">
<h3><span class="header-section-number">4.1.19</span> What is statistical significance?<a href="lecture-4-inference-for-means-continued.html#what-is-statistical-significance" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>As mentioned earlier, the rejection region is selected so that it is unlikely under the null hypothesis</li>
<li>Therefore, when the test-statistic falls in the rejection region, we say it is statistically significant</li>
<li>Traditionally, this region is selected to have 5% probability under the null hypothesis. However, 5% is arbitrary</li>
<li>Note that in setting up the test statistic, only the null hypothesis came into play. The alternative hypothesis did not matter</li>
</ul>
</div>
<div id="what-is-a-p-value" class="section level3 hasAnchor" number="4.1.20">
<h3><span class="header-section-number">4.1.20</span> What is a p-value?<a href="lecture-4-inference-for-means-continued.html#what-is-a-p-value" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>The p-value is defined as the probability of being more extreme than the test statistic under the null hypothesis<br />
= <strong>P(Test statistic is more extreme than its observed value | H0)</strong></li>
<li>In our example, involving a <strong>one-sided</strong> test<br />
<span class="math inline">\(p-value = P(T_{234} &gt; 12.49 |H_0) = 1-pt(12.49,234) = 0\)</span></li>
<li>Clearly, when the test statistic is statistically significant, the p-value is less than 5% or more generally it is less than the Type I error</li>
<li>This explains why the p-value is often compared to 5% to determine statistical significance</li>
</ul>
</div>
<div id="p-value-illustrated" class="section level3 hasAnchor" number="4.1.21">
<h3><span class="header-section-number">4.1.21</span> p-value illustrated<a href="lecture-4-inference-for-means-continued.html#p-value-illustrated" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><img src="4_26.png" width="50%" /></p>
<ul>
<li>Notice the difference between the p-value and the rejection region for a <strong>two-sided</strong> test
<ul>
<li>The red lines mark off the rejection region of α=0.05 at ±1.97</li>
<li>The blue line is a hypothetical observed t-statistic=2.3</li>
<li>The shaded area marks off the p-value</li>
<li>The green line is at -2.3, was not observed. Yet, we use the area beyond it to obtain a two-sided p-value</li>
</ul></li>
</ul>
<p><img src="4_27.png" width="50%" /></p>
<ul>
<li>This figure illustrates the p-value for a one-sided test with <span class="math inline">\(H_A: µ &gt; µ_0\)</span>
<ul>
<li>Once again, the red line marks off the rejection region of α=0.05 at 1.65</li>
<li>The blue line is the observed t-statistic=2.3 in this illustration</li>
<li>The shaded area marks off the p-value. Note that the p-value is half that of the one-sided test by definition</li>
</ul></li>
</ul>
<p><img src="4_28.png" width="50%" /></p>
<ul>
<li>Finally, this figure illustrates the p-value for a one-sided test with <span class="math inline">\(H_A: µ &lt; µ_0\)</span>
<ul>
<li>This time, the red line marks off the rejection region of α=0.05 at -1.65</li>
<li>The blue line is the observed t-statistic=-2.3 in this illustration</li>
<li>The shaded area marks off the p-value</li>
</ul></li>
</ul>
</div>
<div id="type-i-and-type-ii-errors-1" class="section level3 hasAnchor" number="4.1.22">
<h3><span class="header-section-number">4.1.22</span> Type I and Type II errors<a href="lecture-4-inference-for-means-continued.html#type-i-and-type-ii-errors-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><img src="4_29.png" width="50%" /></p>
<ul>
<li>Recall
<ul>
<li>Type I error is the probability of rejecting the null hypothesis when it is true</li>
<li>Type II error is the probability of not rejecting the null hypothesis when the alternative is true</li>
</ul></li>
</ul>
</div>
<div id="t-test" class="section level3 hasAnchor" number="4.1.23">
<h3><span class="header-section-number">4.1.23</span> t-test<a href="lecture-4-inference-for-means-continued.html#t-test" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><img src="4_30.png" width="50%" /></p>
<ul>
<li>The t.test function in R tells us that that we can reject the null hypothesis of no difference in the mean log10 interleukin levels in the two groups at the Type I error level of 0.05</li>
</ul>
</div>
<div id="a-bit-of-history-pearson-vs.-fisher" class="section level3 hasAnchor" number="4.1.24">
<h3><span class="header-section-number">4.1.24</span> A bit of history: Pearson vs. Fisher<a href="lecture-4-inference-for-means-continued.html#a-bit-of-history-pearson-vs.-fisher" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>The hypothesis test and p-value were proposed by Karl Pearson and Ronald Fisher, respectively, who were contemporaries who strongly disagreed with each other</li>
<li>It is ironic that today we use these two techniques together!</li>
<li>As we will discuss in greater detail in later lectures, there has been a backlash against both these approaches and a move towards usage of confidence intervals or Bayesian methods</li>
</ul>
</div>
<div id="inference-for-comparing-two-means" class="section level3 hasAnchor" number="4.1.25">
<h3><span class="header-section-number">4.1.25</span> Inference for comparing two means<a href="lecture-4-inference-for-means-continued.html#inference-for-comparing-two-means" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>The hypothesis test for comparing two means resembles the structure of the hypothesis test for a single mean
<ul>
<li>it can be two-sided or one-sided</li>
<li>the form of the test-statistics depends on the study design and assumptions, e.g.
<ul>
<li>Whether the study design involves paired or unpaired means</li>
<li>Assuming the variance in the two groups is equal or not</li>
<li>Assuming the variance is known or not</li>
</ul></li>
</ul></li>
</ul>
</div>
<div id="stroke-study-question-2-two-sided-alternative-hypothesis" class="section level3 hasAnchor" number="4.1.26">
<h3><span class="header-section-number">4.1.26</span> Stroke study: Question 2, two-sided alternative hypothesis<a href="lecture-4-inference-for-means-continued.html#stroke-study-question-2-two-sided-alternative-hypothesis" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<table>
<thead>
<tr>
<th style="text-align:left;">
Null Hypothesis
</th>
<th style="text-align:left;">
Alternative Hypothesis
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
<span class="math inline">\(H_0\)</span>: The true mean change in the STREAM score between 3-days and 3 months post stroke <strong>is the same for men and women</strong>
</td>
<td style="text-align:left;">
<span class="math inline">\(H_A\)</span>: The true mean change in the STREAM score between 3-days and 3 months post stroke <strong>is not the same for men and women</strong>
</td>
</tr>
</tbody>
</table>
</div>
<div id="stroke-study-question-2-one-sided-hypothesis-i" class="section level3 hasAnchor" number="4.1.27">
<h3><span class="header-section-number">4.1.27</span> Stroke study: Question 2, one-sided hypothesis I<a href="lecture-4-inference-for-means-continued.html#stroke-study-question-2-one-sided-hypothesis-i" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<table>
<thead>
<tr>
<th style="text-align:left;">
Null Hypothesis
</th>
<th style="text-align:left;">
Alternative Hypothesis
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
<span class="math inline">\(H_0\)</span>: The true mean change in the STREAM score between 3-days and 3 months post stroke <strong>is at most as great in men as in women</strong>
</td>
<td style="text-align:left;">
<span class="math inline">\(H_A\)</span>: The <strong>true mean change</strong> in the STREAM score between 3-days and 3 months post stroke <strong>is greater in men than in women</strong>
</td>
</tr>
</tbody>
</table>
</div>
<div id="stroke-study-question-2-one-sided-hypothesis-ii" class="section level3 hasAnchor" number="4.1.28">
<h3><span class="header-section-number">4.1.28</span> Stroke study: Question 2, one-sided hypothesis II<a href="lecture-4-inference-for-means-continued.html#stroke-study-question-2-one-sided-hypothesis-ii" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<table>
<thead>
<tr>
<th style="text-align:left;">
Null Hypothesis
</th>
<th style="text-align:left;">
Alternative Hypothesis
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
<span class="math inline">\(H_0\)</span>: The true mean change in the STREAM score between 3-days and 3 months post stroke <strong>is at least as great in men as in women</strong>
</td>
<td style="text-align:left;">
<span class="math inline">\(H_A\)</span>: The <strong>true mean change</strong> in the STREAM score between 3-days and 3 months post stroke <strong>is lesser in men than in women</strong>
</td>
</tr>
</tbody>
</table>
</div>
<div id="example-one-sided-or-two-sided-test" class="section level3 hasAnchor" number="4.1.29">
<h3><span class="header-section-number">4.1.29</span> Example: One-sided or two-sided test?<a href="lecture-4-inference-for-means-continued.html#example-one-sided-or-two-sided-test" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>We return to the second research question based on the stroke dataset. It is of interest to compare the change in mobility (from baseline to 3 months) between men and women</li>
<li>One way to do this is to carry out a hypothesis test.</li>
<li>We will begin with a two-sided hypothesis test:</li>
</ul>
<p><span class="math inline">\(H_0: \mu_1=\mu_2\space\space\space\space\space vs. \space\space\space\space\space H_A:\mu_1\neq\mu_2\)</span></p>
<p>where <span class="math inline">\(µ_1\)</span> is the true mean change in mobility in men and <span class="math inline">\(µ_2\)</span> is the true mean change in women</p>
</div>
<div id="difference-in-change-in-mobility-between-men-and-women" class="section level3 hasAnchor" number="4.1.30">
<h3><span class="header-section-number">4.1.30</span> Difference in change in mobility between men and women<a href="lecture-4-inference-for-means-continued.html#difference-in-change-in-mobility-between-men-and-women" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<table>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:left;">
Change in Men
</th>
<th style="text-align:left;">
Change in Women
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Number of cases
</td>
<td style="text-align:left;">
144
</td>
<td style="text-align:left;">
91
</td>
</tr>
<tr>
<td style="text-align:left;">
Mean
</td>
<td style="text-align:left;">
<span class="math inline">\(\bar y_1 = 17.09\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(\bar y_2 = 12.86\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;">
Standard deviation
</td>
<td style="text-align:left;">
<span class="math inline">\(s_1 = 19.25\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(s_2 = 18.31\)</span>
</td>
</tr>
</tbody>
</table>
<ul>
<li>Recall that we had assumed that the variance is the same in both groups being compared and calculate a pooled variance that averages across both groups of <span class="math inline">\(s_{diff}=2.53\)</span></li>
</ul>
</div>
<div id="comparing-change-in-mobility-between-men-and-women" class="section level3 hasAnchor" number="4.1.31">
<h3><span class="header-section-number">4.1.31</span> Comparing change in mobility between men and women<a href="lecture-4-inference-for-means-continued.html#comparing-change-in-mobility-between-men-and-women" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>The t-statistic is given by</li>
</ul>
<p><span class="math display">\[\frac{\bar Y_1-\bar Y_2-(\mu_1-\mu_2)}{s_{diff}}=\frac{\bar Y_1-\bar Y_2}{s_{diff}}=\frac{17.09-12.86}{2.53}=1.67\]</span></p>
<ul>
<li>Since we are working under the assumption that the variances are equal, the t-distribution used to define the rejection region has degrees of freedom n1+n2-2 (as we saw previously when defining a confidence interval for comparing two means)</li>
<li>If we use a Type I error value of α=0.05, we <strong>would</strong> reject the null hypothesis if it lies below -1.96 or above 1.96</li>
<li>In our case, the t-statistic falls within this <strong>region</strong> so we say “we do not have enough evidence to reject the null hypothesis”</li>
<li>The p-value is 0.09, which exceeds 0.05</li>
<li>The p-value can be calculated as follows in R</li>
</ul>
<blockquote>
<p>2*(1-pt((17.09-12.86)/2.53,233))<br />
[1] 0.09587913</p>
</blockquote>
</div>
<div id="what-if-our-alternative-hypothesis-was-one-sided-instead" class="section level3 hasAnchor" number="4.1.32">
<h3><span class="header-section-number">4.1.32</span> What if our alternative hypothesis was one-sided instead?<a href="lecture-4-inference-for-means-continued.html#what-if-our-alternative-hypothesis-was-one-sided-instead" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>It is to be expected that men may experience a greater improvement in mobility than women. Therefore, we can restate our hypothesis test as:</li>
</ul>
<p><span class="math inline">\(H_0: µ_1 ≤ µ_2 \space\space\space\space\space vs \space\space\space\space\space H_A: µ_1 &gt; µ_2\)</span></p>
<p>where µ1 is the true mean change in men and µ2 is the true mean change in women</p>
<ul>
<li>As in the case of hypothesis testing for a single mean, the test statistic remains the same</li>
<li>However the rejection region is one-sided. Using the quantiles of the t-distribution with n1+n2-2=233 degrees of freedom, we can determine that the rejection region includes the region above <span class="math inline">\(Q_{0.95} = 1.65\)</span>. Therefore, our test statistic of 1.67 lies in the rejection region</li>
<li>In comparison with this rejection region, we would conclude that we have enough evidence to reject the null hypothesis that the mean change in mobility in men is less than or equal to that of women</li>
</ul>
</div>
<div id="what-if-our-alternative-hypothesis-was-one-sided-in-the-other-direction" class="section level3 hasAnchor" number="4.1.33">
<h3><span class="header-section-number">4.1.33</span> What if our alternative hypothesis was one-sided in the other direction?<a href="lecture-4-inference-for-means-continued.html#what-if-our-alternative-hypothesis-was-one-sided-in-the-other-direction" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>Only for the purpose of illustrating how the rejection region is defined, let us restate our hypothesis test as:</li>
</ul>
<p><span class="math inline">\(H_0: µ_1 \geq µ_2 \space\space\space\space\space vs \space\space\space\space\space H_A: µ_1 &lt; µ_2\)</span></p>
<p>where µ1 is the true mean change in men and µ2 is the true mean change in women</p>
<ul>
<li>Once again, the test statistic remains the same</li>
<li>However the rejection region is now the region below <span class="math inline">\(Q_{0.95} = -1.65\)</span>. Therefore, our test statistic of 1.67 does not lie in the rejection region</li>
<li>This would lead us to conclude we do not have enough evidence to reject the null hypothesis that the mean change in mobility men is less than or equal to that in women</li>
</ul>
</div>
<div id="what-if-our-null-hypothesis-was-one-sided-instead" class="section level3 hasAnchor" number="4.1.34">
<h3><span class="header-section-number">4.1.34</span> What if our null hypothesis was one-sided instead?<a href="lecture-4-inference-for-means-continued.html#what-if-our-null-hypothesis-was-one-sided-instead" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>The p-value for this situation is<br />
P(Test statistic &gt; 1.67| H0)</li>
<li>In R this can be calculated as (1-pt((17.09-12.86)/2.53,233)) = 0.04793956,
which falls below the Type I error level of α=0.05</li>
</ul>
</div>
<div id="why-did-our-conclusion-change-when-we-moved-from-a-two-sided-to-a-one-sided-hypothesis" class="section level3 hasAnchor" number="4.1.35">
<h3><span class="header-section-number">4.1.35</span> Why did our conclusion change when we moved from a two-sided to a one-sided hypothesis?<a href="lecture-4-inference-for-means-continued.html#why-did-our-conclusion-change-when-we-moved-from-a-two-sided-to-a-one-sided-hypothesis" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>The two-sided test is a more stringent test, which makes it more difficult to reject the null hypothesis</li>
<li>Under a two-sided alternative we have to consider the probability of being more extreme than the observed value on both sides of the null</li>
<li>This would be relevant only if we thought that it were possible that the difference <span class="math inline">\(\bar Y_1-\bar Y_2\)</span> could be either positive or negative</li>
<li>If we have reason to believe that men are unlikely to have worse mobility than women, the one-sided test would make more sense in the context of our example</li>
</ul>
</div>
</div>
<div id="hypothesis-testing-vs.-confidence-interval-estimation" class="section level2 hasAnchor" number="4.2">
<h2><span class="header-section-number">4.2</span> Hypothesis testing vs. confidence interval estimation<a href="lecture-4-inference-for-means-continued.html#hypothesis-testing-vs.-confidence-interval-estimation" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="what-is-statistics-1" class="section level3 hasAnchor" number="4.2.1">
<h3><span class="header-section-number">4.2.1</span> What is statistics?<a href="lecture-4-inference-for-means-continued.html#what-is-statistics-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><em>Statistics is a collection of procedures and principles for gathering data and analyzing information in order to help people make decisions when faced with uncertainty</em><br />
<a href="https://www.amazon.ca/Statistical-Methods-Internet-Companion-Statistics/dp/0495122505">Utts &amp; Heckard</a> in ‘Statistical Ideas &amp; Methods’</p>
</div>
<div id="quantifying-uncertainty-vs.-decision-making" class="section level3 hasAnchor" number="4.2.2">
<h3><span class="header-section-number">4.2.2</span> Quantifying uncertainty vs. decision making<a href="lecture-4-inference-for-means-continued.html#quantifying-uncertainty-vs.-decision-making" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>The hypothesis testing framework is designed to support decision making, e.g. 
<ul>
<li>Whether to take an umbrella to work</li>
<li>Whether the observed association between a predictor and an outcome is real</li>
</ul></li>
<li>Confidence interval estimation, on the other hand, conveys the uncertainty in our knowledge about a statistic, e.g.
<ul>
<li>There is a 60%-80% chance it will rain today</li>
<li>The difference in survival associated with treatment A vs. treatment B is 60%-80%</li>
</ul></li>
</ul>
</div>
<div id="interpreting-confidence-intervals-vs.-hypothesis-tests" class="section level3 hasAnchor" number="4.2.3">
<h3><span class="header-section-number">4.2.3</span> Interpreting Confidence Intervals vs. Hypothesis Tests<span class="math inline">\(^*\)</span><a href="lecture-4-inference-for-means-continued.html#interpreting-confidence-intervals-vs.-hypothesis-tests" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>Suppose that you have just calculated a confidence interval for a certain parameter. There are five possible conclusions that can be drawn, depending on where the upper and lower confidence interval limits fall in relation to the upper and lower limits of the region of clinical equivalence.</li>
<li>The region of clinical equivalence, sometimes called the region of indifference, is the region inside of which both treatments would be considered to be the same for all practical purposes.</li>
</ul>
<p><span class="math inline">\(^*\)</span>From Lawrence Joseph’s notes</p>
<div id="interpreting-confidence-intervals-5-possible-conclusions" class="section level4 hasAnchor" number="4.2.3.1">
<h4><span class="header-section-number">4.2.3.1</span> Interpreting confidence intervals: 5 possible conclusions<a href="lecture-4-inference-for-means-continued.html#interpreting-confidence-intervals-5-possible-conclusions" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><img src="4_48.png" width="50%" /></p>
</div>
</div>
<div id="notes-on-significance-tests" class="section level3 hasAnchor" number="4.2.4">
<h3><span class="header-section-number">4.2.4</span> Notes on significance tests<span class="math inline">\(^*\)</span><a href="lecture-4-inference-for-means-continued.html#notes-on-significance-tests" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>We saw that there are two ways of reporting the results of a hypothesis test – either we can report <strong>the decision</strong> (reject vs. not reject which is the same thing as significant vs. not significant) or <strong>the p-value</strong></li>
<li>Reporting the p-value is more informative than merely reporting whether a test was “significant” or “not significant”.</li>
<li>The level of significance, <span class="math inline">\(\alpha\)</span>, is often set to 0.05, but it should be chosen according to the problem. There is nothing magical about <span class="math inline">\(\alpha\)</span> = 0.05. There is no practical difference if p = 0.049 or p = 0.051.</li>
<li>Even a very small p-value does not guarantee <span class="math inline">\(H_0\)</span> is false. Repeating the study is usually necessary for further proof, or to vary the conditions or population.</li>
<li>Statistical significance (small p-value) is not the same as practical significance.</li>
<li>The p-value is not everything. Must also examine your data carefully, data cleaning for outliers, etc. Remember – all tests carry assumptions that can be thrown off by outliers.</li>
<li>Reporting a confidence interval for an effect is more informative than reporting a p-value.</li>
<li>P-values are often misinterpreted. A p-value is not the probability of the null hypothesis.</li>
<li>It is also not the probability that a result occurred by chance. . . .</li>
<li>The p-value only tells you something about the probability of seeing your results given a particular hypothesis—it cannot tell you the probability that the results are true or whether they’re due to random chance.</li>
</ul>
<p><span class="math inline">\(^*\)</span>From Lawrence Joseph’s notes</p>
</div>
</div>
<div id="sample-size-calculations-for-studies-of-one-or-two-means" class="section level2 hasAnchor" number="4.3">
<h2><span class="header-section-number">4.3</span> Sample size calculations for studies of one or two means<a href="lecture-4-inference-for-means-continued.html#sample-size-calculations-for-studies-of-one-or-two-means" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="sample-size-for-hypothesis-tests" class="section level3 hasAnchor" number="4.3.1">
<h3><span class="header-section-number">4.3.1</span> Sample size for hypothesis tests<a href="lecture-4-inference-for-means-continued.html#sample-size-for-hypothesis-tests" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>This approach is relevant when we want to test a certain hypothesis</li>
<li>For example, we might want to test
<ul>
<li><p><span class="math inline">\(H_0\)</span>: mean change in stroke mobility ≤ 10 points vs.<br />
</p></li>
<li><p><span class="math inline">\(H_a\)</span>: mean change in stroke mobility &gt; 10 points</p></li>
<li><p><span class="math inline">\(H_0\)</span>: mean serum cholesterol ≤ 200 vs.</p></li>
<li><p><span class="math inline">\(H_a\)</span>: mean serum cholesterol &gt; 200</p></li>
</ul></li>
</ul>
</div>
<div id="example" class="section level3 hasAnchor" number="4.3.2">
<h3><span class="header-section-number">4.3.2</span> Example<a href="lecture-4-inference-for-means-continued.html#example" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>In the United States, appropriate levels of serum cholesterol in adults have been defined by the National Heart, Lung, and Blood Institute as follows:
<ul>
<li><strong>Good:</strong> 200 mg/dL or lower</li>
<li><strong>Borderline:</strong> 200 to 239 mg/dL</li>
<li><strong>High:</strong> 240 mg/dL or higher</li>
</ul></li>
<li>Let’s say the researcher in our earlier example posed the question differently.</li>
<li>He or she wants to test the hypothesis that the mean cholesterol level in the population has fallen to 195 mg/dL such that it is now within the “Good” range</li>
</ul>
<p><span class="math display">\[H_0: µ ≤ 195\space\space vs.\space H_a: µ &gt; 195\]</span></p>
<ul>
<li>How large a sample size is required to test this hypothesis such that
<ul>
<li>Type I error (α)= <span class="math inline">\(P(Rejecting\space H_0 | H_0\space is\space true)\)</span> = 1%, and</li>
<li>Type II error (β)= <span class="math inline">\(P(Not\space rejecting\space H_0 | H_A\space is\space true)\)</span> = 5%</li>
</ul></li>
<li>The researcher wishes to design the study such that the test is sufficiently sensitive to detect difference of 6 mg/dL or more (i.e. when µ=201 or more)</li>
</ul>
</div>
<div id="we-are-interested-in-detecting-a-shift-in-the-mean-of-the-distribution" class="section level3 hasAnchor" number="4.3.3">
<h3><span class="header-section-number">4.3.3</span> We are interested in detecting a shift in the mean of the distribution<a href="lecture-4-inference-for-means-continued.html#we-are-interested-in-detecting-a-shift-in-the-mean-of-the-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><img src="4_55.png" width="50%" /></p>
</div>
<div id="sample-size-required-for-a-hypothesis-test-of-a-single-mean" class="section level3 hasAnchor" number="4.3.4">
<h3><span class="header-section-number">4.3.4</span> Sample size required for a hypothesis test of a single mean<a href="lecture-4-inference-for-means-continued.html#sample-size-required-for-a-hypothesis-test-of-a-single-mean" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>Again, we rely on the quantiles of the normal distribution rather than the t-distribution</li>
<li>The required sample size for a two-sided test is given by this expression:</li>
</ul>
<p><span class="math display">\[n = \frac{s^2(Z_{1-\alpha/2}+Z_{1-\beta})^2}{(\mu_0-\mu_A)^2}\]</span></p>
<ul>
<li>The required sample size for a one-sided test is given by this expression:</li>
</ul>
<p><span class="math display">\[n = \frac{s^2(Z_{1-\alpha}+Z_{1-\beta})^2}{(\mu_0-\mu_A)^2}\]</span></p>
<ul>
<li>From the expressions on the previous slide we can see that n increases as:
<ul>
<li>s increases</li>
<li>α decreases or β decreases</li>
<li><span class="math inline">\(\mu_0-\mu_A\)</span> decreases</li>
</ul></li>
<li>Once again, you may wish to calculate sample size under several different scenarios</li>
</ul>
</div>
<div id="sample-size-required-under-different-scenarios" class="section level3 hasAnchor" number="4.3.5">
<h3><span class="header-section-number">4.3.5</span> Sample size required under different scenarios<a href="lecture-4-inference-for-means-continued.html#sample-size-required-under-different-scenarios" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><img src="4_58.png" width="100%" /></p>
</div>
<div id="example-serum-cholesterol" class="section level3 hasAnchor" number="4.3.6">
<h3><span class="header-section-number">4.3.6</span> Example: Serum cholesterol<a href="lecture-4-inference-for-means-continued.html#example-serum-cholesterol" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>The sample size required for a one-sided test is</li>
</ul>
<p><span class="math display">\[n = \frac{s^2(Z_{1-0.01}+Z_{1-0.05})^2}{(\mu_0-\mu_A)^2}=\frac{40^2(2.33+1.65)^2}{(195-201)^2}=704\]</span></p>
<ul>
<li><strong>Impact of increasing α to 0.05:</strong>
<ul>
<li>If the type I error was increased to 0.05, we would replace <span class="math inline">\(Z_{1-0.01} = 2.33\)</span> by <span class="math inline">\(Z_{1-0.05} = 1.65\)</span>.</li>
<li><span class="math inline">\(n = \frac{s^2(Z_{1-0.05}+Z_{1-0.05})^2}{(\mu_0-\mu_A)^2}=\frac{40^2(1.65+1.65)^2}{(195-201)^2}=484\)</span></li>
</ul></li>
<li><strong>Impact of increasing β:</strong>
<ul>
<li>If in addition to the above change, the type II error was increased to 0.2, as is commonly done in practice. Then, <span class="math inline">\(Z_{1-0.2} = 1.65\)</span> in the expression above would be replace by <span class="math inline">\(Z_{1-0.2} = 0.84\)</span></li>
<li><span class="math inline">\(n = \frac{s^2(Z_{1-0.01}+Z_{1-0.2})^2}{(\mu_0-\mu_A)^2}=\frac{40^2(1.65+0.84)^2}{(195-201)^2}=276\)</span></li>
</ul></li>
<li><strong>Impact of increasing <span class="math inline">\(\mu_0-\mu_A\)</span></strong>
<ul>
<li>If <span class="math inline">\(µ_0\)</span> were set to 190, then the difference between the two groups increases to 11</li>
<li><span class="math inline">\(n = \frac{s^2(Z_{1-0.01}+Z_{1-0.05})^2}{(\mu_0-\mu_A)^2}=\frac{40^2(1.65+0.84)^2}{(190-201)^2}=82\)</span></li>
</ul></li>
</ul>
</div>
<div id="summary-what-do-you-need-to-calculate-the-sample-size-required" class="section level3 hasAnchor" number="4.3.7">
<h3><span class="header-section-number">4.3.7</span> Summary: What do you need to calculate the sample size required?<a href="lecture-4-inference-for-means-continued.html#summary-what-do-you-need-to-calculate-the-sample-size-required" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<table>
<thead>
<tr>
<th style="text-align:left;">
Confidence interval
</th>
<th style="text-align:left;">
Hypothesis test
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Confidence level 1-α
</td>
<td style="text-align:left;">
Type I error α
</td>
</tr>
<tr>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
Type II error β
</td>
</tr>
<tr>
<td style="text-align:left;">
Guess value for standard deviation (s)
</td>
<td style="text-align:left;">
Guess value for standard deviation (s)
</td>
</tr>
<tr>
<td style="text-align:left;">
Desired precision (or half-width of interval) (δ)
</td>
<td style="text-align:left;">
The minimum important difference to detect <span class="math inline">\((\mu_0-\mu_A)\)</span>
</td>
</tr>
</tbody>
</table>
</div>
<div id="sample-size-calculation-comparing-two-means" class="section level3 hasAnchor" number="4.3.8">
<h3><span class="header-section-number">4.3.8</span> Sample size calculation: Comparing two means<a href="lecture-4-inference-for-means-continued.html#sample-size-calculation-comparing-two-means" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>Once again, we can define different methods depending on whether we plan to report confidence intervals or hypothesis tests</li>
</ul>
</div>
<div id="example-2" class="section level3 hasAnchor" number="4.3.9">
<h3><span class="header-section-number">4.3.9</span> Example<a href="lecture-4-inference-for-means-continued.html#example-2" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p>Consider the study on in-vivo efficacy of the single domain antibody P1.40 in Tg+ mice</p></li>
<li><p>Lets say we wish to repeat the earlier randomized controlled trial.</p></li>
<li><p>The authors reported that the mean change in cholesterol at 4 days after the intervention was 20 mg/dL and I guessed that the <strong>pooled</strong> standard deviation of the difference was <span class="math inline">\(s_p\)</span>=9 mg/dL</p></li>
<li><p>We desire to ensure that the observed mean change lies within δ = ±5 mg/dL of the true mean change with 95% confidence.</p></li>
<li><p>What is the sample size required in each arm of the RCT (assuming the sample size is equal in both arms)?</p></li>
<li><p>Alternatively, we may wish to carry out a one-sided hypothesis test of the difference between the two groups</p></li>
</ul>
<p><span class="math display">\[H_0: µ_{P1.40} - µ_{PBS} ≤ 0\space vs. H_a:  µ_{P1.40} - µ_{PBS} &gt; 0\]</span></p>
<ul>
<li>Recall, that the previous study reported that the mean change in cholesterol at 4 days after the intervention was 20 mg/dL and that the standard deviation was assumed to be <span class="math inline">\(s_p\)</span>=9 mg/dL</li>
<li>We desire to ensure that the test is sensitive enough to detect a difference greater than <span class="math inline">\(µ_1 - µ_2 =15\)</span> mg/dL with Type II error = 20%. The Type I error is fixed at the traditional value of 5%.</li>
<li>What is the sample size required in each arm of the RCT (assuming the sample size is equal in both arms)?</li>
</ul>
</div>
<div id="sample-size-required-to-test-h_0mu_1mu_2" class="section level3 hasAnchor" number="4.3.10">
<h3><span class="header-section-number">4.3.10</span> Sample size required to test <span class="math inline">\(H_0:\mu_1=\mu_2\)</span><a href="lecture-4-inference-for-means-continued.html#sample-size-required-to-test-h_0mu_1mu_2" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>In the expressions below n = total sample size. If the sample size is the same in both groups, it is n/2 in each group</li>
<li>The required sample size for a two-sided test is given by this expression:</li>
</ul>
<p><span class="math display">\[n = \frac{4s_p^2(Z_{1-\alpha/2}+Z_{1-\beta})^2}{(\mu_1-\mu_2)^2}\]</span></p>
<ul>
<li>The required sample size for a one-sided test is given by this expression:</li>
</ul>
<p><span class="math display">\[n = \frac{4s_p^2(Z_{1-\alpha}+Z_{1-\beta})^2}{(\mu_1-\mu_2)^2}\]</span></p>
</div>
<div id="example-in-vivo-efficacy-of-p1.40" class="section level3 hasAnchor" number="4.3.11">
<h3><span class="header-section-number">4.3.11</span> Example: In-vivo efficacy of P1.40<a href="lecture-4-inference-for-means-continued.html#example-in-vivo-efficacy-of-p1.40" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>The sample size required for a one-sided test is</li>
</ul>
<dl>
<dt><span class="math display">\[n = \frac{4s_p^2(Z_{1-0.05}+Z_{1-0.2})^2}{(\mu_1-\mu_2)^2}=\frac{4\times 9^2(1.65+0.84)^2}{(15)^2}\]</span></dt>
<dd>
<p><strong>80 mice (or 40 mice in each group)</strong></p>
</dd>
</dl>
<ul>
<li>If the standard deviation was 4 mg /dL instead, then</li>
</ul>
<dl>
<dt><span class="math display">\[n = \frac{4s_p^2(Z_{1-0.05}+Z_{1-0.2})^2}{(\mu_1-\mu_2)^2}=\frac{4\times 4^2(1.65+0.84)^2}{(15)^2}\]</span></dt>
<dd>
<p><strong>16 (or 8 mice in each group)</strong></p>
</dd>
</dl>
<ul>
<li>If we used a calculation for a two-sided test instead (with the standard deviation of 9), then</li>
</ul>
<dl>
<dt><span class="math display">\[n = \frac{4s_p^2(Z_{1-0.05}+Z_{1-0.2})^2}{(\mu_1-\mu_2)^2}=\frac{4\times 9^2(1.96+0.84)^2}{(15)^2}\]</span></dt>
<dd>
<p><strong>102 (or 51 mice per group)</strong></p>
</dd>
</dl>
</div>
<div id="power" class="section level3 hasAnchor" number="4.3.12">
<h3><span class="header-section-number">4.3.12</span> Power<a href="lecture-4-inference-for-means-continued.html#power" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>The expressions for sample size can be rearranged to calculate the power for a given sample size</li>
<li>For a single mean</li>
</ul>
<p><span class="math display">\[Z_{1-\beta}=\frac{\sqrt N|\mu_0-\mu_A|-s\times z_{1-\alpha/2}}{s}\]</span></p>
<ul>
<li>For comparing two means</li>
</ul>
<p><span class="math display">\[Z_{1-\beta}=\frac{\sqrt N|\mu_1-\mu_2|-2s_pz_{1-\alpha/2}}{2s_p}\]</span></p>
</div>
<div id="calculating-the-power-in-r" class="section level3 hasAnchor" number="4.3.13">
<h3><span class="header-section-number">4.3.13</span> Calculating the power in R<a href="lecture-4-inference-for-means-continued.html#calculating-the-power-in-r" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<pre><code>power.t.test(n = NULL, delta = NULL, sd = 1, sig.level = 0.05,
             power = NULL,
             type = c(&quot;two.sample&quot;, &quot;one.sample&quot;, &quot;paired&quot;),
             alternative = c(&quot;two.sided&quot;, &quot;one.sided&quot;),
             strict = FALSE)</code></pre>
<ul>
<li>The power.t.test function can be used to either take the sample size in each group (n) as an input and return the power, or vice-versa</li>
<li>Whereas the expressions we studied so far were based on normal quantiles, this R function uses the t-distribution quantiles and should therefore provide a more precise answer</li>
</ul>
</div>
<div id="example-power-function" class="section level3 hasAnchor" number="4.3.14">
<h3><span class="header-section-number">4.3.14</span> Example: Power function<a href="lecture-4-inference-for-means-continued.html#example-power-function" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p>A proposed study wishes to investigate the effects of a new hypertensive drug (experimental group) compared to a conventional treatment (control group).</p></li>
<li><p>The outcome of interest is the difference in the mean blood pressure in each group. Previous studies show that the pooled standard deviation (SD) across the two groups is 20mmHg</p></li>
<li><p>Assuming that the desired Type I error is 5% and that the feasible sample size is 25 in each group, and that the minimum clinically important difference is 15mmHg.</p></li>
<li><p>What is the power of a two-sided test to detect the minimum important difference? Plot the function relating the difference between the two groups to the power of the test</p></li>
<li><p>First, we will calculate the power using the expression in your notes</p></li>
<li><p>Then we will use the power.t.test function to plot the power function</p></li>
<li><p>Using the expression for calculating the normal distribution quantile corresponding to the power we have</p></li>
</ul>
<p><span class="math display">\[Z_{1-\beta}=\frac{\sqrt N|\mu_1-\mu_2|-2s_pz_{1-\alpha/2}}{2s_p}=\frac{\sqrt{50}|15|-2\times 20\times 1.96}{2\times 20}=0.6916504\]</span></p>
<ul>
<li>The power of the test is given by<br />
<span class="math inline">\(P(Z\leq Z_{1-\beta})\)</span> = pnorm(0.6916504) = 0.754216</li>
<li>Using the function in R instead we would obtain the following result</li>
</ul>
<pre><code>power.t.test(n = 25, delta = 15, sd = 20, sig.level = 0.05)
= 0.7383646</code></pre>
<p>which is slightly lower than the result based on the approximation using the normal quantile
* To find the power for a series of different values for the minimum difference we can use the following R code (<span style="color: red;">in red</span>)</p>
<p><span class="math inline">\(\#\)</span> a vector of possible values for the difference<br />
<span style="color: red;">min.diff = c(5, 10, 15, 20, 25)</span></p>
<p><span class="math inline">\(\#\)</span> create an object for the result of the power function<br />
<span style="color: red;">result = power.t.test(n = 25, delta = min.diff, sd = 20, sig.level = 0.05)</span></p>
<p><span style="color: red;">names(result)</span> # to examine the contents of the object<br />
[1] “n” “delta” “sd” “sig.level” “power”<br />
[6] “alternative” “note” “method”</p>
<p><span style="color: red;">output=result$power</span> # create another object to extract the power</p>
<p><span class="math inline">\(\#\)</span> scatter and line plot<br />
<span style="color: red;">plot(min.diff,output,type=“b”,xlab=“Difference between group means”,ylab=“Power”)</span></p>
<p><span class="math inline">\(\#\)</span> red reference line at Power=80%<br />
<span style="color: red;">abline(h=0.8,col=2)</span></p>
<p>Notice that with 25 patients in each group, we would have 80% or higher power to detect differences greater than about 17mmHg</p>
<p><img src="4_73.png" width="70%" /></p>
</div>
<div id="what-is-the-impact-of-equal-or-unequal-group-sizes-on-the-precision" class="section level3 hasAnchor" number="4.3.15">
<h3><span class="header-section-number">4.3.15</span> What is the impact of equal or unequal group sizes on the precision?<a href="lecture-4-inference-for-means-continued.html#what-is-the-impact-of-equal-or-unequal-group-sizes-on-the-precision" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>If we write the standard error of an estimated difference in mean responses as <span class="math inline">\(\sigma\sqrt{\frac{1}{n_1}+\frac{1}{n_2}}\)</span> where <span class="math inline">\(\sigma\)</span> is the standard deviation and n1 and n2 are the sample size in each group, then we can establish the following principles (which would apply to both means and proportions:
<ul>
<li><strong>If costs and other factors (including unit variability) are equal, and if both types of units are equally scarce or equally plentiful</strong>, then for a given total sample size of <span class="math inline">\(n = n_1 + n_2\)</span> , an equal division of n i.e. <span class="math inline">\(n_1 = n_2\)</span> is preferable since it yields a smaller standard error than any non-symmetric division.</li>
<li><strong>If one type of unit is much scarcer, and thus the limiting factor</strong>, then it makes sense to choose all (say <span class="math inline">\(n_1\)</span>) of the available scarcer units, and some <span class="math inline">\(n_2 \geq n_1\)</span> of the other type. The greater is <span class="math inline">\(n_2\)</span>, the smaller the standard error of the estimated difference.</li>
</ul></li>
</ul>
<div id="effect-of-different-numbers-in-each-sample-on-precision-when-both-groups-are-equally-difficult-to-sample-from" class="section level4 hasAnchor" number="4.3.15.1">
<h4><span class="header-section-number">4.3.15.1</span> Effect of different numbers in each sample on precision, when both groups are equally difficult to sample from<a href="lecture-4-inference-for-means-continued.html#effect-of-different-numbers-in-each-sample-on-precision-when-both-groups-are-equally-difficult-to-sample-from" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The following table gives the value of the standard error (SE) for various combinations of <span class="math inline">\(n_1\)</span> and <span class="math inline">\(n_2\)</span> adding to 100 and assuming <span class="math inline">\(\sigma = 1\)</span> (the values of <span class="math inline">\(n_1 + n_2 =100\)</span> and <span class="math inline">\(\sigma = 1\)</span> also arbitrary). Notice that, the standard error is relatively unaffected until the ratio exceeds 70:30.</p>
<p><img src="4_75.png" width="50%" /></p>
<p><span class="math inline">\(^*\)</span>if sample sizes are <span class="math inline">\(\pi:(1-\pi)\)</span>, the % increase is <span class="math inline">\(50/\sqrt{\pi(1-\pi)}\)</span></p>
</div>
<div id="effect-of-different-numbers-in-each-sample-on-precision-when-group-1-is-more-scarce-than-group-2" class="section level4 hasAnchor" number="4.3.15.2">
<h4><span class="header-section-number">4.3.15.2</span> Effect of different numbers in each sample on precision, when group 1 is more scarce than group 2<a href="lecture-4-inference-for-means-continued.html#effect-of-different-numbers-in-each-sample-on-precision-when-group-1-is-more-scarce-than-group-2" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>There is a ‘law of diminishing returns’ once <span class="math inline">\(n_2\)</span> is more than a few multiples of <span class="math inline">\(n_1\)</span> as seen in the following table where <span class="math inline">\(n_1\)</span> is fixed (arbitrarily) at 100 and <span class="math inline">\(n_2\)</span> ranges from <span class="math inline">\(kn=1 \times n_1\)</span> to <span class="math inline">\(kn=100 \times n_1\)</span>; again, we assume <span class="math inline">\(\sigma=1\)</span>.</p>
<p><img src="4_76.png" width="100%" /></p>
</div>
</div>
<div id="an-r-package-for-sample-size-and-power-calculations" class="section level3 hasAnchor" number="4.3.16">
<h3><span class="header-section-number">4.3.16</span> An R package for sample size and power calculations<a href="lecture-4-inference-for-means-continued.html#an-r-package-for-sample-size-and-power-calculations" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>There are a number of user-contributed packages that can be added to R</li>
<li>Once such package is the pwr package that includes functions for calculating the sample size required for a hypothesis test when the two groups being compared have unequal sample size</li>
</ul>
</div>
<div id="installing-a-package-in-r" class="section level3 hasAnchor" number="4.3.17">
<h3><span class="header-section-number">4.3.17</span> Installing a package in R<a href="lecture-4-inference-for-means-continued.html#installing-a-package-in-r" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>User-contributed packages are not part of the base R installation. They need to be installed with the install.packages() function and then read into R with the library() function as below:</p>
<blockquote>
<p>install.packages(“pwr”)
library(pwr)
help(package=“pwr”)</p>
</blockquote>
</div>
<div id="sample-size-for-comparing-two-means" class="section level3 hasAnchor" number="4.3.18">
<h3><span class="header-section-number">4.3.18</span> Sample size for comparing two means<a href="lecture-4-inference-for-means-continued.html#sample-size-for-comparing-two-means" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The function pwr.t2n.test() can be used</p>
<pre><code>pwr.t2n.test(n1 = NULL, n2= NULL, d = NULL, sig.level = 0.05, power = NULL,  
 alternative = c(&quot;two.sided&quot;, &quot;less&quot;,&quot;greater&quot;))</code></pre>
<p>Notice that it takes the effect size <span class="math inline">\(d=\frac{|\mu_1-\mu_2|}{s_p}\)</span> as an argument, whereas the power.t.test() function we saw earlier takes arguments delta and sd instead</p>
<p>This function can be used to calculate either the power or the sample size</p>
<div id="example-1-2" class="section level4 hasAnchor" number="4.3.18.1">
<h4><span class="header-section-number">4.3.18.1</span> Example 1:<a href="lecture-4-inference-for-means-continued.html#example-1-2" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Calculate the sample size in group 2 when:<br />
effect size=15/20=0.75, Type I error=0.05, Power=0.8, and feasible sample size in group 1 is 25</p>
<blockquote>
<p>pwr.t2n.test(n1=25,d=0.75,power=0.8)</p>
</blockquote>
<pre><code> t test power calculation 

         n1 = 25
         n2 = 34.17153
          d = 0.75
  sig.level = 0.05
      power = 0.8
alternative = two.sided</code></pre>
</div>
<div id="example-2-1" class="section level4 hasAnchor" number="4.3.18.2">
<h4><span class="header-section-number">4.3.18.2</span> Example 2:<a href="lecture-4-inference-for-means-continued.html#example-2-1" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Calculate the power available when:<br />
effect size=15/20=0.75, Type I error=0.05, Sample size = 25 in both groups</p>
<p>Notice we now have the same result we obtained previously with power.t.test</p>
<blockquote>
<p>pwr.t2n.test(n1=25,n2=25,d=0.75)</p>
</blockquote>
<pre><code> t test power calculation 

        n1 = 25
        n2 = 25
        d = 0.75
        sig.level = 0.05
        power = 0.7383671
        alternative = two.sided</code></pre>
</div>
</div>
</div>
<div id="extra-problems" class="section level2 hasAnchor" number="4.4">
<h2><span class="header-section-number">4.4</span> Extra Problems<a href="lecture-4-inference-for-means-continued.html#extra-problems" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="section" class="section level3 hasAnchor" number="4.4.1">
<h3><span class="header-section-number">4.4.1</span> 1.<a href="lecture-4-inference-for-means-continued.html#section" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>During a weight loss study, each of nine subjects was given (1) the active drug m-chlorophenylpiperazine (mCPP) for 2 weeks and then a placebo for another 2 weeks, or (2) the placebo for the first 2 weeks and then mCPP for the second 2 weeks. The following table shows the amount of weight loss (kg) for the nine subjects when taking the drug mCPP and when taking placebo (Note that if a subject gained weight, then the recorded weight loss is negative, as is the case for the subject 2, who gained 0.3 kg when on the placebo.) Use a t-test to investigate the claim that mCPP affects weight loss. Let <span class="math inline">\(H_A\)</span> be non-directional, and let α=0.01.</p>
<table class="table table-striped" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="empty-cells: hide;border-bottom:hidden;" colspan="1">
</th>
<th style="border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="2">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
Weight Change (kg)
</div>
</th>
<th style="empty-cells: hide;border-bottom:hidden;" colspan="1">
</th>
</tr>
<tr>
<th style="text-align:left;">
Subject
</th>
<th style="text-align:right;">
mcPP
</th>
<th style="text-align:right;">
Placebo
</th>
<th style="text-align:right;">
Difference in kg
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
1
</td>
<td style="text-align:right;">
1.10
</td>
<td style="text-align:right;">
0.00
</td>
<td style="text-align:right;">
1.10
</td>
</tr>
<tr>
<td style="text-align:left;">
2
</td>
<td style="text-align:right;">
1.30
</td>
<td style="text-align:right;">
-0.30
</td>
<td style="text-align:right;">
1.60
</td>
</tr>
<tr>
<td style="text-align:left;">
3
</td>
<td style="text-align:right;">
1.00
</td>
<td style="text-align:right;">
0.60
</td>
<td style="text-align:right;">
0.40
</td>
</tr>
<tr>
<td style="text-align:left;">
4
</td>
<td style="text-align:right;">
1.70
</td>
<td style="text-align:right;">
0.30
</td>
<td style="text-align:right;">
1.40
</td>
</tr>
<tr>
<td style="text-align:left;">
5
</td>
<td style="text-align:right;">
1.40
</td>
<td style="text-align:right;">
-0.70
</td>
<td style="text-align:right;">
2.10
</td>
</tr>
<tr>
<td style="text-align:left;">
6
</td>
<td style="text-align:right;">
0.10
</td>
<td style="text-align:right;">
-0.20
</td>
<td style="text-align:right;">
0.30
</td>
</tr>
<tr>
<td style="text-align:left;">
7
</td>
<td style="text-align:right;">
0.50
</td>
<td style="text-align:right;">
0.60
</td>
<td style="text-align:right;">
-0.10
</td>
</tr>
<tr>
<td style="text-align:left;">
8
</td>
<td style="text-align:right;">
1.60
</td>
<td style="text-align:right;">
0.90
</td>
<td style="text-align:right;">
0.70
</td>
</tr>
<tr>
<td style="text-align:left;">
9
</td>
<td style="text-align:right;">
-0.50
</td>
<td style="text-align:right;">
-2.00
</td>
<td style="text-align:right;">
1.50
</td>
</tr>
<tr>
<td style="text-align:left;">
Mean
</td>
<td style="text-align:right;">
0.91
</td>
<td style="text-align:right;">
-0.09
</td>
<td style="text-align:right;">
1.00
</td>
</tr>
<tr>
<td style="text-align:left;">
SD
</td>
<td style="text-align:right;">
0.74
</td>
<td style="text-align:right;">
0.88
</td>
<td style="text-align:right;">
0.72
</td>
</tr>
</tbody>
</table>
<ol style="list-style-type: lower-alpha">
<li>What is the value of the t-test statistic for assessing whether weight change when taking mCPP is different from a placebo?<br />
</li>
<li>In the context of this study, state the null and alternative hypotheses.<br />
</li>
<li>The p-value for the t-test is 0.003. If α=0.10, what is your conclusion regarding the hypothesis in (b)?<br />
</li>
<li>Construct a 99% confidence interval for the mean difference.<br />
</li>
<li>Assume that a 1kg difference in weight loss between the two regimens is considered important. Interpret the confidence interval in the context of this assumption.</li>
</ol>
</div>
<div id="section-1" class="section level3 hasAnchor" number="4.4.2">
<h3><span class="header-section-number">4.4.2</span> 2.<a href="lecture-4-inference-for-means-continued.html#section-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>A study was undertaken to compare the respiratory responses of hypnotized and non-hypnotized subjects to certain instructions. The 16 male volunteers were allocated at random to an experimental group to be hypnotized or to a control group. Baseline measurements were taken at the start of the experiment. In analyzing the data, the baseline breathing patterns of the two groups were different; this was surprising, since all the subjects had been treated the same up to that time. One explanation proposed for this unexpected difference was that the experimental group were more excited in anticipation of the experience of being hypnotized. The accompanying table presents a summary of the baseline measurements of total ventilation (liters of air per minute per square meter of body area).</p>
<table>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
Experimental
</th>
<th style="text-align:right;">
Control
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
1
</td>
<td style="text-align:right;">
5.320
</td>
<td style="text-align:right;">
4.500
</td>
</tr>
<tr>
<td style="text-align:left;">
2
</td>
<td style="text-align:right;">
5.600
</td>
<td style="text-align:right;">
4.780
</td>
</tr>
<tr>
<td style="text-align:left;">
3
</td>
<td style="text-align:right;">
5.740
</td>
<td style="text-align:right;">
4.790
</td>
</tr>
<tr>
<td style="text-align:left;">
4
</td>
<td style="text-align:right;">
6.060
</td>
<td style="text-align:right;">
4.860
</td>
</tr>
<tr>
<td style="text-align:left;">
5
</td>
<td style="text-align:right;">
6.320
</td>
<td style="text-align:right;">
5.410
</td>
</tr>
<tr>
<td style="text-align:left;">
6
</td>
<td style="text-align:right;">
6.340
</td>
<td style="text-align:right;">
5.700
</td>
</tr>
<tr>
<td style="text-align:left;">
7
</td>
<td style="text-align:right;">
6.790
</td>
<td style="text-align:right;">
6.080
</td>
</tr>
<tr>
<td style="text-align:left;">
8
</td>
<td style="text-align:right;">
7.180
</td>
<td style="text-align:right;">
6.210
</td>
</tr>
<tr>
<td style="text-align:left;">
N
</td>
<td style="text-align:right;">
8.000
</td>
<td style="text-align:right;">
8.000
</td>
</tr>
<tr>
<td style="text-align:left;">
Mean
</td>
<td style="text-align:right;">
6.169
</td>
<td style="text-align:right;">
5.291
</td>
</tr>
<tr>
<td style="text-align:left;">
SD
</td>
<td style="text-align:right;">
0.621
</td>
<td style="text-align:right;">
0.652
</td>
</tr>
</tbody>
</table>
<ol style="list-style-type: lower-alpha">
<li>Create a dotplot to illustrate the distribution of observations in the two groups.<br />
</li>
<li>Use a t-test to test the hypothesis of no difference against a non-directional alternative. Let α=0.05<br />
</li>
<li>Use a t-test to test the hypothesis of no difference against the alternative that the experimental conditions produce a larger mean than the control conditions. Let α=0.05.<br />
</li>
<li>Which of the two tests ((b) or (c)) is more appropriate? Explain</li>
</ol>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="lecture-3-central-limit-theorem-and-inference-for-means.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="lecture-5-sample-size-calculations-to-plan-for-hypothesis-tests-of-means.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/USERNAME/REPO/edit/BRANCH/Lecture_4.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["_main.pdf", "_main.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
