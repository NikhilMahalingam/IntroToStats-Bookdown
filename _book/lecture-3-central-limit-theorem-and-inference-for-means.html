<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>3 Lecture 3: Central Limit Theorem and Inference for Means | Intro to Statistics Notes</title>
  <meta name="description" content="Intro to Stats notes for Nandini Dendukuri - Nikhil Mahalingam" />
  <meta name="generator" content="bookdown 0.28 and GitBook 2.6.7" />

  <meta property="og:title" content="3 Lecture 3: Central Limit Theorem and Inference for Means | Intro to Statistics Notes" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Intro to Stats notes for Nandini Dendukuri - Nikhil Mahalingam" />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="3 Lecture 3: Central Limit Theorem and Inference for Means | Intro to Statistics Notes" />
  
  <meta name="twitter:description" content="Intro to Stats notes for Nandini Dendukuri - Nikhil Mahalingam" />
  




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="lecture-2-types-of-variables-probability-and-probability-distributions.html"/>
<link rel="next" href="lecture-4-inference-for-means-continued.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
<link href="libs/bsTable-3.3.7/bootstrapTable.min.css" rel="stylesheet" />
<script src="libs/bsTable-3.3.7/bootstrapTable.js"></script>




<link rel="stylesheet" href="Styling/ims-style.css" type="text/css" />
<link rel="stylesheet" href="Styling/bs4_style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Intro to Statistics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Schedule</a></li>
<li class="chapter" data-level="" data-path="course-details.html"><a href="course-details.html"><i class="fa fa-check"></i>Course Details</a>
<ul>
<li class="chapter" data-level="" data-path="course-details.html"><a href="course-details.html#project"><i class="fa fa-check"></i>Project</a></li>
<li class="chapter" data-level="" data-path="course-details.html"><a href="course-details.html#suggested-references"><i class="fa fa-check"></i>Suggested References</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="lecture-1.html"><a href="lecture-1.html"><i class="fa fa-check"></i><b>1</b> Lecture 1</a>
<ul>
<li class="chapter" data-level="1.1" data-path="lecture-1.html"><a href="lecture-1.html#introduction"><i class="fa fa-check"></i><b>1.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="lecture-1.html"><a href="lecture-1.html#what-is-statistics"><i class="fa fa-check"></i><b>1.1.1</b> What is Statistics?</a></li>
<li class="chapter" data-level="1.1.2" data-path="lecture-1.html"><a href="lecture-1.html#a-motivating-example"><i class="fa fa-check"></i><b>1.1.2</b> A Motivating Example</a></li>
<li class="chapter" data-level="1.1.3" data-path="lecture-1.html"><a href="lecture-1.html#what-was-the-evidence-behind-this-optimistic-headline"><i class="fa fa-check"></i><b>1.1.3</b> What was the evidence behind this optimistic headline?</a></li>
<li class="chapter" data-level="1.1.4" data-path="lecture-1.html"><a href="lecture-1.html#what-would-a-data-detective-ask"><i class="fa fa-check"></i><b>1.1.4</b> What would a data detective ask?</a></li>
<li class="chapter" data-level="1.1.5" data-path="lecture-1.html"><a href="lecture-1.html#results-reported-in-the-study"><i class="fa fa-check"></i><b>1.1.5</b> Results reported in the study</a></li>
<li class="chapter" data-level="1.1.6" data-path="lecture-1.html"><a href="lecture-1.html#evaluating-the-quality-of-the-statistical-methods"><i class="fa fa-check"></i><b>1.1.6</b> Evaluating the quality of the statistical methods</a></li>
<li class="chapter" data-level="1.1.7" data-path="lecture-1.html"><a href="lecture-1.html#what-if-the-sample-size-were-smaller"><i class="fa fa-check"></i><b>1.1.7</b> What if the sample size were smaller?</a></li>
<li class="chapter" data-level="1.1.8" data-path="lecture-1.html"><a href="lecture-1.html#what-if-the-sample-size-were-larger"><i class="fa fa-check"></i><b>1.1.8</b> What if the sample size were larger?</a></li>
<li class="chapter" data-level="1.1.9" data-path="lecture-1.html"><a href="lecture-1.html#sample-size-and-precision"><i class="fa fa-check"></i><b>1.1.9</b> Sample Size and Precision</a></li>
<li class="chapter" data-level="1.1.10" data-path="lecture-1.html"><a href="lecture-1.html#evaluating-the-quality-of-the-statistical-methods-1"><i class="fa fa-check"></i><b>1.1.10</b> Evaluating the quality of the statistical methods</a></li>
<li class="chapter" data-level="1.1.11" data-path="lecture-1.html"><a href="lecture-1.html#evaluating-the-quality-of-the-study-design"><i class="fa fa-check"></i><b>1.1.11</b> Evaluating the quality of the study design</a></li>
<li class="chapter" data-level="1.1.12" data-path="lecture-1.html"><a href="lecture-1.html#the-role-of-external-or-prior-information"><i class="fa fa-check"></i><b>1.1.12</b> The role of external (or prior) information</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="lecture-1.html"><a href="lecture-1.html#reducing-bias-in-research-studies"><i class="fa fa-check"></i><b>1.2</b> Reducing Bias in Research Studies</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="lecture-1.html"><a href="lecture-1.html#bias-vs.-precision"><i class="fa fa-check"></i><b>1.2.1</b> Bias vs.Â Precision</a></li>
<li class="chapter" data-level="1.2.2" data-path="lecture-1.html"><a href="lecture-1.html#common-study-designs-used-in-clinical-research"><i class="fa fa-check"></i><b>1.2.2</b> Common study designs used in clinical research</a></li>
<li class="chapter" data-level="1.2.3" data-path="lecture-1.html"><a href="lecture-1.html#randomized-controlled-trial"><i class="fa fa-check"></i><b>1.2.3</b> Randomized Controlled Trial</a></li>
<li class="chapter" data-level="1.2.4" data-path="lecture-1.html"><a href="lecture-1.html#reducing-bias-in-research-studies-1"><i class="fa fa-check"></i><b>1.2.4</b> Reducing bias in research studies</a></li>
<li class="chapter" data-level="1.2.5" data-path="lecture-1.html"><a href="lecture-1.html#a-second-motivating-example-renal-denervation"><i class="fa fa-check"></i><b>1.2.5</b> A second motivating example: Renal Denervation</a></li>
<li class="chapter" data-level="1.2.6" data-path="lecture-1.html"><a href="lecture-1.html#example-4a-results-from-a-cohort-study-of-renal-denervation"><i class="fa fa-check"></i><b>1.2.6</b> Example 4a: Results from a cohort study of renal denervation<span class="math inline">\(^*\)</span></a></li>
<li class="chapter" data-level="1.2.7" data-path="lecture-1.html"><a href="lecture-1.html#example-4b-results-compared-to-a-control-group"><i class="fa fa-check"></i><b>1.2.7</b> Example 4b: Results compared to a control group<span class="math inline">\(^*\)</span></a></li>
<li class="chapter" data-level="1.2.8" data-path="lecture-1.html"><a href="lecture-1.html#example-4c-results-from-a-randomized-controlled-trial-rct-of-renal-denervation"><i class="fa fa-check"></i><b>1.2.8</b> Example 4c: Results from a randomized controlled trial (RCT) of renal denervation<span class="math inline">\(^*\)</span></a></li>
<li class="chapter" data-level="1.2.9" data-path="lecture-1.html"><a href="lecture-1.html#example-4d-results-from-a-second-randomized-controlled-trial-of-renal-denervation"><i class="fa fa-check"></i><b>1.2.9</b> Example 4d: Results from a second randomized controlled trial of renal denervation<span class="math inline">\(^*\)</span></a></li>
<li class="chapter" data-level="1.2.10" data-path="lecture-1.html"><a href="lecture-1.html#example-4-renal-denervation-as-a-treatment-for-resistant-hypertension"><i class="fa fa-check"></i><b>1.2.10</b> Example 4: Renal Denervation as a treatment for resistant hypertension</a></li>
<li class="chapter" data-level="1.2.11" data-path="lecture-1.html"><a href="lecture-1.html#lessons-learnt-from-renal-denervation-example"><i class="fa fa-check"></i><b>1.2.11</b> Lessons learnt from renal denervation example</a></li>
<li class="chapter" data-level="1.2.12" data-path="lecture-1.html"><a href="lecture-1.html#health-technology-assessment-of-renal-denervation"><i class="fa fa-check"></i><b>1.2.12</b> Health Technology Assessment of Renal Denervation</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="lecture-1.html"><a href="lecture-1.html#random-sampling-and-randomization"><i class="fa fa-check"></i><b>1.3</b> Random sampling and Randomization</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="lecture-1.html"><a href="lecture-1.html#sample-surveys"><i class="fa fa-check"></i><b>1.3.1</b> Sample surveys</a></li>
<li class="chapter" data-level="1.3.2" data-path="lecture-1.html"><a href="lecture-1.html#simple-random-sample"><i class="fa fa-check"></i><b>1.3.2</b> Simple random sample</a></li>
<li class="chapter" data-level="1.3.3" data-path="lecture-1.html"><a href="lecture-1.html#sample-surveys-1"><i class="fa fa-check"></i><b>1.3.3</b> Sample surveys*</a></li>
<li class="chapter" data-level="1.3.4" data-path="lecture-1.html"><a href="lecture-1.html#margin-of-error"><i class="fa fa-check"></i><b>1.3.4</b> Margin of error</a></li>
<li class="chapter" data-level="1.3.5" data-path="lecture-1.html"><a href="lecture-1.html#how-to-choose-a-simple-random-sample"><i class="fa fa-check"></i><b>1.3.5</b> How to choose a simple random sample</a></li>
<li class="chapter" data-level="1.3.6" data-path="lecture-1.html"><a href="lecture-1.html#example-drawing-a-random-sample"><i class="fa fa-check"></i><b>1.3.6</b> Example: Drawing a random sample</a></li>
<li class="chapter" data-level="1.3.7" data-path="lecture-1.html"><a href="lecture-1.html#practical-concerns-when-random-sampling"><i class="fa fa-check"></i><b>1.3.7</b> Practical concerns when random sampling</a></li>
<li class="chapter" data-level="1.3.8" data-path="lecture-1.html"><a href="lecture-1.html#some-typical-biases-that-can-arise-during-a-survey"><i class="fa fa-check"></i><b>1.3.8</b> Some typical biases that can arise during a survey</a></li>
<li class="chapter" data-level="1.3.9" data-path="lecture-1.html"><a href="lecture-1.html#randomization"><i class="fa fa-check"></i><b>1.3.9</b> Randomization</a></li>
<li class="chapter" data-level="1.3.10" data-path="lecture-1.html"><a href="lecture-1.html#simple-randomization"><i class="fa fa-check"></i><b>1.3.10</b> Simple randomization</a></li>
<li class="chapter" data-level="1.3.11" data-path="lecture-1.html"><a href="lecture-1.html#relevance-of-statistical-methods-to-researchers-in-the-life-sciences"><i class="fa fa-check"></i><b>1.3.11</b> Relevance of statistical methods to researchers in the life sciences</a></li>
<li class="chapter" data-level="1.3.12" data-path="lecture-1.html"><a href="lecture-1.html#organizations-supporting-transparent-reporting-of-biomedical-research-evidence-based-decision-making"><i class="fa fa-check"></i><b>1.3.12</b> Organizations supporting transparent reporting of biomedical research &amp; evidence-based decision making</a></li>
<li class="chapter" data-level="1.3.13" data-path="lecture-1.html"><a href="lecture-1.html#biomedical-journals-are-insisting-on-appropriate-statistical-methods"><i class="fa fa-check"></i><b>1.3.13</b> Biomedical journals are insisting on appropriate statistical methods</a></li>
<li class="chapter" data-level="1.3.14" data-path="lecture-1.html"><a href="lecture-1.html#fev-example-dataset"><i class="fa fa-check"></i><b>1.3.14</b> FEV Example: Dataset</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html"><i class="fa fa-check"></i><b>2</b> Lecture 2: Types of Variables, Probability and Probability Distributions</a>
<ul>
<li class="chapter" data-level="2.1" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#types-of-variables"><i class="fa fa-check"></i><b>2.1</b> Types of variables</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#some-questions-on-types-of-variables"><i class="fa fa-check"></i><b>2.1.1</b> Some questions on types of variables</a></li>
<li class="chapter" data-level="2.1.2" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#qualitative-variables"><i class="fa fa-check"></i><b>2.1.2</b> Qualitative variables</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#probability"><i class="fa fa-check"></i><b>2.2</b> Probability</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#definitions"><i class="fa fa-check"></i><b>2.2.1</b> Definitions</a></li>
<li class="chapter" data-level="2.2.2" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#example-1-coin-tossing"><i class="fa fa-check"></i><b>2.2.2</b> Example 1: Coin Tossing</a></li>
<li class="chapter" data-level="2.2.3" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#example-2-coin-tossing-again"><i class="fa fa-check"></i><b>2.2.3</b> Example 2: Coin Tossing again</a></li>
<li class="chapter" data-level="2.2.4" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#interpretation-of-probability"><i class="fa fa-check"></i><b>2.2.4</b> Interpretation of probability</a></li>
<li class="chapter" data-level="2.2.5" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#relative-frequency-interpretation-of-probability"><i class="fa fa-check"></i><b>2.2.5</b> Relative frequency interpretation of probability</a></li>
<li class="chapter" data-level="2.2.6" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#subjective-interpretation-of-probability"><i class="fa fa-check"></i><b>2.2.6</b> Subjective interpretation of probability</a></li>
<li class="chapter" data-level="2.2.7" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#compound-events"><i class="fa fa-check"></i><b>2.2.7</b> Compound events</a></li>
<li class="chapter" data-level="2.2.8" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#some-questions-on-probability"><i class="fa fa-check"></i><b>2.2.8</b> Some questions on probability</a></li>
<li class="chapter" data-level="2.2.9" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#combining-probabilities-addition-rules"><i class="fa fa-check"></i><b>2.2.9</b> Combining probabilities: Addition rules</a></li>
<li class="chapter" data-level="2.2.10" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#combining-probabilities-multiplication-rules"><i class="fa fa-check"></i><b>2.2.10</b> Combining probabilities: Multiplication rules</a></li>
<li class="chapter" data-level="2.2.11" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#conditional-probability"><i class="fa fa-check"></i><b>2.2.11</b> Conditional probability</a></li>
<li class="chapter" data-level="2.2.12" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#probability-trees"><i class="fa fa-check"></i><b>2.2.12</b> Probability Trees</a></li>
<li class="chapter" data-level="2.2.13" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#example-3-independent-events"><i class="fa fa-check"></i><b>2.2.13</b> Example 3: Independent events</a></li>
<li class="chapter" data-level="2.2.14" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#albinism-example"><i class="fa fa-check"></i><b>2.2.14</b> Albinism example</a></li>
<li class="chapter" data-level="2.2.15" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#albinism-example-sample-space-and-probabilities"><i class="fa fa-check"></i><b>2.2.15</b> Albinism example: Sample space and probabilities</a></li>
<li class="chapter" data-level="2.2.16" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#example-4-medical-testing"><i class="fa fa-check"></i><b>2.2.16</b> Example 4: Medical testing</a></li>
<li class="chapter" data-level="2.2.17" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#medical-testing-example"><i class="fa fa-check"></i><b>2.2.17</b> Medical testing example</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#probability-distributions"><i class="fa fa-check"></i><b>2.3</b> Probability Distributions</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#population-and-sample"><i class="fa fa-check"></i><b>2.3.1</b> Population and sample<span class="math inline">\(^*\)</span></a></li>
<li class="chapter" data-level="2.3.2" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#notation"><i class="fa fa-check"></i><b>2.3.2</b> Notation</a></li>
<li class="chapter" data-level="2.3.3" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#parameters-statistics-probability-distributions"><i class="fa fa-check"></i><b>2.3.3</b> Parameters, Statistics, Probability Distributions</a></li>
<li class="chapter" data-level="2.3.4" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#binomial-distribution"><i class="fa fa-check"></i><b>2.3.4</b> Binomial Distribution</a></li>
<li class="chapter" data-level="2.3.5" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#binomial-distribution-function"><i class="fa fa-check"></i><b>2.3.5</b> Binomial Distribution Function</a></li>
<li class="chapter" data-level="2.3.6" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#albinism-example-for-a-couple-with-5-children-sample-space-and-probabilities"><i class="fa fa-check"></i><b>2.3.6</b> Albinism example for a couple with 5 children: Sample space and probabilities</a></li>
<li class="chapter" data-level="2.3.7" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#probability-distributions-in-r"><i class="fa fa-check"></i><b>2.3.7</b> Probability distributions in R</a></li>
<li class="chapter" data-level="2.3.8" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#example-binomial-distribution-in-practice"><i class="fa fa-check"></i><b>2.3.8</b> Example: Binomial distribution in practice<span class="math inline">\(^*\)</span></a></li>
<li class="chapter" data-level="2.3.9" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#mean-and-variance-of-random-variables"><i class="fa fa-check"></i><b>2.3.9</b> Mean and variance of random variables</a></li>
<li class="chapter" data-level="2.3.10" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#mean-and-variance-for-a-binomial-distribution"><i class="fa fa-check"></i><b>2.3.10</b> Mean and variance for a Binomial distribution</a></li>
<li class="chapter" data-level="2.3.11" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#probability-of-a-continuous-variable"><i class="fa fa-check"></i><b>2.3.11</b> Probability of a continuous variable</a></li>
<li class="chapter" data-level="2.3.12" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#probability-density-function-for-a-continuous-variable"><i class="fa fa-check"></i><b>2.3.12</b> Probability density function for a continuous variable</a></li>
<li class="chapter" data-level="2.3.13" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#normal-distribution"><i class="fa fa-check"></i><b>2.3.13</b> Normal Distribution</a></li>
<li class="chapter" data-level="2.3.14" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#normal-probability-density-function"><i class="fa fa-check"></i><b>2.3.14</b> Normal probability density function</a></li>
<li class="chapter" data-level="2.3.15" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#three-normal-curves-with-different-means-and-standard-deviations"><i class="fa fa-check"></i><b>2.3.15</b> Three normal curves with different means and standard deviations</a></li>
<li class="chapter" data-level="2.3.16" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#area-under-the-normal-curve"><i class="fa fa-check"></i><b>2.3.16</b> Area under the normal curve</a></li>
<li class="chapter" data-level="2.3.17" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#example-distribution-of-serum-cholesterol-values"><i class="fa fa-check"></i><b>2.3.17</b> Example: Distribution of serum cholesterol values</a></li>
<li class="chapter" data-level="2.3.18" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#area-under-the-normal-curve-1"><i class="fa fa-check"></i><b>2.3.18</b> Area under the normal curve</a></li>
<li class="chapter" data-level="2.3.19" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#mean-and-variance-of-the-normal-distribution"><i class="fa fa-check"></i><b>2.3.19</b> Mean and variance of the normal distribution</a></li>
<li class="chapter" data-level="2.3.20" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#examples-of-discrete-distributions"><i class="fa fa-check"></i><b>2.3.20</b> Examples of discrete distributions</a></li>
<li class="chapter" data-level="2.3.21" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#bernoulli-distribution"><i class="fa fa-check"></i><b>2.3.21</b> Bernoulli distribution</a></li>
<li class="chapter" data-level="2.3.22" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#binomial-distribution-1"><i class="fa fa-check"></i><b>2.3.22</b> Binomial distribution</a></li>
<li class="chapter" data-level="2.3.23" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#poisson-distribution"><i class="fa fa-check"></i><b>2.3.23</b> Poisson distribution</a></li>
<li class="chapter" data-level="2.3.24" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#example-transcriptomic-analyses"><i class="fa fa-check"></i><b>2.3.24</b> Example: Transcriptomic Analyses<span class="math inline">\(^*\)</span></a></li>
<li class="chapter" data-level="2.3.25" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#underlying-statistical-principles-of-commonly-used-packages"><i class="fa fa-check"></i><b>2.3.25</b> Underlying statistical principles of commonly used packages</a></li>
<li class="chapter" data-level="2.3.26" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#how-it-works"><i class="fa fa-check"></i><b>2.3.26</b> How it works</a></li>
<li class="chapter" data-level="2.3.27" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#what-would-be-a-suitable-probability-distribution"><i class="fa fa-check"></i><b>2.3.27</b> What would be a suitable probability distribution?</a></li>
<li class="chapter" data-level="2.3.28" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#poisson-distribution-is-limiting"><i class="fa fa-check"></i><b>2.3.28</b> Poisson Distribution is limiting</a></li>
<li class="chapter" data-level="2.3.29" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#negative-binomial-distribution"><i class="fa fa-check"></i><b>2.3.29</b> Negative Binomial Distribution</a></li>
<li class="chapter" data-level="2.3.30" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#conceptual-justification"><i class="fa fa-check"></i><b>2.3.30</b> Conceptual Justification</a></li>
<li class="chapter" data-level="2.3.31" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#additional-notes-and-practical-implications"><i class="fa fa-check"></i><b>2.3.31</b> Additional Notes and Practical Implications</a></li>
<li class="chapter" data-level="2.3.32" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#examples-of-continuous-distributions"><i class="fa fa-check"></i><b>2.3.32</b> Examples of continuous distributions</a></li>
<li class="chapter" data-level="2.3.33" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#normal-distribution-1"><i class="fa fa-check"></i><b>2.3.33</b> Normal distribution</a></li>
<li class="chapter" data-level="2.3.34" data-path="lecture-2-types-of-variables-probability-and-probability-distributions.html"><a href="lecture-2-types-of-variables-probability-and-probability-distributions.html#uniform-distribution"><i class="fa fa-check"></i><b>2.3.34</b> Uniform distribution</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html"><i class="fa fa-check"></i><b>3</b> Lecture 3: Central Limit Theorem and Inference for Means</a>
<ul>
<li class="chapter" data-level="3.1" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#mean-and-standard-deviation"><i class="fa fa-check"></i><b>3.1</b> Mean and Standard Deviation</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#descriptive-statistics-vs.-inferential-statistics"><i class="fa fa-check"></i><b>3.1.1</b> Descriptive statistics vs.Â Inferential Statistics</a></li>
<li class="chapter" data-level="3.1.2" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#some-commonly-encountered-shapes-of-distributions-of-a-variable"><i class="fa fa-check"></i><b>3.1.2</b> Some commonly encountered shapes of distributions of a variable</a></li>
<li class="chapter" data-level="3.1.3" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#descriptive-statistics-notation"><i class="fa fa-check"></i><b>3.1.3</b> Descriptive statistics: Notation</a></li>
<li class="chapter" data-level="3.1.4" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#histogram-of-fev"><i class="fa fa-check"></i><b>3.1.4</b> Histogram of FEV</a></li>
<li class="chapter" data-level="3.1.5" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#measures-of-central-tendency"><i class="fa fa-check"></i><b>3.1.5</b> Measures of central tendency</a></li>
<li class="chapter" data-level="3.1.6" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#summary-of-fev-variable"><i class="fa fa-check"></i><b>3.1.6</b> Summary of FEV variable</a></li>
<li class="chapter" data-level="3.1.7" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#robustness"><i class="fa fa-check"></i><b>3.1.7</b> Robustness</a></li>
<li class="chapter" data-level="3.1.8" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#mean-vs.-median"><i class="fa fa-check"></i><b>3.1.8</b> Mean vs.Â Median</a></li>
<li class="chapter" data-level="3.1.9" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#quantiles"><i class="fa fa-check"></i><b>3.1.9</b> Quantiles</a></li>
<li class="chapter" data-level="3.1.10" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#measures-of-spread"><i class="fa fa-check"></i><b>3.1.10</b> Measures of spread</a></li>
<li class="chapter" data-level="3.1.11" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#summary-of-fev-variable-1"><i class="fa fa-check"></i><b>3.1.11</b> Summary of FEV variable</a></li>
<li class="chapter" data-level="3.1.12" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#comparison-of-measures-of-spread"><i class="fa fa-check"></i><b>3.1.12</b> Comparison of measures of spread</a></li>
<li class="chapter" data-level="3.1.13" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#variance-and-standard-deviation"><i class="fa fa-check"></i><b>3.1.13</b> Variance and Standard Deviation</a></li>
<li class="chapter" data-level="3.1.14" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#why-n-1-rather-than-n"><i class="fa fa-check"></i><b>3.1.14</b> Why n-1 rather than n?<span class="math inline">\(^*\)</span></a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#central-limit-theorem"><i class="fa fa-check"></i><b>3.2</b> Central Limit Theorem</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#example-1-serum-cholesterol-in-children"><i class="fa fa-check"></i><b>3.2.1</b> Example 1: Serum cholesterol in children</a></li>
<li class="chapter" data-level="3.2.2" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#the-sampling-distribution-of-bar-y"><i class="fa fa-check"></i><b>3.2.2</b> The sampling distribution of <span class="math inline">\(\bar Y\)</span></a></li>
<li class="chapter" data-level="3.2.3" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#example-sampling-distribution-of-bar-y-when-n10"><i class="fa fa-check"></i><b>3.2.3</b> Example: Sampling distribution of <span class="math inline">\(\bar Y\)</span> when n=10</a></li>
<li class="chapter" data-level="3.2.4" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#example-sampling-distribution-of-bar-y-when-n30"><i class="fa fa-check"></i><b>3.2.4</b> Example: Sampling distribution of <span class="math inline">\(\bar Y\)</span> when n=30</a></li>
<li class="chapter" data-level="3.2.5" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#example-sampling-distribution-of-bar-y-when-n100"><i class="fa fa-check"></i><b>3.2.5</b> Example: Sampling distribution of <span class="math inline">\(\bar Y\)</span> when n=100</a></li>
<li class="chapter" data-level="3.2.6" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#example-sampling-distribution-of-bar-y-when-n1000"><i class="fa fa-check"></i><b>3.2.6</b> Example: Sampling distribution of <span class="math inline">\(\bar Y\)</span> when n=1000</a></li>
<li class="chapter" data-level="3.2.7" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#example-1"><i class="fa fa-check"></i><b>3.2.7</b> Example 1</a></li>
<li class="chapter" data-level="3.2.8" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#the-sampling-distribution-of-bar-y-1"><i class="fa fa-check"></i><b>3.2.8</b> The sampling distribution of <span class="math inline">\(\bar Y\)</span></a></li>
<li class="chapter" data-level="3.2.9" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#central-limit-theorem-1"><i class="fa fa-check"></i><b>3.2.9</b> Central Limit Theorem</a></li>
<li class="chapter" data-level="3.2.10" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#example-1-1"><i class="fa fa-check"></i><b>3.2.10</b> Example 1</a></li>
<li class="chapter" data-level="3.2.11" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#theory-related-to-the-sums-of-random-variables"><i class="fa fa-check"></i><b>3.2.11</b> Theory related to the sums of random variables</a></li>
<li class="chapter" data-level="3.2.12" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#some-examples-related-to-the-sums-of-independent-random-variables"><i class="fa fa-check"></i><b>3.2.12</b> Some examples related to the sums of independent random variables</a></li>
<li class="chapter" data-level="3.2.13" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#example-2-central-limit-theorem-in-action"><i class="fa fa-check"></i><b>3.2.13</b> Example 2: Central Limit Theorem in action</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#confidence-intervals-for-means"><i class="fa fa-check"></i><b>3.3</b> Confidence intervals for means</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#confidence-interval-estimation-for-a-single-mean"><i class="fa fa-check"></i><b>3.3.1</b> Confidence interval estimation for a single mean</a></li>
<li class="chapter" data-level="3.3.2" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#t-distribution"><i class="fa fa-check"></i><b>3.3.2</b> t-distribution</a></li>
<li class="chapter" data-level="3.3.3" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#example-1-serum-potassium-concentration"><i class="fa fa-check"></i><b>3.3.3</b> Example 1: Serum Potassium Concentration</a></li>
<li class="chapter" data-level="3.3.4" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#example-1-histogram-of-the-data"><i class="fa fa-check"></i><b>3.3.4</b> Example 1: Histogram of the data</a></li>
<li class="chapter" data-level="3.3.5" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#verifying-assumptions-behind-the-t-distribution-confidence-interval"><i class="fa fa-check"></i><b>3.3.5</b> Verifying assumptions behind the t-distribution confidence interval</a></li>
<li class="chapter" data-level="3.3.6" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#example-1-standard-error-and-95-confidence-interval"><i class="fa fa-check"></i><b>3.3.6</b> Example 1: Standard Error and 95% confidence interval</a></li>
<li class="chapter" data-level="3.3.7" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#interpretation-of-the-95-confidence-interval"><i class="fa fa-check"></i><b>3.3.7</b> Interpretation of the 95% confidence interval</a></li>
<li class="chapter" data-level="3.3.8" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#confidence-level"><i class="fa fa-check"></i><b>3.3.8</b> Confidence level</a></li>
<li class="chapter" data-level="3.3.9" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#example-1-distribution-of-the-data-with-intervals"><i class="fa fa-check"></i><b>3.3.9</b> Example 1: Distribution of the data (with intervals)</a></li>
<li class="chapter" data-level="3.3.10" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#interpreting-the-confidence-interval"><i class="fa fa-check"></i><b>3.3.10</b> Interpreting the confidence interval</a></li>
<li class="chapter" data-level="3.3.11" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#standard-error-vs-standard-deviation"><i class="fa fa-check"></i><b>3.3.11</b> Standard error vs Standard deviation</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#confidence-interval-for-the-difference-between-two-means"><i class="fa fa-check"></i><b>3.4</b> Confidence interval for the difference between two means</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#example-2-nck1-deficiency-and-adipogenesis"><i class="fa fa-check"></i><b>3.4.1</b> Example 2: Nck1 deficiency and adipogenesis</a></li>
<li class="chapter" data-level="3.4.2" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#confidence-interval-for-the-difference-between-means-from-two-independent-samples"><i class="fa fa-check"></i><b>3.4.2</b> Confidence interval for the difference between means from two independent samples</a></li>
<li class="chapter" data-level="3.4.3" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#variance-of-the-difference-in-means"><i class="fa fa-check"></i><b>3.4.3</b> Variance of the difference in means</a></li>
<li class="chapter" data-level="3.4.4" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#calculating-degrees-of-freedom-of-the-t-distribution-when-variances-are-not-equal"><i class="fa fa-check"></i><b>3.4.4</b> Calculating degrees of freedom of the t-distribution when variances are not equal</a></li>
<li class="chapter" data-level="3.4.5" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#example-2-nck1-deficiency-and-adipogenesis-1"><i class="fa fa-check"></i><b>3.4.5</b> Example 2: Nck1 deficiency and adipogenesis</a></li>
<li class="chapter" data-level="3.4.6" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#calculating-the-pooled-variance-for-body-weight"><i class="fa fa-check"></i><b>3.4.6</b> Calculating the pooled variance for body weight</a></li>
<li class="chapter" data-level="3.4.7" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#confidence-interval-for-difference-in-body-weight"><i class="fa fa-check"></i><b>3.4.7</b> Confidence interval for difference in body weight</a></li>
<li class="chapter" data-level="3.4.8" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#confidence-intervals-comparing-the-two-groups"><i class="fa fa-check"></i><b>3.4.8</b> Confidence intervals comparing the two groups</a></li>
<li class="chapter" data-level="3.4.9" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#interpreting-the-confidence-interval-1"><i class="fa fa-check"></i><b>3.4.9</b> Interpreting the confidence interval</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#sample-size-calculations"><i class="fa fa-check"></i><b>3.5</b> Sample size calculations</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#an-illustration"><i class="fa fa-check"></i><b>3.5.1</b> An illustration</a></li>
<li class="chapter" data-level="3.5.2" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#sample-size-calculation"><i class="fa fa-check"></i><b>3.5.2</b> Sample size calculation</a></li>
<li class="chapter" data-level="3.5.3" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#sample-size-calculation-for-reporting-a-confidence-interval"><i class="fa fa-check"></i><b>3.5.3</b> Sample size calculation for reporting a confidence interval</a></li>
<li class="chapter" data-level="3.5.4" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#example-method-for-a-single-mean"><i class="fa fa-check"></i><b>3.5.4</b> Example: Method for a single mean</a></li>
<li class="chapter" data-level="3.5.5" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#the-desired-precision-is-much-smaller-than-the-standard-deviation-of-the-variable"><i class="fa fa-check"></i><b>3.5.5</b> The desired precision is much smaller than the standard deviation of the variable</a></li>
<li class="chapter" data-level="3.5.6" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#example-method-for-a-single-mean-1"><i class="fa fa-check"></i><b>3.5.6</b> Example: Method for a single mean</a></li>
<li class="chapter" data-level="3.5.7" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#alternative-values-of-Î±-s-and-Î´"><i class="fa fa-check"></i><b>3.5.7</b> Alternative values of Î±, s and Î´</a></li>
<li class="chapter" data-level="3.5.8" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#example-sample-size-calculation-for-comparing-two-means"><i class="fa fa-check"></i><b>3.5.8</b> Example: Sample size calculation for comparing two means</a></li>
<li class="chapter" data-level="3.5.9" data-path="lecture-3-central-limit-theorem-and-inference-for-means.html"><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#example-comparison-of-two-means"><i class="fa fa-check"></i><b>3.5.9</b> Example: Comparison of two means</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html"><i class="fa fa-check"></i><b>4</b> Lecture 4: Inference for means continued</a>
<ul>
<li class="chapter" data-level="4.1" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#hypothesis-testing"><i class="fa fa-check"></i><b>4.1</b> Hypothesis testing</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#example-1-nck1-and-adipogenesis-continued"><i class="fa fa-check"></i><b>4.1.1</b> Example 1: Nck1 and adipogenesis continued</a></li>
<li class="chapter" data-level="4.1.2" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#hypothesis-testing-1"><i class="fa fa-check"></i><b>4.1.2</b> Hypothesis testing</a></li>
<li class="chapter" data-level="4.1.3" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#hypothesis-testing-for-a-single-mean"><i class="fa fa-check"></i><b>4.1.3</b> Hypothesis testing for a single mean</a></li>
<li class="chapter" data-level="4.1.4" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#mobility-after-stroke-two-sided-alternative-hypothesis"><i class="fa fa-check"></i><b>4.1.4</b> Mobility after stroke: two-sided alternative hypothesis</a></li>
<li class="chapter" data-level="4.1.5" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#mobility-after-stroke-one-sided-alternative-hypothesis-i"><i class="fa fa-check"></i><b>4.1.5</b> Mobility after stroke: one-sided alternative hypothesis I</a></li>
<li class="chapter" data-level="4.1.6" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#mobility-after-stroke-one-sided-alternative-hypothesis-ii"><i class="fa fa-check"></i><b>4.1.6</b> Mobility after stroke: one-sided alternative hypothesis II</a></li>
<li class="chapter" data-level="4.1.7" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#more-generally-the-hypothesis-test-for-a-single-mean-may-be-stated-as-follows"><i class="fa fa-check"></i><b>4.1.7</b> More generally, the hypothesis test for a single mean may be stated as follows</a></li>
<li class="chapter" data-level="4.1.8" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#example-mobility-after-stroke"><i class="fa fa-check"></i><b>4.1.8</b> Example: Mobility after stroke</a></li>
<li class="chapter" data-level="4.1.9" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#defining-the-test-statistic-and-the-rejection-region"><i class="fa fa-check"></i><b>4.1.9</b> Defining the test statistic and the rejection region</a></li>
<li class="chapter" data-level="4.1.10" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#defining-the-t-test-statistic"><i class="fa fa-check"></i><b>4.1.10</b> Defining the t-test statistic</a></li>
<li class="chapter" data-level="4.1.11" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#rejection-region-for-the-t-test"><i class="fa fa-check"></i><b>4.1.11</b> Rejection region for the t-test</a></li>
<li class="chapter" data-level="4.1.12" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#comparison-to-confidence-interval"><i class="fa fa-check"></i><b>4.1.12</b> Comparison to confidence interval</a></li>
<li class="chapter" data-level="4.1.13" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#determining-the-rejection-region-using-r"><i class="fa fa-check"></i><b>4.1.13</b> Determining the rejection region using R</a></li>
<li class="chapter" data-level="4.1.14" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#type-i-and-type-ii-errors"><i class="fa fa-check"></i><b>4.1.14</b> Type I and Type II errors</a></li>
<li class="chapter" data-level="4.1.15" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#hypothesis-testing-a-summary"><i class="fa fa-check"></i><b>4.1.15</b> Hypothesis testing: A summary</a></li>
<li class="chapter" data-level="4.1.16" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#similarity-between-diagnostic-testing-and-hypothesis-testing"><i class="fa fa-check"></i><b>4.1.16</b> Similarity between diagnostic testing and hypothesis testing</a></li>
<li class="chapter" data-level="4.1.17" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#defining-the-t-test-statistic-for-a-one-sided-test"><i class="fa fa-check"></i><b>4.1.17</b> Defining the t-test statistic, for a one-sided test</a></li>
<li class="chapter" data-level="4.1.18" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#why-did-the-test-statistic-not-change-for-the-one-sided-hypothesis-test"><i class="fa fa-check"></i><b>4.1.18</b> Why did the test statistic not change for the one-sided hypothesis test?</a></li>
<li class="chapter" data-level="4.1.19" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#what-is-statistical-significance"><i class="fa fa-check"></i><b>4.1.19</b> What is statistical significance?</a></li>
<li class="chapter" data-level="4.1.20" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#what-is-a-p-value"><i class="fa fa-check"></i><b>4.1.20</b> What is a p-value?</a></li>
<li class="chapter" data-level="4.1.21" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#p-value-illustrated"><i class="fa fa-check"></i><b>4.1.21</b> p-value illustrated</a></li>
<li class="chapter" data-level="4.1.22" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#type-i-and-type-ii-errors-1"><i class="fa fa-check"></i><b>4.1.22</b> Type I and Type II errors</a></li>
<li class="chapter" data-level="4.1.23" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#t-test"><i class="fa fa-check"></i><b>4.1.23</b> t-test</a></li>
<li class="chapter" data-level="4.1.24" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#a-bit-of-history-pearson-vs.-fisher"><i class="fa fa-check"></i><b>4.1.24</b> A bit of history: Pearson vs.Â Fisher</a></li>
<li class="chapter" data-level="4.1.25" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#inference-for-comparing-two-means"><i class="fa fa-check"></i><b>4.1.25</b> Inference for comparing two means</a></li>
<li class="chapter" data-level="4.1.26" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#stroke-study-question-2-two-sided-alternative-hypothesis"><i class="fa fa-check"></i><b>4.1.26</b> Stroke study: Question 2, two-sided alternative hypothesis</a></li>
<li class="chapter" data-level="4.1.27" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#stroke-study-question-2-one-sided-hypothesis-i"><i class="fa fa-check"></i><b>4.1.27</b> Stroke study: Question 2, one-sided hypothesis I</a></li>
<li class="chapter" data-level="4.1.28" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#stroke-study-question-2-one-sided-hypothesis-ii"><i class="fa fa-check"></i><b>4.1.28</b> Stroke study: Question 2, one-sided hypothesis II</a></li>
<li class="chapter" data-level="4.1.29" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#example-one-sided-or-two-sided-test"><i class="fa fa-check"></i><b>4.1.29</b> Example: One-sided or two-sided test?</a></li>
<li class="chapter" data-level="4.1.30" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#difference-in-change-in-mobility-between-men-and-women"><i class="fa fa-check"></i><b>4.1.30</b> Difference in change in mobility between men and women</a></li>
<li class="chapter" data-level="4.1.31" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#comparing-change-in-mobility-between-men-and-women"><i class="fa fa-check"></i><b>4.1.31</b> Comparing change in mobility between men and women</a></li>
<li class="chapter" data-level="4.1.32" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#what-if-our-alternative-hypothesis-was-one-sided-instead"><i class="fa fa-check"></i><b>4.1.32</b> What if our alternative hypothesis was one-sided instead?</a></li>
<li class="chapter" data-level="4.1.33" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#what-if-our-alternative-hypothesis-was-one-sided-in-the-other-direction"><i class="fa fa-check"></i><b>4.1.33</b> What if our alternative hypothesis was one-sided in the other direction?</a></li>
<li class="chapter" data-level="4.1.34" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#what-if-our-null-hypothesis-was-one-sided-instead"><i class="fa fa-check"></i><b>4.1.34</b> What if our null hypothesis was one-sided instead?</a></li>
<li class="chapter" data-level="4.1.35" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#why-did-our-conclusion-change-when-we-moved-from-a-two-sided-to-a-one-sided-hypothesis"><i class="fa fa-check"></i><b>4.1.35</b> Why did our conclusion change when we moved from a two-sided to a one-sided hypothesis?</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#hypothesis-testing-vs.-confidence-interval-estimation"><i class="fa fa-check"></i><b>4.2</b> Hypothesis testing vs.Â confidence interval estimation</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#what-is-statistics-1"><i class="fa fa-check"></i><b>4.2.1</b> What is statistics?</a></li>
<li class="chapter" data-level="4.2.2" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#quantifying-uncertainty-vs.-decision-making"><i class="fa fa-check"></i><b>4.2.2</b> Quantifying uncertainty vs.Â decision making</a></li>
<li class="chapter" data-level="4.2.3" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#interpreting-confidence-intervals-vs.-hypothesis-tests"><i class="fa fa-check"></i><b>4.2.3</b> Interpreting Confidence Intervals vs.Â Hypothesis Tests<span class="math inline">\(^*\)</span></a></li>
<li class="chapter" data-level="4.2.4" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#notes-on-significance-tests"><i class="fa fa-check"></i><b>4.2.4</b> Notes on significance tests<span class="math inline">\(^*\)</span></a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#sample-size-calculations-for-studies-of-one-or-two-means"><i class="fa fa-check"></i><b>4.3</b> Sample size calculations for studies of one or two means</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#sample-size-for-hypothesis-tests"><i class="fa fa-check"></i><b>4.3.1</b> Sample size for hypothesis tests</a></li>
<li class="chapter" data-level="4.3.2" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#example"><i class="fa fa-check"></i><b>4.3.2</b> Example</a></li>
<li class="chapter" data-level="4.3.3" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#we-are-interested-in-detecting-a-shift-in-the-mean-of-the-distribution"><i class="fa fa-check"></i><b>4.3.3</b> We are interested in detecting a shift in the mean of the distribution</a></li>
<li class="chapter" data-level="4.3.4" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#sample-size-required-for-a-hypothesis-test-of-a-single-mean"><i class="fa fa-check"></i><b>4.3.4</b> Sample size required for a hypothesis test of a single mean</a></li>
<li class="chapter" data-level="4.3.5" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#sample-size-required-under-different-scenarios"><i class="fa fa-check"></i><b>4.3.5</b> Sample size required under different scenarios</a></li>
<li class="chapter" data-level="4.3.6" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#example-serum-cholesterol"><i class="fa fa-check"></i><b>4.3.6</b> Example: Serum cholesterol</a></li>
<li class="chapter" data-level="4.3.7" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#summary-what-do-you-need-to-calculate-the-sample-size-required"><i class="fa fa-check"></i><b>4.3.7</b> Summary: What do you need to calculate the sample size required?</a></li>
<li class="chapter" data-level="4.3.8" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#sample-size-calculation-comparing-two-means"><i class="fa fa-check"></i><b>4.3.8</b> Sample size calculation: Comparing two means</a></li>
<li class="chapter" data-level="4.3.9" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#example-2"><i class="fa fa-check"></i><b>4.3.9</b> Example</a></li>
<li class="chapter" data-level="4.3.10" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#sample-size-required-to-test-h_0mu_1mu_2"><i class="fa fa-check"></i><b>4.3.10</b> Sample size required to test <span class="math inline">\(H_0:\mu_1=\mu_2\)</span></a></li>
<li class="chapter" data-level="4.3.11" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#example-in-vivo-efficacy-of-p1.40"><i class="fa fa-check"></i><b>4.3.11</b> Example: In-vivo efficacy of P1.40</a></li>
<li class="chapter" data-level="4.3.12" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#power"><i class="fa fa-check"></i><b>4.3.12</b> Power</a></li>
<li class="chapter" data-level="4.3.13" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#calculating-the-power-in-r"><i class="fa fa-check"></i><b>4.3.13</b> Calculating the power in R</a></li>
<li class="chapter" data-level="4.3.14" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#example-power-function"><i class="fa fa-check"></i><b>4.3.14</b> Example: Power function</a></li>
<li class="chapter" data-level="4.3.15" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#what-is-the-impact-of-equal-or-unequal-group-sizes-on-the-precision"><i class="fa fa-check"></i><b>4.3.15</b> What is the impact of equal or unequal group sizes on the precision?</a></li>
<li class="chapter" data-level="4.3.16" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#an-r-package-for-sample-size-and-power-calculations"><i class="fa fa-check"></i><b>4.3.16</b> An R package for sample size and power calculations</a></li>
<li class="chapter" data-level="4.3.17" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#installing-a-package-in-r"><i class="fa fa-check"></i><b>4.3.17</b> Installing a package in R</a></li>
<li class="chapter" data-level="4.3.18" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#sample-size-for-comparing-two-means"><i class="fa fa-check"></i><b>4.3.18</b> Sample size for comparing two means</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#extra-problems"><i class="fa fa-check"></i><b>4.4</b> Extra Problems</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#section"><i class="fa fa-check"></i><b>4.4.1</b> 1.</a></li>
<li class="chapter" data-level="4.4.2" data-path="lecture-4-inference-for-means-continued.html"><a href="lecture-4-inference-for-means-continued.html#section-1"><i class="fa fa-check"></i><b>4.4.2</b> 2.</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="lecture-5-sample-size-calculations-to-plan-for-hypothesis-tests-of-means.html"><a href="lecture-5-sample-size-calculations-to-plan-for-hypothesis-tests-of-means.html"><i class="fa fa-check"></i><b>5</b> Lecture 5: Sample size calculations to plan for hypothesis tests of means</a>
<ul>
<li class="chapter" data-level="5.1" data-path="lecture-5-sample-size-calculations-to-plan-for-hypothesis-tests-of-means.html"><a href="lecture-5-sample-size-calculations-to-plan-for-hypothesis-tests-of-means.html#sample-size-calculation-1"><i class="fa fa-check"></i><b>5.1</b> Sample size calculation</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="lecture-5-sample-size-calculations-to-plan-for-hypothesis-tests-of-means.html"><a href="lecture-5-sample-size-calculations-to-plan-for-hypothesis-tests-of-means.html#type-i-and-type-ii-errors-2"><i class="fa fa-check"></i><b>5.1.1</b> Type I and Type II errors</a></li>
<li class="chapter" data-level="5.1.2" data-path="lecture-5-sample-size-calculations-to-plan-for-hypothesis-tests-of-means.html"><a href="lecture-5-sample-size-calculations-to-plan-for-hypothesis-tests-of-means.html#similarity-between-diagnostic-testing-and-hypothesis-testing-1"><i class="fa fa-check"></i><b>5.1.2</b> Similarity between diagnostic testing and hypothesis testing</a></li>
<li class="chapter" data-level="5.1.3" data-path="lecture-5-sample-size-calculations-to-plan-for-hypothesis-tests-of-means.html"><a href="lecture-5-sample-size-calculations-to-plan-for-hypothesis-tests-of-means.html#example-3"><i class="fa fa-check"></i><b>5.1.3</b> Example</a></li>
<li class="chapter" data-level="5.1.4" data-path="lecture-5-sample-size-calculations-to-plan-for-hypothesis-tests-of-means.html"><a href="lecture-5-sample-size-calculations-to-plan-for-hypothesis-tests-of-means.html#we-are-interested-in-detecting-a-shift-in-the-mean-of-the-distribution-1"><i class="fa fa-check"></i><b>5.1.4</b> We are interested in detecting a shift in the mean of the distribution</a></li>
<li class="chapter" data-level="5.1.5" data-path="lecture-5-sample-size-calculations-to-plan-for-hypothesis-tests-of-means.html"><a href="lecture-5-sample-size-calculations-to-plan-for-hypothesis-tests-of-means.html#sample-size-required-for-a-hypothesis-test-of-a-single-mean-1"><i class="fa fa-check"></i><b>5.1.5</b> Sample size required for a hypothesis test of a single mean</a></li>
<li class="chapter" data-level="5.1.6" data-path="lecture-5-sample-size-calculations-to-plan-for-hypothesis-tests-of-means.html"><a href="lecture-5-sample-size-calculations-to-plan-for-hypothesis-tests-of-means.html#sample-size-required-under-different-scenarios-for-a-one-sided-test"><i class="fa fa-check"></i><b>5.1.6</b> Sample size required under different scenarios for a one-sided test</a></li>
<li class="chapter" data-level="5.1.7" data-path="lecture-5-sample-size-calculations-to-plan-for-hypothesis-tests-of-means.html"><a href="lecture-5-sample-size-calculations-to-plan-for-hypothesis-tests-of-means.html#example-serum-cholesterol-1"><i class="fa fa-check"></i><b>5.1.7</b> Example: Serum cholesterol</a></li>
<li class="chapter" data-level="5.1.8" data-path="lecture-5-sample-size-calculations-to-plan-for-hypothesis-tests-of-means.html"><a href="lecture-5-sample-size-calculations-to-plan-for-hypothesis-tests-of-means.html#summary-input-needed-to-calculate-sample-size-for-single-mean"><i class="fa fa-check"></i><b>5.1.8</b> Summary: Input needed to calculate sample size for single mean</a></li>
<li class="chapter" data-level="5.1.9" data-path="lecture-5-sample-size-calculations-to-plan-for-hypothesis-tests-of-means.html"><a href="lecture-5-sample-size-calculations-to-plan-for-hypothesis-tests-of-means.html#example-planning-a-study-to-compare-means-using-a-hypothesis-test"><i class="fa fa-check"></i><b>5.1.9</b> Example: Planning a study to compare means using a hypothesis test</a></li>
<li class="chapter" data-level="5.1.10" data-path="lecture-5-sample-size-calculations-to-plan-for-hypothesis-tests-of-means.html"><a href="lecture-5-sample-size-calculations-to-plan-for-hypothesis-tests-of-means.html#sample-size-required-to-compare-means"><i class="fa fa-check"></i><b>5.1.10</b> Sample size required to compare means</a></li>
<li class="chapter" data-level="5.1.11" data-path="lecture-5-sample-size-calculations-to-plan-for-hypothesis-tests-of-means.html"><a href="lecture-5-sample-size-calculations-to-plan-for-hypothesis-tests-of-means.html#example-sample-size-required-to-compare-nck1-wt-and-ko-mice"><i class="fa fa-check"></i><b>5.1.11</b> Example: Sample size required to compare Nck1 WT and KO mice</a></li>
<li class="chapter" data-level="5.1.12" data-path="lecture-5-sample-size-calculations-to-plan-for-hypothesis-tests-of-means.html"><a href="lecture-5-sample-size-calculations-to-plan-for-hypothesis-tests-of-means.html#power-1"><i class="fa fa-check"></i><b>5.1.12</b> Power</a></li>
<li class="chapter" data-level="5.1.13" data-path="lecture-5-sample-size-calculations-to-plan-for-hypothesis-tests-of-means.html"><a href="lecture-5-sample-size-calculations-to-plan-for-hypothesis-tests-of-means.html#calculating-the-power-in-r-1"><i class="fa fa-check"></i><b>5.1.13</b> Calculating the power in R</a></li>
<li class="chapter" data-level="5.1.14" data-path="lecture-5-sample-size-calculations-to-plan-for-hypothesis-tests-of-means.html"><a href="lecture-5-sample-size-calculations-to-plan-for-hypothesis-tests-of-means.html#example-power-function-1"><i class="fa fa-check"></i><b>5.1.14</b> Example: Power function</a></li>
<li class="chapter" data-level="5.1.15" data-path="lecture-5-sample-size-calculations-to-plan-for-hypothesis-tests-of-means.html"><a href="lecture-5-sample-size-calculations-to-plan-for-hypothesis-tests-of-means.html#what-is-the-impact-of-equal-or-unequal-group-sizes-on-the-precision-1"><i class="fa fa-check"></i><b>5.1.15</b> What is the impact of equal or unequal group sizes on the precision?<span class="math inline">\(^*\)</span></a></li>
<li class="chapter" data-level="5.1.16" data-path="lecture-5-sample-size-calculations-to-plan-for-hypothesis-tests-of-means.html"><a href="lecture-5-sample-size-calculations-to-plan-for-hypothesis-tests-of-means.html#an-r-package-for-sample-size-and-power-calculations-1"><i class="fa fa-check"></i><b>5.1.16</b> An R package for sample size and power calculations</a></li>
<li class="chapter" data-level="5.1.17" data-path="lecture-5-sample-size-calculations-to-plan-for-hypothesis-tests-of-means.html"><a href="lecture-5-sample-size-calculations-to-plan-for-hypothesis-tests-of-means.html#installing-a-package-in-r-1"><i class="fa fa-check"></i><b>5.1.17</b> Installing a package in R</a></li>
<li class="chapter" data-level="5.1.18" data-path="lecture-5-sample-size-calculations-to-plan-for-hypothesis-tests-of-means.html"><a href="lecture-5-sample-size-calculations-to-plan-for-hypothesis-tests-of-means.html#sample-size-for-comparing-two-means-1"><i class="fa fa-check"></i><b>5.1.18</b> Sample size for comparing two means</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html"><i class="fa fa-check"></i><b>6</b> Lecture 6: Bayesian inference for means</a>
<ul>
<li class="chapter" data-level="6.1" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#example-beach-water-quality"><i class="fa fa-check"></i><b>6.1</b> Example: Beach Water Quality</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#descriptive-statistics"><i class="fa fa-check"></i><b>6.1.1</b> Descriptive Statistics</a></li>
<li class="chapter" data-level="6.1.2" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#frequentist-inference"><i class="fa fa-check"></i><b>6.1.2</b> Frequentist inference</a></li>
<li class="chapter" data-level="6.1.3" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#p-value"><i class="fa fa-check"></i><b>6.1.3</b> p-value</a></li>
<li class="chapter" data-level="6.1.4" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#confidence-interval"><i class="fa fa-check"></i><b>6.1.4</b> 95% confidence interval</a></li>
<li class="chapter" data-level="6.1.5" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#bayesian-analysis"><i class="fa fa-check"></i><b>6.1.5</b> Bayesian analysis</a></li>
<li class="chapter" data-level="6.1.6" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#what-is-the-true-mean-e.-coli-count-Âµ"><i class="fa fa-check"></i><b>6.1.6</b> What is the true mean E. coli count (Âµ)?</a></li>
<li class="chapter" data-level="6.1.7" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#bayesian-inductive-vs.-frequentist-deductive-thinking"><i class="fa fa-check"></i><b>6.1.7</b> Bayesian (inductive) vs.Â Frequentist (deductive) thinking</a></li>
<li class="chapter" data-level="6.1.8" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#principal-elements-of-a-bayesian-analysis"><i class="fa fa-check"></i><b>6.1.8</b> Principal elements of a Bayesian analysis</a></li>
<li class="chapter" data-level="6.1.9" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#the-prior-distribution"><i class="fa fa-check"></i><b>6.1.9</b> The prior distribution</a></li>
<li class="chapter" data-level="6.1.10" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#beach-water-quality-bayesian-analysis"><i class="fa fa-check"></i><b>6.1.10</b> Beach Water Quality: Bayesian analysis</a></li>
<li class="chapter" data-level="6.1.11" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#two-possible-prior-distributions"><i class="fa fa-check"></i><b>6.1.11</b> Two possible prior distributions</a></li>
<li class="chapter" data-level="6.1.12" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#illustration-of-the-two-prior-distributions"><i class="fa fa-check"></i><b>6.1.12</b> Illustration of the two prior distributions</a></li>
<li class="chapter" data-level="6.1.13" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#applying-bayes-theorem"><i class="fa fa-check"></i><b>6.1.13</b> Applying Bayes Theorem</a></li>
<li class="chapter" data-level="6.1.14" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#the-normal-posterior-distribution"><i class="fa fa-check"></i><b>6.1.14</b> The normal posterior distribution</a></li>
<li class="chapter" data-level="6.1.15" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#beach-water-quality-example-non-informative-prior"><i class="fa fa-check"></i><b>6.1.15</b> Beach Water Quality Example: Non-informative prior</a></li>
<li class="chapter" data-level="6.1.16" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#bayesian-analysis-using-r"><i class="fa fa-check"></i><b>6.1.16</b> Bayesian analysis using R</a></li>
<li class="chapter" data-level="6.1.17" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#posterior-distribution-compared-to-likelihood-and-non-informative-prior"><i class="fa fa-check"></i><b>6.1.17</b> Posterior distribution compared to likelihood and non-informative prior</a></li>
<li class="chapter" data-level="6.1.18" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#prior-and-posterior-distribution-plot-from-r"><i class="fa fa-check"></i><b>6.1.18</b> Prior and posterior distribution plot from R</a></li>
<li class="chapter" data-level="6.1.19" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#statistics-typically-reported-in-a-bayesian-analysis"><i class="fa fa-check"></i><b>6.1.19</b> Statistics typically reported in a Bayesian analysis</a></li>
<li class="chapter" data-level="6.1.20" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#interpretation-of-the-bayesian-credible-interval-cri"><i class="fa fa-check"></i><b>6.1.20</b> Interpretation of the Bayesian credible interval (CrI)</a></li>
<li class="chapter" data-level="6.1.21" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#mean-e.-coli-counts-hypothesis-testing-vs.-confidence-interval-vs.-bayesian-inference"><i class="fa fa-check"></i><b>6.1.21</b> Mean E. coli counts: Hypothesis testing vs.Â confidence interval vs.Â Bayesian inference</a></li>
<li class="chapter" data-level="6.1.22" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#beach-water-quality-informative-prior-distribution"><i class="fa fa-check"></i><b>6.1.22</b> Beach Water Quality: Informative prior distribution</a></li>
<li class="chapter" data-level="6.1.23" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#expressing-the-95-ci-from-earlier-data-as-a-normal-distribution"><i class="fa fa-check"></i><b>6.1.23</b> Expressing the 95% CI from earlier data as a normal distribution</a></li>
<li class="chapter" data-level="6.1.24" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#beach-water-quality-example-informative-prior"><i class="fa fa-check"></i><b>6.1.24</b> Beach Water Quality Example: Informative prior</a></li>
<li class="chapter" data-level="6.1.25" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#non-informative-prior"><i class="fa fa-check"></i><b>6.1.25</b> Non-informative prior</a></li>
<li class="chapter" data-level="6.1.26" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#results-with-non-informative-vs.-informative-prior"><i class="fa fa-check"></i><b>6.1.26</b> Results with non-informative vs.Â informative prior</a></li>
<li class="chapter" data-level="6.1.27" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#r-code-for-bayesian-analysis"><i class="fa fa-check"></i><b>6.1.27</b> R code for Bayesian analysis</a></li>
<li class="chapter" data-level="6.1.28" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#beach-water-quality-example"><i class="fa fa-check"></i><b>6.1.28</b> Beach Water Quality Example</a></li>
<li class="chapter" data-level="6.1.29" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#example-renal-denervation"><i class="fa fa-check"></i><b>6.1.29</b> Example: Renal Denervation</a></li>
<li class="chapter" data-level="6.1.30" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#re-analysis-of-renal-denervation-data-using-a-bayesian-approach"><i class="fa fa-check"></i><b>6.1.30</b> Re-analysis of Renal Denervation data using a Bayesian approach</a></li>
<li class="chapter" data-level="6.1.31" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#posterior-distributions"><i class="fa fa-check"></i><b>6.1.31</b> Posterior distributions</a></li>
<li class="chapter" data-level="6.1.32" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#posterior-distribution-of-the-difference-between-the-two-groups"><i class="fa fa-check"></i><b>6.1.32</b> Posterior distribution of the difference between the two groups</a></li>
<li class="chapter" data-level="6.1.33" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#posterior-distribution-of-the-difference-between-the-two-groups-1"><i class="fa fa-check"></i><b>6.1.33</b> Posterior distribution of the difference between the two groups</a></li>
<li class="chapter" data-level="6.1.34" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#summary-of-results-hypothesis-testing-vs.-confidence-interval-vs.-bayesian-inference"><i class="fa fa-check"></i><b>6.1.34</b> Summary of results: Hypothesis testing vs.Â confidence interval vs.Â Bayesian inference</a></li>
<li class="chapter" data-level="6.1.35" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#update-on-the-renal-denervation-story"><i class="fa fa-check"></i><b>6.1.35</b> Update on the renal denervation story</a></li>
<li class="chapter" data-level="6.1.36" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#why-is-bayesian-inference-not-used-more-widely"><i class="fa fa-check"></i><b>6.1.36</b> Why is Bayesian inference not used more widely?</a></li>
<li class="chapter" data-level="6.1.37" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#are-bayesian-methods-worth-the-effort"><i class="fa fa-check"></i><b>6.1.37</b> Are Bayesian methods worth the effort?</a></li>
<li class="chapter" data-level="6.1.38" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#are-bayesian-methods-complex"><i class="fa fa-check"></i><b>6.1.38</b> Are Bayesian methods complex?</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#risk-of-incorrect-conclusions-with-hypothesis-testing"><i class="fa fa-check"></i><b>6.2</b> Risk of incorrect conclusions with hypothesis testing</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#concerns-with-hypothesis-testing"><i class="fa fa-check"></i><b>6.2.1</b> Concerns with hypothesis testing</a></li>
<li class="chapter" data-level="6.2.2" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#optimizing-decision-making"><i class="fa fa-check"></i><b>6.2.2</b> Optimizing decision making<span class="math inline">\(^*\)</span></a></li>
<li class="chapter" data-level="6.2.3" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#concerns-with-p-values"><i class="fa fa-check"></i><b>6.2.3</b> Concerns with p-values</a></li>
<li class="chapter" data-level="6.2.4" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#factors-that-influence-the-accuracy-of-hypothesis-testing"><i class="fa fa-check"></i><b>6.2.4</b> Factors that influence the accuracy of hypothesis testing</a></li>
<li class="chapter" data-level="6.2.5" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#probabilities-of-true-and-false-reporting"><i class="fa fa-check"></i><b>6.2.5</b> Probabilities of true and false reporting<span class="math inline">\(^*\)</span></a></li>
<li class="chapter" data-level="6.2.6" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#illustration-from-nuzzo-et-al."><i class="fa fa-check"></i><b>6.2.6</b> Illustration from Nuzzo et al.</a></li>
<li class="chapter" data-level="6.2.7" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#illustration-of-true-and-false-reporting-probabilities"><i class="fa fa-check"></i><b>6.2.7</b> Illustration of true and false reporting probabilities</a></li>
<li class="chapter" data-level="6.2.8" data-path="lecture-6-bayesian-inference-for-means.html"><a href="lecture-6-bayesian-inference-for-means.html#pre-study-odds-of-h0h1"><i class="fa fa-check"></i><b>6.2.8</b> Pre-study odds of H0:H1</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html"><i class="fa fa-check"></i><b>7</b> Lecture 7: Statistical inference for proportions</a>
<ul>
<li class="chapter" data-level="7.1" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#when-is-a-single-proportion-used"><i class="fa fa-check"></i><b>7.1</b> When is a single proportion used?</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#central-limit-theorem-2"><i class="fa fa-check"></i><b>7.1.1</b> Central Limit Theorem</a></li>
<li class="chapter" data-level="7.1.2" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#application-of-the-central-limit-theorem-normal-approximation-to-the-binomial-distribution"><i class="fa fa-check"></i><b>7.1.2</b> Application of the Central Limit Theorem: Normal Approximation to the Binomial Distribution</a></li>
<li class="chapter" data-level="7.1.3" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#sampling-distributions-when-Ï0.1"><i class="fa fa-check"></i><b>7.1.3</b> Sampling distributions when Ï=0.1</a></li>
<li class="chapter" data-level="7.1.4" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#sampling-distributions-when-Ï0.5"><i class="fa fa-check"></i><b>7.1.4</b> Sampling distributions when Ï=0.5</a></li>
<li class="chapter" data-level="7.1.5" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#sampling-distributions-when-Ï0.9"><i class="fa fa-check"></i><b>7.1.5</b> Sampling distributions when Ï=0.9</a></li>
<li class="chapter" data-level="7.1.6" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#sampling-distribution-of-a-binomial-variable"><i class="fa fa-check"></i><b>7.1.6</b> Sampling distribution of a Binomial variable</a></li>
<li class="chapter" data-level="7.1.7" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#normal-approximation-to-the-binomial-distribution"><i class="fa fa-check"></i><b>7.1.7</b> Normal approximation to the Binomial distribution</a></li>
<li class="chapter" data-level="7.1.8" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#example-4-estimating-the-number-of-true-positives"><i class="fa fa-check"></i><b>7.1.8</b> Example 4: Estimating the number of true positives</a></li>
<li class="chapter" data-level="7.1.9" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#example-4-applying-a-continuity-correction"><i class="fa fa-check"></i><b>7.1.9</b> Example 4: Applying a continuity correction</a></li>
<li class="chapter" data-level="7.1.10" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#continuity-correction"><i class="fa fa-check"></i><b>7.1.10</b> Continuity correction</a></li>
<li class="chapter" data-level="7.1.11" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#example-4"><i class="fa fa-check"></i><b>7.1.11</b> Example</a></li>
<li class="chapter" data-level="7.1.12" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#comparison-with-the-exact-results-based-on-the-binomial-distribution"><i class="fa fa-check"></i><b>7.1.12</b> Comparison with the exact results based on the Binomial distribution</a></li>
<li class="chapter" data-level="7.1.13" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#example-asymptomatic-colonization-with-clostridium-difficile"><i class="fa fa-check"></i><b>7.1.13</b> Example: Asymptomatic colonization with Clostridium difficile</a></li>
<li class="chapter" data-level="7.1.14" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#asymptomatic-colonization-with-clostridium-difficile-selected-results"><i class="fa fa-check"></i><b>7.1.14</b> Asymptomatic colonization with Clostridium difficile: Selected results</a></li>
<li class="chapter" data-level="7.1.15" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#example-asymptomatic-colonization-with-clostridium-difficile-1"><i class="fa fa-check"></i><b>7.1.15</b> Example: Asymptomatic colonization with Clostridium difficile</a></li>
<li class="chapter" data-level="7.1.16" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#methods-for-means-vs.-proportions"><i class="fa fa-check"></i><b>7.1.16</b> Methods for means vs.Â proportions</a></li>
<li class="chapter" data-level="7.1.17" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#analogy-between-calculation-of-means-and-proportions"><i class="fa fa-check"></i><b>7.1.17</b> Analogy between calculation of means and proportions</a></li>
<li class="chapter" data-level="7.1.18" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#frequentist-confidence-interval-for-a-single-proportion"><i class="fa fa-check"></i><b>7.1.18</b> Frequentist confidence interval for a single proportion</a></li>
<li class="chapter" data-level="7.1.19" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#large-sample-confidence-interval-for-a-proportion"><i class="fa fa-check"></i><b>7.1.19</b> Large sample confidence interval for a proportion</a></li>
<li class="chapter" data-level="7.1.20" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#exact-confidence-interval-for-a-proportion"><i class="fa fa-check"></i><b>7.1.20</b> Exact confidence interval for a proportion</a></li>
<li class="chapter" data-level="7.1.21" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#clopper-pearson-exact-confidence-interval-for-a-proportion-biometrika-1934"><i class="fa fa-check"></i><b>7.1.21</b> Clopper-Pearson exact confidence interval for a proportion (Biometrika, 1934)</a></li>
<li class="chapter" data-level="7.1.22" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#exact-confidence-interval-for-a-proportion-1"><i class="fa fa-check"></i><b>7.1.22</b> Exact confidence interval for a proportion<span class="math inline">\(^*\)</span></a></li>
<li class="chapter" data-level="7.1.23" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#r-function-to-obtain-a-confidence-interval-for-a-small-proportion"><i class="fa fa-check"></i><b>7.1.23</b> R function to obtain a confidence interval for a small proportion</a></li>
<li class="chapter" data-level="7.1.24" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#exact-confidence-interval-for-a-proportion-2"><i class="fa fa-check"></i><b>7.1.24</b> Exact confidence interval for a proportion</a></li>
<li class="chapter" data-level="7.1.25" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#how-do-you-determine-if-your-sample-is-sufficiently-large"><i class="fa fa-check"></i><b>7.1.25</b> How do you determine if your sample is sufficiently large?</a></li>
<li class="chapter" data-level="7.1.26" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#example-zero-proportion"><i class="fa fa-check"></i><b>7.1.26</b> Example: Zero proportion</a></li>
<li class="chapter" data-level="7.1.27" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#example-binom.test"><i class="fa fa-check"></i><b>7.1.27</b> Example: binom.test()</a></li>
<li class="chapter" data-level="7.1.28" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#example-asymptomatic-colonization-with-c.-difficile"><i class="fa fa-check"></i><b>7.1.28</b> Example: Asymptomatic colonization with C. difficile</a></li>
<li class="chapter" data-level="7.1.29" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#exact-or-approximate-ci"><i class="fa fa-check"></i><b>7.1.29</b> Exact or approximate CI?</a></li>
<li class="chapter" data-level="7.1.30" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#ci-for-proportion"><i class="fa fa-check"></i><b>7.1.30</b> 95% CI for proportion</a></li>
<li class="chapter" data-level="7.1.31" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#exact-or-approximate-ci-1"><i class="fa fa-check"></i><b>7.1.31</b> Exact or approximate CI?</a></li>
<li class="chapter" data-level="7.1.32" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#exact-95-equal-tailed-confidence-interval-for-proportion-of-probiotic-use"><i class="fa fa-check"></i><b>7.1.32</b> Exact 95% equal-tailed confidence interval for proportion of probiotic use</a></li>
<li class="chapter" data-level="7.1.33" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#confidence-intervals-for-proportion-of-patients-with-risk-factor-among-patients-asymptomatically-colonized-with-c.-difficile"><i class="fa fa-check"></i><b>7.1.33</b> 95% confidence intervals for proportion of patients with risk factor among patients asymptomatically colonized with C. difficile</a></li>
<li class="chapter" data-level="7.1.34" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#statistics-used-to-compare-two-proportions-p_1-and-p_2"><i class="fa fa-check"></i><b>7.1.34</b> Statistics used to compare two proportions <span class="math inline">\(p_1\)</span> and <span class="math inline">\(p_2\)</span></a></li>
<li class="chapter" data-level="7.1.35" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#example-probiotics-for-prevention-of-cdad"><i class="fa fa-check"></i><b>7.1.35</b> Example: Probiotics for prevention of CDAD</a></li>
<li class="chapter" data-level="7.1.36" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#results-from-two-randomized-controlled-trials"><i class="fa fa-check"></i><b>7.1.36</b> Results from two randomized controlled trials</a></li>
<li class="chapter" data-level="7.1.37" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#forest-plot-of-relative-risk-from-10-studies"><i class="fa fa-check"></i><b>7.1.37</b> Forest plot of relative risk from 10 studies<span class="math inline">\(^*\)</span></a></li>
<li class="chapter" data-level="7.1.38" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#results-from-two-randomized-controlled-trials-1"><i class="fa fa-check"></i><b>7.1.38</b> Results from two randomized controlled trials</a></li>
<li class="chapter" data-level="7.1.39" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#confidence-interval-for-the-difference-between-two-proportions"><i class="fa fa-check"></i><b>7.1.39</b> Confidence Interval for the difference between two proportions</a></li>
<li class="chapter" data-level="7.1.40" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#hypothesis-test-for-comparing-two-proportions"><i class="fa fa-check"></i><b>7.1.40</b> Hypothesis test for comparing two proportions</a></li>
<li class="chapter" data-level="7.1.41" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#probiotics-example-confidence-interval-for-difference-in-proportions"><i class="fa fa-check"></i><b>7.1.41</b> Probiotics example: Confidence interval for difference in proportions</a></li>
<li class="chapter" data-level="7.1.42" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#probiotics-example-hypothesis-test"><i class="fa fa-check"></i><b>7.1.42</b> Probiotics example: Hypothesis test</a></li>
<li class="chapter" data-level="7.1.43" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#probiotics-example-results-for-both-studies"><i class="fa fa-check"></i><b>7.1.43</b> Probiotics example: Results for both studies</a></li>
<li class="chapter" data-level="7.1.44" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#comparing-two-proportions-in-r"><i class="fa fa-check"></i><b>7.1.44</b> Comparing two proportions in R</a></li>
<li class="chapter" data-level="7.1.45" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#probiotics-example-obtaining-the-results-in-r"><i class="fa fa-check"></i><b>7.1.45</b> Probiotics example: Obtaining the results in R</a></li>
<li class="chapter" data-level="7.1.46" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#number-needed-to-treat"><i class="fa fa-check"></i><b>7.1.46</b> Number needed to treat</a></li>
<li class="chapter" data-level="7.1.47" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#probiotics-example-number-needed-to-treat"><i class="fa fa-check"></i><b>7.1.47</b> Probiotics example: Number needed to treat</a></li>
<li class="chapter" data-level="7.1.48" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#confidence-interval-for-number-needed-to-treat"><i class="fa fa-check"></i><b>7.1.48</b> Confidence interval for number needed to treat</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#sample-size-determination-for-studies-of-proportions"><i class="fa fa-check"></i><b>7.2</b> Sample size determination for studies of proportions</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#sample-size-for-desired-margin-of-error"><i class="fa fa-check"></i><b>7.2.1</b> Sample Size For Desired Margin Of Error</a></li>
<li class="chapter" data-level="7.2.2" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#sample-size-for-desired-power-and-type-i-error"><i class="fa fa-check"></i><b>7.2.2</b> Sample Size For Desired Power And Type I Error</a></li>
<li class="chapter" data-level="7.2.3" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#example-5"><i class="fa fa-check"></i><b>7.2.3</b> Example</a></li>
<li class="chapter" data-level="7.2.4" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#planning-a-study-to-compare-proportions"><i class="fa fa-check"></i><b>7.2.4</b> Planning a study to compare proportions</a></li>
<li class="chapter" data-level="7.2.5" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#sample-size-formulae"><i class="fa fa-check"></i><b>7.2.5</b> Sample size formulae</a></li>
<li class="chapter" data-level="7.2.6" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#example-6"><i class="fa fa-check"></i><b>7.2.6</b> Example</a></li>
<li class="chapter" data-level="7.2.7" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#inputs-for-the-sample-size-calculation"><i class="fa fa-check"></i><b>7.2.7</b> Inputs for the sample size calculation</a></li>
<li class="chapter" data-level="7.2.8" data-path="lecture-7-statistical-inference-for-proportions.html"><a href="lecture-7-statistical-inference-for-proportions.html#example-7"><i class="fa fa-check"></i><b>7.2.8</b> Example</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html"><a href="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html"><i class="fa fa-check"></i><b>8</b> Lecture 8: Other statistics for comparing proportions and methods for contingency tables</a>
<ul>
<li class="chapter" data-level="8.1" data-path="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html"><a href="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html#odds"><i class="fa fa-check"></i><b>8.1</b> Odds</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html"><a href="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html#odds-ratio-and-relative-risk"><i class="fa fa-check"></i><b>8.1.1</b> Odds Ratio and Relative Risk</a></li>
<li class="chapter" data-level="8.1.2" data-path="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html"><a href="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html#confidence-interval-for-an-odds-ratio"><i class="fa fa-check"></i><b>8.1.2</b> Confidence interval for an odds ratio</a></li>
<li class="chapter" data-level="8.1.3" data-path="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html"><a href="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html#confidence-interval-for-the-relative-risk"><i class="fa fa-check"></i><b>8.1.3</b> Confidence interval for the relative risk</a></li>
<li class="chapter" data-level="8.1.4" data-path="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html"><a href="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html#probiotics-example-results-for-both-studies-1"><i class="fa fa-check"></i><b>8.1.4</b> Probiotics example: Results for both studies</a></li>
<li class="chapter" data-level="8.1.5" data-path="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html"><a href="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html#probiotics-and-cdad-rearranging-the-data"><i class="fa fa-check"></i><b>8.1.5</b> Probiotics and CDAD: Rearranging the data</a></li>
<li class="chapter" data-level="8.1.6" data-path="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html"><a href="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html#r-function-for-odds-ratio-and-relative-risk"><i class="fa fa-check"></i><b>8.1.6</b> R function for odds ratio and relative risk</a></li>
<li class="chapter" data-level="8.1.7" data-path="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html"><a href="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html#example-probiotics-and-cdad"><i class="fa fa-check"></i><b>8.1.7</b> Example: Probiotics and CDAD</a></li>
<li class="chapter" data-level="8.1.8" data-path="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html"><a href="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html#example-95-confidence-intervals-for-gao-et-al."><i class="fa fa-check"></i><b>8.1.8</b> Example: 95% confidence intervals for Gao et al.</a></li>
<li class="chapter" data-level="8.1.9" data-path="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html"><a href="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html#example-95-confidence-intervals-for-otitis-data"><i class="fa fa-check"></i><b>8.1.9</b> Example: 95% confidence intervals for otitis data</a></li>
<li class="chapter" data-level="8.1.10" data-path="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html"><a href="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html#example-probiotics-and-cdad-1"><i class="fa fa-check"></i><b>8.1.10</b> Example: Probiotics and CDAD</a></li>
<li class="chapter" data-level="8.1.11" data-path="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html"><a href="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html#risk-ratio-vs.-risk-difference"><i class="fa fa-check"></i><b>8.1.11</b> Risk ratio vs.Â risk difference</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html"><a href="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html#methods-for-contingency-tables"><i class="fa fa-check"></i><b>8.2</b> Methods for contingency tables</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html"><a href="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html#comparing-two-or-more-proportions-the-generic-setup"><i class="fa fa-check"></i><b>8.2.1</b> Comparing Two or More Proportions: The generic setup</a></li>
<li class="chapter" data-level="8.2.2" data-path="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html"><a href="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html#examples-from-two-randomized-controlled-trials"><i class="fa fa-check"></i><b>8.2.2</b> Examples from two randomized controlled trials</a></li>
<li class="chapter" data-level="8.2.3" data-path="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html"><a href="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html#r-code-to-examine-an-r-c-table"><i class="fa fa-check"></i><b>8.2.3</b> R code to examine an r Ã c table</a></li>
<li class="chapter" data-level="8.2.4" data-path="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html"><a href="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html#output-from-r"><i class="fa fa-check"></i><b>8.2.4</b> Output from R</a></li>
<li class="chapter" data-level="8.2.5" data-path="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html"><a href="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html#hypothesis-tests-to-compare-two-or-more-proportions"><i class="fa fa-check"></i><b>8.2.5</b> Hypothesis tests to compare two or more proportions</a></li>
<li class="chapter" data-level="8.2.6" data-path="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html"><a href="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html#methods-to-compare-two-or-more-proportions"><i class="fa fa-check"></i><b>8.2.6</b> Methods to Compare Two or More Proportions</a></li>
<li class="chapter" data-level="8.2.7" data-path="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html"><a href="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html#examples-from-two-randomized-controlled-trials-1"><i class="fa fa-check"></i><b>8.2.7</b> Examples from two randomized controlled trials</a></li>
<li class="chapter" data-level="8.2.8" data-path="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html"><a href="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html#methods-to-compare-two-or-more-proportions-1"><i class="fa fa-check"></i><b>8.2.8</b> Methods to Compare Two or More Proportions</a></li>
<li class="chapter" data-level="8.2.9" data-path="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html"><a href="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html#which-method-do-we-use"><i class="fa fa-check"></i><b>8.2.9</b> Which method do we use?</a></li>
<li class="chapter" data-level="8.2.10" data-path="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html"><a href="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html#hypothesis-test-for-comparing-two-or-more-proportions"><i class="fa fa-check"></i><b>8.2.10</b> Hypothesis test for comparing two or more proportions</a></li>
<li class="chapter" data-level="8.2.11" data-path="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html"><a href="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html#example-one-sample-chi2-test"><i class="fa fa-check"></i><b>8.2.11</b> Example: One Sample <span class="math inline">\(\chi^2\)</span> test</a></li>
<li class="chapter" data-level="8.2.12" data-path="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html"><a href="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html#calculating-the-p-value-under-a-chi-square-distribution"><i class="fa fa-check"></i><b>8.2.12</b> Calculating the p-value under a chi-square distribution</a></li>
<li class="chapter" data-level="8.2.13" data-path="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html"><a href="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html#example-two-sample-chi2-test"><i class="fa fa-check"></i><b>8.2.13</b> Example: Two sample <span class="math inline">\(\chi^2\)</span> Test</a></li>
<li class="chapter" data-level="8.2.14" data-path="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html"><a href="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html#example-chi2-test-for-the-2-x-3-table"><i class="fa fa-check"></i><b>8.2.14</b> Example: <span class="math inline">\(\chi^2\)</span> test for the 2 x 3 Table</a></li>
<li class="chapter" data-level="8.2.15" data-path="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html"><a href="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html#some-more-notes-on-the-chi-square-test"><i class="fa fa-check"></i><b>8.2.15</b> Some more notes on the chi-square test</a></li>
<li class="chapter" data-level="8.2.16" data-path="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html"><a href="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html#chi-square-test-in-r"><i class="fa fa-check"></i><b>8.2.16</b> Chi-square test in R</a></li>
<li class="chapter" data-level="8.2.17" data-path="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html"><a href="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html#chi-square-test-for-a-single-proportion"><i class="fa fa-check"></i><b>8.2.17</b> Chi-square test for a single proportion</a></li>
<li class="chapter" data-level="8.2.18" data-path="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html"><a href="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html#two-sample-chi2-test-in-r"><i class="fa fa-check"></i><b>8.2.18</b> Two sample <span class="math inline">\(\chi^2\)</span> Test in R</a></li>
<li class="chapter" data-level="8.2.19" data-path="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html"><a href="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html#three-sample-chi2-test-in-r"><i class="fa fa-check"></i><b>8.2.19</b> Three sample <span class="math inline">\(\chi^2\)</span> Test in R</a></li>
<li class="chapter" data-level="8.2.20" data-path="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html"><a href="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html#example-ecmo"><i class="fa fa-check"></i><b>8.2.20</b> Example: ECMO<span class="math inline">\(^*\)</span></a></li>
<li class="chapter" data-level="8.2.21" data-path="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html"><a href="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html#example-fishers-exact-test"><i class="fa fa-check"></i><b>8.2.21</b> Example: Fisherâs Exact Test</a></li>
<li class="chapter" data-level="8.2.22" data-path="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html"><a href="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html#fishers-exact-test"><i class="fa fa-check"></i><b>8.2.22</b> Fisherâs exact test</a></li>
<li class="chapter" data-level="8.2.23" data-path="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html"><a href="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html#example-fishers-exact-test-1"><i class="fa fa-check"></i><b>8.2.23</b> Example: Fisherâs exact test</a></li>
<li class="chapter" data-level="8.2.24" data-path="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html"><a href="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html#calculation-of-p-value-for-fishers-exact-test"><i class="fa fa-check"></i><b>8.2.24</b> Calculation of p-value for Fisherâs exact test</a></li>
<li class="chapter" data-level="8.2.25" data-path="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html"><a href="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html#fishers-exact-test-1"><i class="fa fa-check"></i><b>8.2.25</b> Fisherâs exact test</a></li>
<li class="chapter" data-level="8.2.26" data-path="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html"><a href="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html#carrying-out-fishers-exact-test-in-r---two-sided-alternative"><i class="fa fa-check"></i><b>8.2.26</b> Carrying out Fisherâs exact test in R - two-sided alternative</a></li>
<li class="chapter" data-level="8.2.27" data-path="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html"><a href="lecture-8-other-statistics-for-comparing-proportions-and-methods-for-contingency-tables.html#carrying-out-fishers-exact-test-in-r---one--sided-alternative"><i class="fa fa-check"></i><b>8.2.27</b> Carrying out Fisherâs exact test in R - one -sided alternative</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="lecture-9-non-parametric-methods.html"><a href="lecture-9-non-parametric-methods.html"><i class="fa fa-check"></i><b>9</b> Lecture 9: Non-parametric methods</a>
<ul>
<li class="chapter" data-level="9.1" data-path="lecture-9-non-parametric-methods.html"><a href="lecture-9-non-parametric-methods.html#parametric-inference"><i class="fa fa-check"></i><b>9.1</b> Parametric Inference</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="lecture-9-non-parametric-methods.html"><a href="lecture-9-non-parametric-methods.html#examples"><i class="fa fa-check"></i><b>9.1.1</b> Examples<span class="math inline">\(^*\)</span></a></li>
<li class="chapter" data-level="9.1.2" data-path="lecture-9-non-parametric-methods.html"><a href="lecture-9-non-parametric-methods.html#non-parametric-inference"><i class="fa fa-check"></i><b>9.1.2</b> Non-Parametric Inference</a></li>
<li class="chapter" data-level="9.1.3" data-path="lecture-9-non-parametric-methods.html"><a href="lecture-9-non-parametric-methods.html#hypothesis-testing-procedure"><i class="fa fa-check"></i><b>9.1.3</b> Hypothesis testing procedure</a></li>
<li class="chapter" data-level="9.1.4" data-path="lecture-9-non-parametric-methods.html"><a href="lecture-9-non-parametric-methods.html#example-comparison-of-two-matched-samples"><i class="fa fa-check"></i><b>9.1.4</b> Example: Comparison of Two Matched Samples</a></li>
<li class="chapter" data-level="9.1.5" data-path="lecture-9-non-parametric-methods.html"><a href="lecture-9-non-parametric-methods.html#example-8"><i class="fa fa-check"></i><b>9.1.5</b> Example</a></li>
<li class="chapter" data-level="9.1.6" data-path="lecture-9-non-parametric-methods.html"><a href="lecture-9-non-parametric-methods.html#comparison-of-two-matched-samples-the-sign-test"><i class="fa fa-check"></i><b>9.1.6</b> Comparison of Two Matched Samples: The Sign Test</a></li>
<li class="chapter" data-level="9.1.7" data-path="lecture-9-non-parametric-methods.html"><a href="lecture-9-non-parametric-methods.html#the-sign-test-the-test-statistic"><i class="fa fa-check"></i><b>9.1.7</b> The Sign Test: The test statistic</a></li>
<li class="chapter" data-level="9.1.8" data-path="lecture-9-non-parametric-methods.html"><a href="lecture-9-non-parametric-methods.html#the-sign-test-calculating-the-p-value"><i class="fa fa-check"></i><b>9.1.8</b> The Sign Test: Calculating the p-value</a></li>
<li class="chapter" data-level="9.1.9" data-path="lecture-9-non-parametric-methods.html"><a href="lecture-9-non-parametric-methods.html#example-9"><i class="fa fa-check"></i><b>9.1.9</b> Example</a></li>
<li class="chapter" data-level="9.1.10" data-path="lecture-9-non-parametric-methods.html"><a href="lecture-9-non-parametric-methods.html#carrying-out-the-sign-test-in-r"><i class="fa fa-check"></i><b>9.1.10</b> Carrying out the Sign Test in R</a></li>
<li class="chapter" data-level="9.1.11" data-path="lecture-9-non-parametric-methods.html"><a href="lecture-9-non-parametric-methods.html#are-non-parameteric-methods-really-distribution-free"><i class="fa fa-check"></i><b>9.1.11</b> Are non-parameteric methods really âdistribution freeâ?</a></li>
<li class="chapter" data-level="9.1.12" data-path="lecture-9-non-parametric-methods.html"><a href="lecture-9-non-parametric-methods.html#comparison-of-two-matched-samples-the-wilcoxon-signed-rank-test"><i class="fa fa-check"></i><b>9.1.12</b> Comparison of Two Matched Samples: The Wilcoxon Signed Rank Test</a></li>
<li class="chapter" data-level="9.1.13" data-path="lecture-9-non-parametric-methods.html"><a href="lecture-9-non-parametric-methods.html#example-wilcoxon-signed-rank-test"><i class="fa fa-check"></i><b>9.1.13</b> Example: Wilcoxon Signed Rank Test</a></li>
<li class="chapter" data-level="9.1.14" data-path="lecture-9-non-parametric-methods.html"><a href="lecture-9-non-parametric-methods.html#wilcoxon-signed-rank-test-in-r"><i class="fa fa-check"></i><b>9.1.14</b> Wilcoxon Signed Rank Test in R</a></li>
<li class="chapter" data-level="9.1.15" data-path="lecture-9-non-parametric-methods.html"><a href="lecture-9-non-parametric-methods.html#normal-approximation-to-the-sign-and-wilcoxon-signed-rank-tests"><i class="fa fa-check"></i><b>9.1.15</b> Normal approximation to the Sign and Wilcoxon Signed Rank Tests</a></li>
<li class="chapter" data-level="9.1.16" data-path="lecture-9-non-parametric-methods.html"><a href="lecture-9-non-parametric-methods.html#normal-approximation-to-the-wilcoxon-signed-rank-test"><i class="fa fa-check"></i><b>9.1.16</b> Normal approximation to the Wilcoxon Signed Rank Test</a></li>
<li class="chapter" data-level="9.1.17" data-path="lecture-9-non-parametric-methods.html"><a href="lecture-9-non-parametric-methods.html#comparison-of-two-unmatched-samples"><i class="fa fa-check"></i><b>9.1.17</b> Comparison of two unmatched samples</a></li>
<li class="chapter" data-level="9.1.18" data-path="lecture-9-non-parametric-methods.html"><a href="lecture-9-non-parametric-methods.html#wilcoxon-rank-sum-test"><i class="fa fa-check"></i><b>9.1.18</b> Wilcoxon Rank Sum Test</a></li>
<li class="chapter" data-level="9.1.19" data-path="lecture-9-non-parametric-methods.html"><a href="lecture-9-non-parametric-methods.html#wilcoxon-rank-sum-test-calculation-of-the-test-statistic"><i class="fa fa-check"></i><b>9.1.19</b> Wilcoxon Rank Sum Test: Calculation of the test statistic</a></li>
<li class="chapter" data-level="9.1.20" data-path="lecture-9-non-parametric-methods.html"><a href="lecture-9-non-parametric-methods.html#exact-wilcoxon-rank-sum-test"><i class="fa fa-check"></i><b>9.1.20</b> Exact Wilcoxon Rank Sum Test</a></li>
<li class="chapter" data-level="9.1.21" data-path="lecture-9-non-parametric-methods.html"><a href="lecture-9-non-parametric-methods.html#example-wilcoxon-rank-sum-test"><i class="fa fa-check"></i><b>9.1.21</b> Example: Wilcoxon Rank Sum Test</a></li>
<li class="chapter" data-level="9.1.22" data-path="lecture-9-non-parametric-methods.html"><a href="lecture-9-non-parametric-methods.html#approximate-wilcoxon-rank-sum-test"><i class="fa fa-check"></i><b>9.1.22</b> Approximate Wilcoxon Rank Sum Test</a></li>
<li class="chapter" data-level="9.1.23" data-path="lecture-9-non-parametric-methods.html"><a href="lecture-9-non-parametric-methods.html#wilcoxon-rank-sum-test-in-r"><i class="fa fa-check"></i><b>9.1.23</b> Wilcoxon Rank Sum Test in R</a></li>
<li class="chapter" data-level="9.1.24" data-path="lecture-9-non-parametric-methods.html"><a href="lecture-9-non-parametric-methods.html#summary-of-hypothesis-tests-covered-in-this-course"><i class="fa fa-check"></i><b>9.1.24</b> Summary of hypothesis tests covered in this course</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="lecture-9-non-parametric-methods.html"><a href="lecture-9-non-parametric-methods.html#bootstrap-confidence-interval"><i class="fa fa-check"></i><b>9.2</b> Bootstrap confidence interval</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="lecture-9-non-parametric-methods.html"><a href="lecture-9-non-parametric-methods.html#confidence-intervals-vs.-hypothesis-testing"><i class="fa fa-check"></i><b>9.2.1</b> Confidence intervals vs.Â Hypothesis Testing</a></li>
<li class="chapter" data-level="9.2.2" data-path="lecture-9-non-parametric-methods.html"><a href="lecture-9-non-parametric-methods.html#bootstrap-confidence-intervals"><i class="fa fa-check"></i><b>9.2.2</b> Bootstrap confidence intervals</a></li>
<li class="chapter" data-level="9.2.3" data-path="lecture-9-non-parametric-methods.html"><a href="lecture-9-non-parametric-methods.html#bootstrap-example"><i class="fa fa-check"></i><b>9.2.3</b> Bootstrap: Example<span class="math inline">\(^*\)</span></a></li>
<li class="chapter" data-level="9.2.4" data-path="lecture-9-non-parametric-methods.html"><a href="lecture-9-non-parametric-methods.html#the-empirical-bootstrap"><i class="fa fa-check"></i><b>9.2.4</b> The empirical bootstrap</a></li>
<li class="chapter" data-level="9.2.5" data-path="lecture-9-non-parametric-methods.html"><a href="lecture-9-non-parametric-methods.html#example-10"><i class="fa fa-check"></i><b>9.2.5</b> Example</a></li>
<li class="chapter" data-level="9.2.6" data-path="lecture-9-non-parametric-methods.html"><a href="lecture-9-non-parametric-methods.html#r-code-for-bootstrap"><i class="fa fa-check"></i><b>9.2.6</b> R code for bootstrap</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="lecture-10-analysis-of-variance-anova.html"><a href="lecture-10-analysis-of-variance-anova.html"><i class="fa fa-check"></i><b>10</b> Lecture 10: Analysis of Variance (ANOVA)</a>
<ul>
<li class="chapter" data-level="10.1" data-path="lecture-10-analysis-of-variance-anova.html"><a href="lecture-10-analysis-of-variance-anova.html#introduction-1"><i class="fa fa-check"></i><b>10.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="10.1.1" data-path="lecture-10-analysis-of-variance-anova.html"><a href="lecture-10-analysis-of-variance-anova.html#example-mao-and-schizophrenia"><i class="fa fa-check"></i><b>10.1.1</b> Example: MAO and Schizophrenia</a></li>
<li class="chapter" data-level="10.1.2" data-path="lecture-10-analysis-of-variance-anova.html"><a href="lecture-10-analysis-of-variance-anova.html#why-not-answer-these-questions-with-repeated-t-tests"><i class="fa fa-check"></i><b>10.1.2</b> Why not answer these questions with repeated t-tests?</a></li>
<li class="chapter" data-level="10.1.3" data-path="lecture-10-analysis-of-variance-anova.html"><a href="lecture-10-analysis-of-variance-anova.html#graphical-perspective-on-anova"><i class="fa fa-check"></i><b>10.1.3</b> Graphical perspective on ANOVA</a></li>
<li class="chapter" data-level="10.1.4" data-path="lecture-10-analysis-of-variance-anova.html"><a href="lecture-10-analysis-of-variance-anova.html#one-way-anova"><i class="fa fa-check"></i><b>10.1.4</b> One-way ANOVA</a></li>
<li class="chapter" data-level="10.1.5" data-path="lecture-10-analysis-of-variance-anova.html"><a href="lecture-10-analysis-of-variance-anova.html#one-way-anova-assumptions"><i class="fa fa-check"></i><b>10.1.5</b> One-way ANOVA: Assumptions</a></li>
<li class="chapter" data-level="10.1.6" data-path="lecture-10-analysis-of-variance-anova.html"><a href="lecture-10-analysis-of-variance-anova.html#one-way-anova-notation"><i class="fa fa-check"></i><b>10.1.6</b> One-way ANOVA: Notation</a></li>
<li class="chapter" data-level="10.1.7" data-path="lecture-10-analysis-of-variance-anova.html"><a href="lecture-10-analysis-of-variance-anova.html#one-way-anova-mao-and-schizophrenia"><i class="fa fa-check"></i><b>10.1.7</b> One-way ANOVA: MAO and Schizophrenia</a></li>
<li class="chapter" data-level="10.1.8" data-path="lecture-10-analysis-of-variance-anova.html"><a href="lecture-10-analysis-of-variance-anova.html#anova-within-group-variation"><i class="fa fa-check"></i><b>10.1.8</b> ANOVA: Within-group variation</a></li>
<li class="chapter" data-level="10.1.9" data-path="lecture-10-analysis-of-variance-anova.html"><a href="lecture-10-analysis-of-variance-anova.html#mao-within-group-variation"><i class="fa fa-check"></i><b>10.1.9</b> MAO: Within-group variation</a></li>
<li class="chapter" data-level="10.1.10" data-path="lecture-10-analysis-of-variance-anova.html"><a href="lecture-10-analysis-of-variance-anova.html#anova-between-group-variation"><i class="fa fa-check"></i><b>10.1.10</b> ANOVA: Between-group variation</a></li>
<li class="chapter" data-level="10.1.11" data-path="lecture-10-analysis-of-variance-anova.html"><a href="lecture-10-analysis-of-variance-anova.html#mao-between-group-variation"><i class="fa fa-check"></i><b>10.1.11</b> MAO: Between-group variation</a></li>
<li class="chapter" data-level="10.1.12" data-path="lecture-10-analysis-of-variance-anova.html"><a href="lecture-10-analysis-of-variance-anova.html#a-fundamental-relationship-of-anova"><i class="fa fa-check"></i><b>10.1.12</b> A fundamental relationship of ANOVA</a></li>
<li class="chapter" data-level="10.1.13" data-path="lecture-10-analysis-of-variance-anova.html"><a href="lecture-10-analysis-of-variance-anova.html#anova-table"><i class="fa fa-check"></i><b>10.1.13</b> ANOVA table</a></li>
<li class="chapter" data-level="10.1.14" data-path="lecture-10-analysis-of-variance-anova.html"><a href="lecture-10-analysis-of-variance-anova.html#mao-example-anova-table"><i class="fa fa-check"></i><b>10.1.14</b> MAO Example: ANOVA table</a></li>
<li class="chapter" data-level="10.1.15" data-path="lecture-10-analysis-of-variance-anova.html"><a href="lecture-10-analysis-of-variance-anova.html#the-f-test"><i class="fa fa-check"></i><b>10.1.15</b> The F-test</a></li>
<li class="chapter" data-level="10.1.16" data-path="lecture-10-analysis-of-variance-anova.html"><a href="lecture-10-analysis-of-variance-anova.html#mao-example-the-f-test"><i class="fa fa-check"></i><b>10.1.16</b> MAO example: The F-test</a></li>
<li class="chapter" data-level="10.1.17" data-path="lecture-10-analysis-of-variance-anova.html"><a href="lecture-10-analysis-of-variance-anova.html#the-f-distribution"><i class="fa fa-check"></i><b>10.1.17</b> The F-distribution</a></li>
<li class="chapter" data-level="10.1.18" data-path="lecture-10-analysis-of-variance-anova.html"><a href="lecture-10-analysis-of-variance-anova.html#rejection-region"><i class="fa fa-check"></i><b>10.1.18</b> Rejection region</a></li>
<li class="chapter" data-level="10.1.19" data-path="lecture-10-analysis-of-variance-anova.html"><a href="lecture-10-analysis-of-variance-anova.html#mao-example-conclusion"><i class="fa fa-check"></i><b>10.1.19</b> MAO example: Conclusion</a></li>
<li class="chapter" data-level="10.1.20" data-path="lecture-10-analysis-of-variance-anova.html"><a href="lecture-10-analysis-of-variance-anova.html#anova-in-r"><i class="fa fa-check"></i><b>10.1.20</b> ANOVA in R</a></li>
<li class="chapter" data-level="10.1.21" data-path="lecture-10-analysis-of-variance-anova.html"><a href="lecture-10-analysis-of-variance-anova.html#checking-the-assumptions-of-anova"><i class="fa fa-check"></i><b>10.1.21</b> Checking the assumptions of ANOVA</a></li>
<li class="chapter" data-level="10.1.22" data-path="lecture-10-analysis-of-variance-anova.html"><a href="lecture-10-analysis-of-variance-anova.html#residuals-for-mao-example"><i class="fa fa-check"></i><b>10.1.22</b> Residuals for MAO example</a></li>
<li class="chapter" data-level="10.1.23" data-path="lecture-10-analysis-of-variance-anova.html"><a href="lecture-10-analysis-of-variance-anova.html#quantile-quantile-plot-to-check-for-normality"><i class="fa fa-check"></i><b>10.1.23</b> Quantile-quantile plot to check for normality</a></li>
<li class="chapter" data-level="10.1.24" data-path="lecture-10-analysis-of-variance-anova.html"><a href="lecture-10-analysis-of-variance-anova.html#quantile-quantile-qq-plot-for-mao-data"><i class="fa fa-check"></i><b>10.1.24</b> Quantile-quantile (QQ) plot for MAO data</a></li>
<li class="chapter" data-level="10.1.25" data-path="lecture-10-analysis-of-variance-anova.html"><a href="lecture-10-analysis-of-variance-anova.html#residual-plot-to-evaluate-constant-variance-across-groups"><i class="fa fa-check"></i><b>10.1.25</b> Residual plot to evaluate constant variance across groups</a></li>
<li class="chapter" data-level="10.1.26" data-path="lecture-10-analysis-of-variance-anova.html"><a href="lecture-10-analysis-of-variance-anova.html#residuals-for-mao-example-1"><i class="fa fa-check"></i><b>10.1.26</b> Residuals for MAO example</a></li>
<li class="chapter" data-level="10.1.27" data-path="lecture-10-analysis-of-variance-anova.html"><a href="lecture-10-analysis-of-variance-anova.html#multiple-comparisons"><i class="fa fa-check"></i><b>10.1.27</b> Multiple comparisons</a></li>
<li class="chapter" data-level="10.1.28" data-path="lecture-10-analysis-of-variance-anova.html"><a href="lecture-10-analysis-of-variance-anova.html#multiple-comparisons-solutions"><i class="fa fa-check"></i><b>10.1.28</b> Multiple comparisons: Solutions</a></li>
<li class="chapter" data-level="10.1.29" data-path="lecture-10-analysis-of-variance-anova.html"><a href="lecture-10-analysis-of-variance-anova.html#bonferroni-correction"><i class="fa fa-check"></i><b>10.1.29</b> Bonferroni correction</a></li>
<li class="chapter" data-level="10.1.30" data-path="lecture-10-analysis-of-variance-anova.html"><a href="lecture-10-analysis-of-variance-anova.html#bonferroni-correction-for-the-mao-example"><i class="fa fa-check"></i><b>10.1.30</b> Bonferroni correction for the MAO example</a></li>
<li class="chapter" data-level="10.1.31" data-path="lecture-10-analysis-of-variance-anova.html"><a href="lecture-10-analysis-of-variance-anova.html#bonferroni-correction-1"><i class="fa fa-check"></i><b>10.1.31</b> Bonferroni correction</a></li>
<li class="chapter" data-level="10.1.32" data-path="lecture-10-analysis-of-variance-anova.html"><a href="lecture-10-analysis-of-variance-anova.html#tukeys-confidence-interval"><i class="fa fa-check"></i><b>10.1.32</b> Tukeyâs confidence interval</a></li>
<li class="chapter" data-level="10.1.33" data-path="lecture-10-analysis-of-variance-anova.html"><a href="lecture-10-analysis-of-variance-anova.html#results-for-the-mao-data"><i class="fa fa-check"></i><b>10.1.33</b> Results for the MAO data</a></li>
<li class="chapter" data-level="10.1.34" data-path="lecture-10-analysis-of-variance-anova.html"><a href="lecture-10-analysis-of-variance-anova.html#multiple-comparisons-the-debate"><i class="fa fa-check"></i><b>10.1.34</b> Multiple comparisons: The debate</a></li>
<li class="chapter" data-level="10.1.35" data-path="lecture-10-analysis-of-variance-anova.html"><a href="lecture-10-analysis-of-variance-anova.html#steps-involved-in-anova"><i class="fa fa-check"></i><b>10.1.35</b> Steps involved in ANOVA</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="lecture-11-analysis-of-variance-anova-2.html"><a href="lecture-11-analysis-of-variance-anova-2.html"><i class="fa fa-check"></i><b>11</b> Lecture 11: Analysis of Variance (ANOVA) 2</a>
<ul>
<li class="chapter" data-level="11.1" data-path="lecture-11-analysis-of-variance-anova-2.html"><a href="lecture-11-analysis-of-variance-anova-2.html#way-anova-model"><i class="fa fa-check"></i><b>11.1</b> 1-way ANOVA model</a>
<ul>
<li class="chapter" data-level="11.1.1" data-path="lecture-11-analysis-of-variance-anova-2.html"><a href="lecture-11-analysis-of-variance-anova-2.html#extending-the-1-way-anova-model"><i class="fa fa-check"></i><b>11.1.1</b> Extending the 1-way ANOVA model</a></li>
<li class="chapter" data-level="11.1.2" data-path="lecture-11-analysis-of-variance-anova-2.html"><a href="lecture-11-analysis-of-variance-anova-2.html#study-designs-handled-with-2-way-anova-models"><i class="fa fa-check"></i><b>11.1.2</b> Study designs handled with 2-way ANOVA models</a></li>
<li class="chapter" data-level="11.1.3" data-path="lecture-11-analysis-of-variance-anova-2.html"><a href="lecture-11-analysis-of-variance-anova-2.html#example-repeated-measures-design"><i class="fa fa-check"></i><b>11.1.3</b> Example: Repeated Measures Design</a></li>
<li class="chapter" data-level="11.1.4" data-path="lecture-11-analysis-of-variance-anova-2.html"><a href="lecture-11-analysis-of-variance-anova-2.html#number-of-study-units-from-3rs-website-of-michael-festing"><i class="fa fa-check"></i><b>11.1.4</b> Number of study units (from 3rs website of Michael Festing<span class="math inline">\(^*\)</span>)</a></li>
<li class="chapter" data-level="11.1.5" data-path="lecture-11-analysis-of-variance-anova-2.html"><a href="lecture-11-analysis-of-variance-anova-2.html#example-repeated-measures-design-1"><i class="fa fa-check"></i><b>11.1.5</b> Example: Repeated Measures Design</a></li>
<li class="chapter" data-level="11.1.6" data-path="lecture-11-analysis-of-variance-anova-2.html"><a href="lecture-11-analysis-of-variance-anova-2.html#example-2-way-anova-model"><i class="fa fa-check"></i><b>11.1.6</b> Example: 2-way ANOVA model</a></li>
<li class="chapter" data-level="11.1.7" data-path="lecture-11-analysis-of-variance-anova-2.html"><a href="lecture-11-analysis-of-variance-anova-2.html#example-visualizing-the-patient-effects"><i class="fa fa-check"></i><b>11.1.7</b> Example: Visualizing the patient-effects</a></li>
<li class="chapter" data-level="11.1.8" data-path="lecture-11-analysis-of-variance-anova-2.html"><a href="lecture-11-analysis-of-variance-anova-2.html#example-1-way-anova-model"><i class="fa fa-check"></i><b>11.1.8</b> Example: 1-way ANOVA model</a></li>
<li class="chapter" data-level="11.1.9" data-path="lecture-11-analysis-of-variance-anova-2.html"><a href="lecture-11-analysis-of-variance-anova-2.html#example-2-way-anova-model-1"><i class="fa fa-check"></i><b>11.1.9</b> Example: 2-way ANOVA model</a></li>
<li class="chapter" data-level="11.1.10" data-path="lecture-11-analysis-of-variance-anova-2.html"><a href="lecture-11-analysis-of-variance-anova-2.html#way-anova-in-r"><i class="fa fa-check"></i><b>11.1.10</b> 2-way ANOVA in R</a></li>
<li class="chapter" data-level="11.1.11" data-path="lecture-11-analysis-of-variance-anova-2.html"><a href="lecture-11-analysis-of-variance-anova-2.html#example-factorial-design"><i class="fa fa-check"></i><b>11.1.11</b> Example: Factorial Design<span class="math inline">\(^*\)</span></a></li>
<li class="chapter" data-level="11.1.12" data-path="lecture-11-analysis-of-variance-anova-2.html"><a href="lecture-11-analysis-of-variance-anova-2.html#example-2-way-anova-model-2"><i class="fa fa-check"></i><b>11.1.12</b> Example: 2-way ANOVA model</a></li>
<li class="chapter" data-level="11.1.13" data-path="lecture-11-analysis-of-variance-anova-2.html"><a href="lecture-11-analysis-of-variance-anova-2.html#example-2-way-anova-table"><i class="fa fa-check"></i><b>11.1.13</b> Example: 2-way ANOVA table</a></li>
<li class="chapter" data-level="11.1.14" data-path="lecture-11-analysis-of-variance-anova-2.html"><a href="lecture-11-analysis-of-variance-anova-2.html#example-2-way-anova-table-in-r"><i class="fa fa-check"></i><b>11.1.14</b> Example: 2-way ANOVA table in R</a></li>
<li class="chapter" data-level="11.1.15" data-path="lecture-11-analysis-of-variance-anova-2.html"><a href="lecture-11-analysis-of-variance-anova-2.html#example-pairwise-comparisons"><i class="fa fa-check"></i><b>11.1.15</b> Example: Pairwise comparisons</a></li>
<li class="chapter" data-level="11.1.16" data-path="lecture-11-analysis-of-variance-anova-2.html"><a href="lecture-11-analysis-of-variance-anova-2.html#assumptions-behind-2-way-anova"><i class="fa fa-check"></i><b>11.1.16</b> Assumptions behind 2-way ANOVA</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="lecture-11-analysis-of-variance-anova-2.html"><a href="lecture-11-analysis-of-variance-anova-2.html#correlation"><i class="fa fa-check"></i><b>11.2</b> Correlation</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="lecture-11-analysis-of-variance-anova-2.html"><a href="lecture-11-analysis-of-variance-anova-2.html#association-between-age-bp"><i class="fa fa-check"></i><b>11.2.1</b> Association between age &amp; BP</a></li>
<li class="chapter" data-level="11.2.2" data-path="lecture-11-analysis-of-variance-anova-2.html"><a href="lecture-11-analysis-of-variance-anova-2.html#the-correlation-coefficient"><i class="fa fa-check"></i><b>11.2.2</b> The correlation coefficient</a></li>
<li class="chapter" data-level="11.2.3" data-path="lecture-11-analysis-of-variance-anova-2.html"><a href="lecture-11-analysis-of-variance-anova-2.html#pearsons-correlation-coefficient"><i class="fa fa-check"></i><b>11.2.3</b> Pearsonâs correlation coefficient</a></li>
<li class="chapter" data-level="11.2.4" data-path="lecture-11-analysis-of-variance-anova-2.html"><a href="lecture-11-analysis-of-variance-anova-2.html#properties-of-rho"><i class="fa fa-check"></i><b>11.2.4</b> Properties of <span class="math inline">\(\rho\)</span></a></li>
<li class="chapter" data-level="11.2.5" data-path="lecture-11-analysis-of-variance-anova-2.html"><a href="lecture-11-analysis-of-variance-anova-2.html#scatterplots-of-data-with-a-variety-of-sample-correlation-values"><i class="fa fa-check"></i><b>11.2.5</b> Scatterplots of data with a variety of sample correlation values</a></li>
<li class="chapter" data-level="11.2.6" data-path="lecture-11-analysis-of-variance-anova-2.html"><a href="lecture-11-analysis-of-variance-anova-2.html#example-length-and-weight-of-snakes"><i class="fa fa-check"></i><b>11.2.6</b> Example: Length and weight of snakes</a></li>
<li class="chapter" data-level="11.2.7" data-path="lecture-11-analysis-of-variance-anova-2.html"><a href="lecture-11-analysis-of-variance-anova-2.html#scatterplot-of-weight-vs.-length-of-snakes"><i class="fa fa-check"></i><b>11.2.7</b> Scatterplot of weight vs.Â length of snakes</a></li>
<li class="chapter" data-level="11.2.8" data-path="lecture-11-analysis-of-variance-anova-2.html"><a href="lecture-11-analysis-of-variance-anova-2.html#how-strong-is-the-linear-relationship-between-snake-length-and-weight"><i class="fa fa-check"></i><b>11.2.8</b> How strong is the linear relationship between snake length and weight?</a></li>
<li class="chapter" data-level="11.2.9" data-path="lecture-11-analysis-of-variance-anova-2.html"><a href="lecture-11-analysis-of-variance-anova-2.html#scatterplot-of-standardized-values-of-weight-vs.-length-of-snakes"><i class="fa fa-check"></i><b>11.2.9</b> Scatterplot of standardized values of weight vs.Â length of snakes</a></li>
<li class="chapter" data-level="11.2.10" data-path="lecture-11-analysis-of-variance-anova-2.html"><a href="lecture-11-analysis-of-variance-anova-2.html#example-calculating-the-correlation-coefficient"><i class="fa fa-check"></i><b>11.2.10</b> Example: Calculating the correlation coefficient</a></li>
<li class="chapter" data-level="11.2.11" data-path="lecture-11-analysis-of-variance-anova-2.html"><a href="lecture-11-analysis-of-variance-anova-2.html#inference-about-rho-test-for-a-zero-population-correlation"><i class="fa fa-check"></i><b>11.2.11</b> Inference about <span class="math inline">\(\rho\)</span> : Test For A Zero Population Correlation</a></li>
<li class="chapter" data-level="11.2.12" data-path="lecture-11-analysis-of-variance-anova-2.html"><a href="lecture-11-analysis-of-variance-anova-2.html#example-blood-pressure-and-platelet-calcium"><i class="fa fa-check"></i><b>11.2.12</b> Example: Blood pressure and platelet calcium</a></li>
<li class="chapter" data-level="11.2.13" data-path="lecture-11-analysis-of-variance-anova-2.html"><a href="lecture-11-analysis-of-variance-anova-2.html#inferences-on-rho-1-Î±-confidence-interval"><i class="fa fa-check"></i><b>11.2.13</b> Inferences on <span class="math inline">\(\rho\)</span>: (1-Î±)% confidence interval</a></li>
<li class="chapter" data-level="11.2.14" data-path="lecture-11-analysis-of-variance-anova-2.html"><a href="lecture-11-analysis-of-variance-anova-2.html#example-blood-pressure-and-platelet-calcium-1"><i class="fa fa-check"></i><b>11.2.14</b> Example: Blood pressure and platelet calcium</a></li>
<li class="chapter" data-level="11.2.15" data-path="lecture-11-analysis-of-variance-anova-2.html"><a href="lecture-11-analysis-of-variance-anova-2.html#correlation-coefficient-in-r"><i class="fa fa-check"></i><b>11.2.15</b> Correlation coefficient in R</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html"><i class="fa fa-check"></i><b>12</b> Lecture 12: Simple and Multiple Linear Regression</a>
<ul>
<li class="chapter" data-level="12.1" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#correlation-and-simple-linear-regression"><i class="fa fa-check"></i><b>12.1</b> Correlation and Simple Linear Regression</a>
<ul>
<li class="chapter" data-level="12.1.1" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#simple-and-multiple-linear-regression"><i class="fa fa-check"></i><b>12.1.1</b> Simple and Multiple Linear Regression</a></li>
<li class="chapter" data-level="12.1.2" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#research-question"><i class="fa fa-check"></i><b>12.1.2</b> Research question</a></li>
<li class="chapter" data-level="12.1.3" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#terminologies"><i class="fa fa-check"></i><b>12.1.3</b> Terminologies</a></li>
<li class="chapter" data-level="12.1.4" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#finch-mayo-dataset"><i class="fa fa-check"></i><b>12.1.4</b> Finch-Mayo Dataset</a></li>
<li class="chapter" data-level="12.1.5" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#knowing-the-type-of-outcome-measure-can-help-specify-the-theoretical-model"><i class="fa fa-check"></i><b>12.1.5</b> Knowing the type of outcome measure can help specify the theoretical model</a></li>
<li class="chapter" data-level="12.1.6" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#research-question-1"><i class="fa fa-check"></i><b>12.1.6</b> Research question</a></li>
<li class="chapter" data-level="12.1.7" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#measurement-scale"><i class="fa fa-check"></i><b>12.1.7</b> Measurement scale</a></li>
<li class="chapter" data-level="12.1.8" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#walking-capacity---physical-function"><i class="fa fa-check"></i><b>12.1.8</b> Walking capacity &lt;- Physical Function?</a></li>
<li class="chapter" data-level="12.1.9" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#descriptive-statistics-and-graphs"><i class="fa fa-check"></i><b>12.1.9</b> Descriptive statistics and graphs</a></li>
<li class="chapter" data-level="12.1.10" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#histogram-of-walking-capacity"><i class="fa fa-check"></i><b>12.1.10</b> Histogram of walking capacity</a></li>
<li class="chapter" data-level="12.1.11" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#walking-capacity-vs.-physical-function"><i class="fa fa-check"></i><b>12.1.11</b> Walking capacity vs.Â Physical Function</a></li>
<li class="chapter" data-level="12.1.12" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#correlation-between-physical-function-and-walking-capacity"><i class="fa fa-check"></i><b>12.1.12</b> Correlation between physical function and walking capacity</a></li>
<li class="chapter" data-level="12.1.13" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#results-of-simple-linear-regression-walking-capacity---pfi"><i class="fa fa-check"></i><b>12.1.13</b> Results of simple linear regression: Walking capacity &lt;- PFI</a></li>
<li class="chapter" data-level="12.1.14" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#simple-linear-regression"><i class="fa fa-check"></i><b>12.1.14</b> Simple Linear Regression</a></li>
<li class="chapter" data-level="12.1.15" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#comparison-of-regression-lines"><i class="fa fa-check"></i><b>12.1.15</b> Comparison of Regression Lines</a></li>
<li class="chapter" data-level="12.1.16" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#simple-linear-regression-model"><i class="fa fa-check"></i><b>12.1.16</b> Simple Linear Regression Model</a></li>
<li class="chapter" data-level="12.1.17" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#illustration-of-assumptions-behind-simple-linear-regression"><i class="fa fa-check"></i><b>12.1.17</b> Illustration of assumptions behind Simple Linear Regression</a></li>
<li class="chapter" data-level="12.1.18" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#assumptions-involved-in-simple-linear-regression"><i class="fa fa-check"></i><b>12.1.18</b> Assumptions involved in Simple Linear Regression</a></li>
<li class="chapter" data-level="12.1.19" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#simple-linear-regression-1"><i class="fa fa-check"></i><b>12.1.19</b> Simple Linear Regression</a></li>
<li class="chapter" data-level="12.1.20" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#residual"><i class="fa fa-check"></i><b>12.1.20</b> Residual</a></li>
<li class="chapter" data-level="12.1.21" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#simple-linear-regression-2"><i class="fa fa-check"></i><b>12.1.21</b> Simple Linear Regression</a></li>
<li class="chapter" data-level="12.1.22" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#estimating-a-and-b-using-the-method-of-least-squares"><i class="fa fa-check"></i><b>12.1.22</b> Estimating a and b using the method of least squares</a></li>
<li class="chapter" data-level="12.1.23" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#relation-between-slope-and-correlation-coefficient"><i class="fa fa-check"></i><b>12.1.23</b> Relation between slope and correlation coefficient</a></li>
<li class="chapter" data-level="12.1.24" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#estimating-the-error-variance"><i class="fa fa-check"></i><b>12.1.24</b> Estimating the error variance</a></li>
<li class="chapter" data-level="12.1.25" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#expressions-for-standard-errors-and-confidence-intervals-for-parameter-estimates"><i class="fa fa-check"></i><b>12.1.25</b> Expressions for standard errors and confidence intervals for parameter estimates</a></li>
<li class="chapter" data-level="12.1.26" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#hypothesis-tests-for-regression-coefficients"><i class="fa fa-check"></i><b>12.1.26</b> Hypothesis tests for regression coefficients</a></li>
<li class="chapter" data-level="12.1.27" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#estimating-the-regression-line"><i class="fa fa-check"></i><b>12.1.27</b> Estimating the regression line</a></li>
<li class="chapter" data-level="12.1.28" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#best-fitting-straight-line"><i class="fa fa-check"></i><b>12.1.28</b> Best fitting straight line</a></li>
<li class="chapter" data-level="12.1.29" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#confidence-interval-for-b"><i class="fa fa-check"></i><b>12.1.29</b> Confidence interval for b</a></li>
<li class="chapter" data-level="12.1.30" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#change-in-walking-capacity-for-a-1-sd-change-in-physical-function"><i class="fa fa-check"></i><b>12.1.30</b> Change in walking capacity for a 1 SD change in physical function</a></li>
<li class="chapter" data-level="12.1.31" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#estimating-average-walking-capacity-for-patients-with-physical-function50"><i class="fa fa-check"></i><b>12.1.31</b> Estimating average Walking Capacity for patients with Physical Function=50</a></li>
<li class="chapter" data-level="12.1.32" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#ci-for-average-walking-capacity-among-patients-with-pf50"><i class="fa fa-check"></i><b>12.1.32</b> 95% CI for average Walking Capacity among patients with PF=50</a></li>
<li class="chapter" data-level="12.1.33" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#ci-for-predicted-walking-capacity-in-an-individual-patient-with-pf50"><i class="fa fa-check"></i><b>12.1.33</b> 95% CI for predicted Walking Capacity in an individual patient with PF=50</a></li>
<li class="chapter" data-level="12.1.34" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#regression-diagnostics-using-residuals"><i class="fa fa-check"></i><b>12.1.34</b> Regression diagnostics using residuals</a></li>
<li class="chapter" data-level="12.1.35" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#plot-of-residuals-vs.-predicted-value-haty-or-exposure-x"><i class="fa fa-check"></i><b>12.1.35</b> Plot of residuals vs.Â predicted value <span class="math inline">\((\hat{y})\)</span> or exposure (X)</a></li>
<li class="chapter" data-level="12.1.36" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#residual-plot-prototype-a-ideal-situation-no-apparent-pattern"><i class="fa fa-check"></i><b>12.1.36</b> Residual plot: Prototype (a), Ideal Situation: No apparent pattern</a></li>
<li class="chapter" data-level="12.1.37" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#residual-plot-prototype-b-suggests-that-the-linear-model-is-inappropriate.-quadratic-model-with-x2-may-be-needed"><i class="fa fa-check"></i><b>12.1.37</b> Residual plot: Prototype (b), Suggests that the linear model is inappropriate. Quadratic model (with <span class="math inline">\(x^2\)</span>) may be needed</a></li>
<li class="chapter" data-level="12.1.38" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#how-does-the-non-linear-pattern-arise"><i class="fa fa-check"></i><b>12.1.38</b> How does the non-linear pattern arise?</a></li>
<li class="chapter" data-level="12.1.39" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#residual-plot-prototype-c-plot-suggests-variance-is-not-constant.-transformation-may-help."><i class="fa fa-check"></i><b>12.1.39</b> Residual plot: Prototype (c), Plot suggests variance is not constant. Transformation may help.</a></li>
<li class="chapter" data-level="12.1.40" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#residual-plot-for-walking-capacity-vs.-physical-function-model"><i class="fa fa-check"></i><b>12.1.40</b> Residual plot for Walking Capacity vs.Â Physical Function model</a></li>
<li class="chapter" data-level="12.1.41" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#what-is-the-impact-of-an-outlier"><i class="fa fa-check"></i><b>12.1.41</b> What is the impact of an outlier?</a></li>
<li class="chapter" data-level="12.1.42" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#what-should-we-do-with-an-outlier"><i class="fa fa-check"></i><b>12.1.42</b> What should we do with an outlier?</a></li>
<li class="chapter" data-level="12.1.43" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#qq-plot-to-see-if-residuals-are-normally-distributed"><i class="fa fa-check"></i><b>12.1.43</b> QQ-plot to see if residuals are normally distributed</a></li>
<li class="chapter" data-level="12.1.44" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#q-q-plot-for-walking-capacity-vs.-physical-function-model"><i class="fa fa-check"></i><b>12.1.44</b> Q-Q plot for Walking Capacity vs.Â Physical Function model</a></li>
<li class="chapter" data-level="12.1.45" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#what-does-the-qq-plot-tell-us"><i class="fa fa-check"></i><b>12.1.45</b> What does the QQ plot tell us?</a></li>
<li class="chapter" data-level="12.1.46" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#goodness-of-fit"><i class="fa fa-check"></i><b>12.1.46</b> Goodness of fit</a></li>
<li class="chapter" data-level="12.1.47" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#multiple-linear-regression-conceptual-model"><i class="fa fa-check"></i><b>12.1.47</b> Multiple Linear Regression: Conceptual Model</a></li>
<li class="chapter" data-level="12.1.48" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#self-perceived-health---physical-function-covariates"><i class="fa fa-check"></i><b>12.1.48</b> Self-Perceived Health &lt;- Physical Function + covariates</a></li>
<li class="chapter" data-level="12.1.49" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#exploratory-analyses"><i class="fa fa-check"></i><b>12.1.49</b> Exploratory analyses</a></li>
<li class="chapter" data-level="12.1.50" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#multiple-linear-regression-model"><i class="fa fa-check"></i><b>12.1.50</b> Multiple Linear Regression Model</a></li>
<li class="chapter" data-level="12.1.51" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#results-of-simple-and-multiple-linear-regression-models"><i class="fa fa-check"></i><b>12.1.51</b> Results<span class="math inline">\(^*\)</span> of simple and multiple linear regression models</a></li>
<li class="chapter" data-level="12.1.52" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#interpretation-of-regression-coefficients-in-a-model-with-interaction-terms"><i class="fa fa-check"></i><b>12.1.52</b> Interpretation of regression coefficients in a model with interaction terms</a></li>
<li class="chapter" data-level="12.1.53" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#interpretation-of-coefficients-of-interaction-terms"><i class="fa fa-check"></i><b>12.1.53</b> Interpretation of coefficients of interaction terms</a></li>
<li class="chapter" data-level="12.1.54" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#model-checking"><i class="fa fa-check"></i><b>12.1.54</b> Model checking</a></li>
<li class="chapter" data-level="12.1.55" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#residuals-vs.-fitted-values-for-our-example"><i class="fa fa-check"></i><b>12.1.55</b> Residuals vs.Â Fitted values for our example</a></li>
<li class="chapter" data-level="12.1.56" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#standardized-residuals-vs.-fitted-values"><i class="fa fa-check"></i><b>12.1.56</b> Standardized Residuals vs.Â Fitted Values</a></li>
<li class="chapter" data-level="12.1.57" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#qq-normal-plot-of-standardized-residuals"><i class="fa fa-check"></i><b>12.1.57</b> QQ (normal)-plot of standardized residuals</a></li>
<li class="chapter" data-level="12.1.58" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#vif-for-our-example"><i class="fa fa-check"></i><b>12.1.58</b> VIF for our example</a></li>
<li class="chapter" data-level="12.1.59" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#model-with-centred-pfi-and-mhi-notice-change-in-slopes-of-these-variables"><i class="fa fa-check"></i><b>12.1.59</b> Model with centred PFI and MHI (notice change in slopes of these variables!)</a></li>
<li class="chapter" data-level="12.1.60" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#results-of-multiple-linear-regression-model-before-and-after-centering"><i class="fa fa-check"></i><b>12.1.60</b> Results<span class="math inline">\(^*\)</span> of multiple linear regression model before and after centering</a></li>
<li class="chapter" data-level="12.1.61" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#revised-interpretation-of-interaction-terms"><i class="fa fa-check"></i><b>12.1.61</b> Revised interpretation of interaction terms</a></li>
<li class="chapter" data-level="12.1.62" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#interpretation-of-regression-coefficients-in-a-model-with-centred-explanatory-variables"><i class="fa fa-check"></i><b>12.1.62</b> Interpretation of regression coefficients in a model with centred explanatory variables</a></li>
<li class="chapter" data-level="12.1.63" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#inference-for-slopes"><i class="fa fa-check"></i><b>12.1.63</b> Inference for slopes</a></li>
<li class="chapter" data-level="12.1.64" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#example-inference-for-slope-of-pfi-when-mhi90"><i class="fa fa-check"></i><b>12.1.64</b> Example: Inference for slope of PFI when MHI=90</a></li>
<li class="chapter" data-level="12.1.65" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#anova-table-for-multiple-linear-regression-model"><i class="fa fa-check"></i><b>12.1.65</b> ANOVA table for Multiple Linear Regression Model<span class="math inline">\(^*\)</span></a></li>
<li class="chapter" data-level="12.1.66" data-path="lecture-12-simple-and-multiple-linear-regression.html"><a href="lecture-12-simple-and-multiple-linear-regression.html#adjusted-r-squared"><i class="fa fa-check"></i><b>12.1.66</b> Adjusted R-squared</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://nandinidendukuri.com" target="blank">Nandini Dendukuri</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Intro to Statistics Notes</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="lecture-3-central-limit-theorem-and-inference-for-means" class="section level1 hasAnchor" number="3">
<h1><span class="header-section-number">3</span> Lecture 3: Central Limit Theorem and Inference for Means<a href="lecture-3-central-limit-theorem-and-inference-for-means.html#lecture-3-central-limit-theorem-and-inference-for-means" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="mean-and-standard-deviation" class="section level2 hasAnchor" number="3.1">
<h2><span class="header-section-number">3.1</span> Mean and Standard Deviation<a href="lecture-3-central-limit-theorem-and-inference-for-means.html#mean-and-standard-deviation" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="descriptive-statistics-vs.-inferential-statistics" class="section level3 hasAnchor" number="3.1.1">
<h3><span class="header-section-number">3.1.1</span> Descriptive statistics vs.Â Inferential Statistics<a href="lecture-3-central-limit-theorem-and-inference-for-means.html#descriptive-statistics-vs.-inferential-statistics" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><img src="3_3.png" width="50%" /></p>
<ul>
<li>Descriptive statistics help to describe the characteristics of the sample gathered</li>
<li>Inferential statistics help to use these characteristics to draw conclusions about the target population</li>
</ul>
</div>
<div id="some-commonly-encountered-shapes-of-distributions-of-a-variable" class="section level3 hasAnchor" number="3.1.2">
<h3><span class="header-section-number">3.1.2</span> Some commonly encountered shapes of distributions of a variable<a href="lecture-3-central-limit-theorem-and-inference-for-means.html#some-commonly-encountered-shapes-of-distributions-of-a-variable" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><img src="3_4.png" width="50%" /></p>
</div>
<div id="descriptive-statistics-notation" class="section level3 hasAnchor" number="3.1.3">
<h3><span class="header-section-number">3.1.3</span> Descriptive statistics: Notation<a href="lecture-3-central-limit-theorem-and-inference-for-means.html#descriptive-statistics-notation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>We use capital letters to denote a variable, and small letters to denote the values it takes. For example,
<ul>
<li>X = FEV (the variable),</li>
<li>x = 0.793 litres (an observed value)</li>
</ul></li>
<li><span class="math inline">\(\sum_{i=1}^nx_i\)</span> means the sum of the observed values x on a sample of size n.Â <span class="math inline">\(x_i\)</span> is the observed value for the <span class="math inline">\(i^{th}\)</span> subject in the sample</li>
<li>The next few slides list common measures of central tendency and spread</li>
</ul>
</div>
<div id="histogram-of-fev" class="section level3 hasAnchor" number="3.1.4">
<h3><span class="header-section-number">3.1.4</span> Histogram of FEV<a href="lecture-3-central-limit-theorem-and-inference-for-means.html#histogram-of-fev" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><img src="3_6.png" width="50%" /></p>
</div>
<div id="measures-of-central-tendency" class="section level3 hasAnchor" number="3.1.5">
<h3><span class="header-section-number">3.1.5</span> Measures of central tendency<a href="lecture-3-central-limit-theorem-and-inference-for-means.html#measures-of-central-tendency" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><img src="3_7.png" width="100%" /></p>
</div>
<div id="summary-of-fev-variable" class="section level3 hasAnchor" number="3.1.6">
<h3><span class="header-section-number">3.1.6</span> Summary of FEV variable<a href="lecture-3-central-limit-theorem-and-inference-for-means.html#summary-of-fev-variable" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><img src="3_8.png" width="100%" /></p>
<p>For a symmetric distribution, the median=mean.</p>
<p>The values above suggest that the distribution of FEV may be slightly skewed to the right as the mean is higher than the mode</p>
</div>
<div id="robustness" class="section level3 hasAnchor" number="3.1.7">
<h3><span class="header-section-number">3.1.7</span> Robustness<a href="lecture-3-central-limit-theorem-and-inference-for-means.html#robustness" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>A statistic is said to be <strong>robust</strong> if the value of the statistic is relatively unaffected by changes in a small portion of the data, even if the changes are dramatic ones. The median is a robust statistic, but the mean is not robust because it can be greatly shifted by changes in even one</li>
<li><strong>Example:</strong> In the FEV dataset, I replaced the last observation in the dataset of 3.211 by 6.211, an extreme value. This resulted in increasing the mean from 2.637 to 2.641 but the median remained at 2.548</li>
<li>If the frequency distribution is skewed, both measures are pulled toward the longer tail, but the mean is usually pulled farther than the median</li>
</ul>
</div>
<div id="mean-vs.-median" class="section level3 hasAnchor" number="3.1.8">
<h3><span class="header-section-number">3.1.8</span> Mean vs.Â Median<a href="lecture-3-central-limit-theorem-and-inference-for-means.html#mean-vs.-median" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>In some situations the mean makes very little sense. Suppose, for example, that the observations are survival times of cancer patients on a certain treatment protocol, and that most patients survive less than 1 year, while a few respond well and survive for 5 or even 10 years. In this case, the mean survival time might be greater than the survival time of most patients; the median would more nearly represent the experience of a âtypicalâ patient. Note also that the mean survival time cannot be computed until the last patient has died; the median does not share this disadvantage. Situations in which the median can readily be computed, but the mean cannot, are not uncommon in bioassay, survival, and toxicity studies</li>
<li>An advantage of the mean is that in some circumstances it is more efficient than the median. Efficiency is a technical notion in statistical theory; roughly speaking, a method is efficient if it takes full advantage of all the information in the data. Partly because of its efficiency, the mean has played a major role in classical methods in statistics</li>
</ul>
</div>
<div id="quantiles" class="section level3 hasAnchor" number="3.1.9">
<h3><span class="header-section-number">3.1.9</span> Quantiles<a href="lecture-3-central-limit-theorem-and-inference-for-means.html#quantiles" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>Quantiles (also known as percentiles) help to demarcate different points of the distribution of a continuous variable</li>
<li>The q% quantile is the number below which q% of observed values lie</li>
<li>For example
<ul>
<li>The 10% quantile of FEV is the value below which 10% of FEV values lie = 1.612<br />
= <span class="math inline">\(0.1n^{th}\)</span> lowest value of FEV</li>
</ul></li>
</ul>
</div>
<div id="measures-of-spread" class="section level3 hasAnchor" number="3.1.10">
<h3><span class="header-section-number">3.1.10</span> Measures of spread<a href="lecture-3-central-limit-theorem-and-inference-for-means.html#measures-of-spread" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><img src="3_12.png" width="100%" /></p>
</div>
<div id="summary-of-fev-variable-1" class="section level3 hasAnchor" number="3.1.11">
<h3><span class="header-section-number">3.1.11</span> Summary of FEV variable<a href="lecture-3-central-limit-theorem-and-inference-for-means.html#summary-of-fev-variable-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><img src="3_13.png" width="100%" /></p>
</div>
<div id="comparison-of-measures-of-spread" class="section level3 hasAnchor" number="3.1.12">
<h3><span class="header-section-number">3.1.12</span> Comparison of measures of spread<a href="lecture-3-central-limit-theorem-and-inference-for-means.html#comparison-of-measures-of-spread" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><img src="3_14.png" width="100%" /></p>
</div>
<div id="variance-and-standard-deviation" class="section level3 hasAnchor" number="3.1.13">
<h3><span class="header-section-number">3.1.13</span> Variance and Standard Deviation<a href="lecture-3-central-limit-theorem-and-inference-for-means.html#variance-and-standard-deviation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>The standard deviation is more commonly reported than the variance because it is in the same units as the variable X and the mean of X</li>
<li>Notice that we use the sum of the squared deviations. This is because the sum of the deviations themselves will always be 0. We need a way to get rid of the signs of the deviations. Alternatives to taking the squares include taking the absolute value. But squares are more popular because of their mathematical properties</li>
<li>Why do we divide by n-1 rather than n? We do so because we are measuring the deviation from a quantity that is also defined using the sample, i.e.Â <span class="math inline">\(\bar x\)</span>. It is as if we must penalize the sample size to correct for this. If we knew the true population mean (Âµ), then we would divide by n instead:</li>
</ul>
<p><span class="math display">\[Population\space variance = \frac{\sum_{i=1}^n(x_i-\mu)^2}{n}\]</span></p>
</div>
<div id="why-n-1-rather-than-n" class="section level3 hasAnchor" number="3.1.14">
<h3><span class="header-section-number">3.1.14</span> Why n-1 rather than n?<span class="math inline">\(^*\)</span><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#why-n-1-rather-than-n" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>Suppose the population has only 4 members {1,2,3,4}
<ul>
<li>The true mean is <span class="math inline">\(\frac{1+2+3+4}{4} = 2.5\)</span></li>
<li>The true variance is <span class="math inline">\(\frac{(1â2.5)^2+(2â2.5)^2+(3â2.5)^2+(4â2.5)^2}{4}=1.25\)</span></li>
</ul></li>
<li>Now suppose we cannot view the whole population, but instead take a sample of size two. On the next slide, all possible samples are listed together with mean, the correct calculation for the sample variance dividing by n-1 and the incorrect calculation dividing by n.Â Each sample is equally likely to occur, assuming we are sampling with replacement from the population</li>
<li>Notice that the incorrect expression for the sample variance results in an underestimate on the average across samples</li>
</ul>
<table>
<thead>
<tr>
<th style="text-align:left;">
Sample
</th>
<th style="text-align:right;">
Sample mean
</th>
<th style="text-align:right;">
Correct Sample variance
</th>
<th style="text-align:right;">
Underestimated Sample variance
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
(1,2)
</td>
<td style="text-align:right;">
1.5
</td>
<td style="text-align:right;">
0.50
</td>
<td style="text-align:right;">
0.250
</td>
</tr>
<tr>
<td style="text-align:left;">
(1,3)
</td>
<td style="text-align:right;">
2.0
</td>
<td style="text-align:right;">
2.00
</td>
<td style="text-align:right;">
1.000
</td>
</tr>
<tr>
<td style="text-align:left;">
(1,4)
</td>
<td style="text-align:right;">
2.5
</td>
<td style="text-align:right;">
4.50
</td>
<td style="text-align:right;">
2.250
</td>
</tr>
<tr>
<td style="text-align:left;">
(2,3)
</td>
<td style="text-align:right;">
2.5
</td>
<td style="text-align:right;">
0.50
</td>
<td style="text-align:right;">
0.250
</td>
</tr>
<tr>
<td style="text-align:left;">
(2,4)
</td>
<td style="text-align:right;">
3.0
</td>
<td style="text-align:right;">
2.00
</td>
<td style="text-align:right;">
1.000
</td>
</tr>
<tr>
<td style="text-align:left;">
(3,4)
</td>
<td style="text-align:right;">
3.5
</td>
<td style="text-align:right;">
0.50
</td>
<td style="text-align:right;">
0.250
</td>
</tr>
<tr>
<td style="text-align:left;">
(2,1)
</td>
<td style="text-align:right;">
1.5
</td>
<td style="text-align:right;">
0.50
</td>
<td style="text-align:right;">
0.250
</td>
</tr>
<tr>
<td style="text-align:left;">
(3,1)
</td>
<td style="text-align:right;">
2.0
</td>
<td style="text-align:right;">
2.00
</td>
<td style="text-align:right;">
1.000
</td>
</tr>
<tr>
<td style="text-align:left;">
(4,1)
</td>
<td style="text-align:right;">
2.5
</td>
<td style="text-align:right;">
4.50
</td>
<td style="text-align:right;">
2.250
</td>
</tr>
<tr>
<td style="text-align:left;">
(3,2)
</td>
<td style="text-align:right;">
2.5
</td>
<td style="text-align:right;">
0.50
</td>
<td style="text-align:right;">
0.250
</td>
</tr>
<tr>
<td style="text-align:left;">
(4,2)
</td>
<td style="text-align:right;">
3.0
</td>
<td style="text-align:right;">
2.00
</td>
<td style="text-align:right;">
1.000
</td>
</tr>
<tr>
<td style="text-align:left;">
(4,3)
</td>
<td style="text-align:right;">
3.5
</td>
<td style="text-align:right;">
0.50
</td>
<td style="text-align:right;">
0.250
</td>
</tr>
<tr>
<td style="text-align:left;">
(1,1)
</td>
<td style="text-align:right;">
1.0
</td>
<td style="text-align:right;">
0.00
</td>
<td style="text-align:right;">
0.000
</td>
</tr>
<tr>
<td style="text-align:left;">
(2,2)
</td>
<td style="text-align:right;">
2.0
</td>
<td style="text-align:right;">
0.00
</td>
<td style="text-align:right;">
0.000
</td>
</tr>
<tr>
<td style="text-align:left;">
(3,3)
</td>
<td style="text-align:right;">
3.0
</td>
<td style="text-align:right;">
0.00
</td>
<td style="text-align:right;">
0.000
</td>
</tr>
<tr>
<td style="text-align:left;">
(4,4)
</td>
<td style="text-align:right;">
4.0
</td>
<td style="text-align:right;">
0.00
</td>
<td style="text-align:right;">
0.000
</td>
</tr>
<tr>
<td style="text-align:left;">
Average across samples
</td>
<td style="text-align:right;">
2.5
</td>
<td style="text-align:right;">
1.25
</td>
<td style="text-align:right;">
0.625
</td>
</tr>
</tbody>
</table>
<p><span class="math inline">\(^*\)</span>Lawrence Josephâs notes</p>
</div>
</div>
<div id="central-limit-theorem" class="section level2 hasAnchor" number="3.2">
<h2><span class="header-section-number">3.2</span> Central Limit Theorem<a href="lecture-3-central-limit-theorem-and-inference-for-means.html#central-limit-theorem" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="example-1-serum-cholesterol-in-children" class="section level3 hasAnchor" number="3.2.1">
<h3><span class="header-section-number">3.2.1</span> Example 1: Serum cholesterol in children<a href="lecture-3-central-limit-theorem-and-inference-for-means.html#example-1-serum-cholesterol-in-children" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>Though we are more conscious of the relationship between cholesterol level and heart disease in adults, high levels of cholesterol are also a concern in children, particularly if they have risk factors like family history or obesity</li>
<li>The American Academy of Pediatrics now recommends cholesterol testing in certain age groups</li>
<li>To determine if a child is at risk of heart disease, we would need to compare the observed cholesterol level with the standard expected in a normal child. How large a sample size do we need to determine the normal level?</li>
<li>The serum cholesterol levels (Y) of 12- to 14-year-olds follow a normal distribution with mean Î¼=155mg/dl and standard deviation Ï=27 mg/dl</li>
<li>You wish to estimate the true mean serum cholesterol in this population by using a sample of observations:
<ul>
<li>Should you prefer a sample of n=10, 30 or 100 observations?</li>
</ul></li>
</ul>
<p><img src="3_21.png" width="100%" /></p>
</div>
<div id="the-sampling-distribution-of-bar-y" class="section level3 hasAnchor" number="3.2.2">
<h3><span class="header-section-number">3.2.2</span> The sampling distribution of <span class="math inline">\(\bar Y\)</span><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#the-sampling-distribution-of-bar-y" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>The sample mean can be used, not only as a description of the data in the sample, but also as an estimate of the population mean Î¼.</li>
<li>It is natural to ask, âHow close to Î¼ is <span class="math inline">\(\bar y\)</span>?â We cannot answer this question for the mean <span class="math inline">\(\bar y\)</span> of a particular sample, but we can answer it if we think in terms of the random sampling model and regard the sample mean as a random variable <span class="math inline">\(\bar Y\)</span>.</li>
<li>The question then becomes: âHow close to Î¼ is <span class="math inline">\(\bar Y\)</span> likely to be?â and the answer is provided by the <strong>sampling distribution of <span class="math inline">\(\bar Y\)</span></strong> - that is, the probability distribution that describes sampling variability in <span class="math inline">\(\bar Y\)</span></li>
<li>In order to visualize the sampling distribution of <span class="math inline">\(\bar Y\)</span>, imagine repeated samples of size n are drawn from a population with fixed mean Âµ and standard deviation Ï. The variation of the <span class="math inline">\(\bar y&#39;s\)</span> among the samples is specified by the sampling distribution of <span class="math inline">\(\bar Y\)</span></li>
</ul>
<p><img src="3_23.png" width="50%" /></p>
</div>
<div id="example-sampling-distribution-of-bar-y-when-n10" class="section level3 hasAnchor" number="3.2.3">
<h3><span class="header-section-number">3.2.3</span> Example: Sampling distribution of <span class="math inline">\(\bar Y\)</span> when n=10<a href="lecture-3-central-limit-theorem-and-inference-for-means.html#example-sampling-distribution-of-bar-y-when-n10" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><img src="3_24.png" width="50%" /></p>
</div>
<div id="example-sampling-distribution-of-bar-y-when-n30" class="section level3 hasAnchor" number="3.2.4">
<h3><span class="header-section-number">3.2.4</span> Example: Sampling distribution of <span class="math inline">\(\bar Y\)</span> when n=30<a href="lecture-3-central-limit-theorem-and-inference-for-means.html#example-sampling-distribution-of-bar-y-when-n30" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><img src="3_25.png" width="50%" /></p>
</div>
<div id="example-sampling-distribution-of-bar-y-when-n100" class="section level3 hasAnchor" number="3.2.5">
<h3><span class="header-section-number">3.2.5</span> Example: Sampling distribution of <span class="math inline">\(\bar Y\)</span> when n=100<a href="lecture-3-central-limit-theorem-and-inference-for-means.html#example-sampling-distribution-of-bar-y-when-n100" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><img src="3_26.png" width="50%" /></p>
</div>
<div id="example-sampling-distribution-of-bar-y-when-n1000" class="section level3 hasAnchor" number="3.2.6">
<h3><span class="header-section-number">3.2.6</span> Example: Sampling distribution of <span class="math inline">\(\bar Y\)</span> when n=1000<a href="lecture-3-central-limit-theorem-and-inference-for-means.html#example-sampling-distribution-of-bar-y-when-n1000" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><img src="3_27.png" width="50%" /></p>
</div>
<div id="example-1" class="section level3 hasAnchor" number="3.2.7">
<h3><span class="header-section-number">3.2.7</span> Example 1<a href="lecture-3-central-limit-theorem-and-inference-for-means.html#example-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>We notice that the mean of the sampling distribution gets very close to Âµ even with smaller sample sizes. This only improves as n increases</li>
<li>As n increases, there is a very clear decrease in the standard deviation of the means across a 100 samples</li>
<li>Finally, we notice that the shape of the sampling distribution is increasingly like a normal distribution as n increases</li>
</ul>
</div>
<div id="the-sampling-distribution-of-bar-y-1" class="section level3 hasAnchor" number="3.2.8">
<h3><span class="header-section-number">3.2.8</span> The sampling distribution of <span class="math inline">\(\bar Y\)</span><a href="lecture-3-central-limit-theorem-and-inference-for-means.html#the-sampling-distribution-of-bar-y-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><strong>Mean</strong>: The mean of the sampling distribution of <span class="math inline">\(\bar Y\)</span> is equal to the population mean, i.e.Â <span class="math inline">\(E(\bar Y)=\mu_{\bar Y}=\mu\)</span></li>
<li><strong>Standard deviation</strong>: The standard deviation of the sampling distribution is equal to the population standard deviation divided by the square root of the sample size, i.e.Â <span class="math inline">\(SD(\bar Y)=\sigma_{\bar Y}=\frac{\sigma}{\sqrt n}\)</span>. Note that this implies the <span class="math inline">\(Variance(\bar Y)=\sigma^2_{\bar Y}=\frac{\sigma^2}{n}\)</span></li>
<li><strong>Shape</strong>
<ul>
<li>If the population distribution of Y is normal, then the sampling distribution is normal, regardless of the sample size n.Â </li>
<li><em>Central Limit Theorem</em>: If n is large, then the sampling distribution is approximately normal, even if the population distribution of Y is not normal</li>
</ul></li>
</ul>
</div>
<div id="central-limit-theorem-1" class="section level3 hasAnchor" number="3.2.9">
<h3><span class="header-section-number">3.2.9</span> Central Limit Theorem<a href="lecture-3-central-limit-theorem-and-inference-for-means.html#central-limit-theorem-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>From the text by Moore and McCabe:</li>
</ul>
<p>âThe sampling distribution of <span class="math inline">\(\bar Y\)</span> is normal if the underlying population itself is normal.</p>
<p>What happens when the population distribution is not normal? It turns out that as the <em>sample size increases, the distribution of <span class="math inline">\(\bar Y\)</span> becomes closer to a normal distribution</em>. This is true no matter what the population distribution may be, as long as the population has a finite standard deviation Ï. This famous fact of probability theory is called the <em>central limit theorem</em>. For large sample size n, we can regard <span class="math inline">\(\bar Y\)</span> as having the <span class="math inline">\(N\left(\mu,\frac{\sigma}{\sqrt n}\right)\)</span> distributionâ</p>
</div>
<div id="example-1-1" class="section level3 hasAnchor" number="3.2.10">
<h3><span class="header-section-number">3.2.10</span> Example 1<a href="lecture-3-central-limit-theorem-and-inference-for-means.html#example-1-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>Applying the Central Limit Theorem, we can say that the sampling distribution of the mean serum cholesterol is:
<ul>
<li><span class="math inline">\(N\left(\mu_{\bar Y}=155,\sigma_{\bar Y}=\frac{27}{\sqrt {10}}=8.54\right)\)</span> when n=10</li>
<li><span class="math inline">\(N\left(\mu_{\bar Y}=155,\sigma_{\bar Y}=\frac{27}{\sqrt {30}}=4.93\right)\)</span> when n=30</li>
<li><span class="math inline">\(N\left(\mu_{\bar Y}=155,\sigma_{\bar Y}=\frac{27}{\sqrt {100}}=2.7\right)\)</span> when n=100</li>
<li><span class="math inline">\(N\left(\mu_{\bar Y}=155,\sigma_{\bar Y}=\frac{27}{\sqrt {1000}}=0.85\right)\)</span> when n=1000</li>
</ul></li>
</ul>
<p>Therefore, applying the rules pertaining to the normal distribution, we know that roughly 95% of the sampling distribution lies in the following ranges depending on the size of n:</p>
<p><img src="3_32.png" width="50%" /></p>
</div>
<div id="theory-related-to-the-sums-of-random-variables" class="section level3 hasAnchor" number="3.2.11">
<h3><span class="header-section-number">3.2.11</span> Theory related to the sums of random variables<a href="lecture-3-central-limit-theorem-and-inference-for-means.html#theory-related-to-the-sums-of-random-variables" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>These two slides help to see how <span class="math inline">\(\frac{\sigma}{\sqrt n}\)</span> arises.</li>
<li>Let X and Y be two arbitrary, independent random variables. Then from probability theory we know that:
<ul>
<li>E(X+Y) = E(X) + E(Y)</li>
<li>Var(X + Y) = Var(X) + Var(Y)</li>
<li>E(aX+bY) = aE(X) + bE(Y), where a and b are constants</li>
<li><span class="math inline">\(Var(aX+bY) = a^2 Var(X) + b^2 Var(Y)\)</span></li>
<li>If X ~ <span class="math inline">\(N(\mu_X,\sigma_X^2)\)</span> and Y ~ <span class="math inline">\(N(\mu_Y,\sigma_Y^2)\)</span> then (X+Y) ~ <span class="math inline">\(N(\mu_X+\mu_Y,\sigma_X^2+\sigma_Y^2)\)</span></li>
</ul></li>
</ul>
</div>
<div id="some-examples-related-to-the-sums-of-independent-random-variables" class="section level3 hasAnchor" number="3.2.12">
<h3><span class="header-section-number">3.2.12</span> Some examples related to the sums of independent random variables<a href="lecture-3-central-limit-theorem-and-inference-for-means.html#some-examples-related-to-the-sums-of-independent-random-variables" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ol style="list-style-type: decimal">
<li><p>If X ~ <span class="math inline">\(N(\mu_X=0,\sigma_X^2=1)\)</span> and Y ~ <span class="math inline">\(N(\mu_Y=3,\sigma_Y^2=4)\)</span>,<br />
then X+Y ~ N(mean=3, variance=5)</p></li>
<li><p>If <span class="math inline">\(X_1,X_2,...,X_n\)</span> ~ N(0,1), then <span class="math inline">\(\sum_{i=1}^nX_i\)</span> ~ N(0,n)</p></li>
<li><p>â¦ and then, <span class="math inline">\(\frac{1}{n}\sum_{i=1}^nX_i\)</span> ~ <span class="math inline">\(N(0,\frac{1}{n})\)</span></p></li>
<li><p>If <span class="math inline">\(X_1,X_2,...,X_n\)</span> ~ <span class="math inline">\(N(\mu,\sigma^2)\)</span>, then <span class="math inline">\(\sum_{i=1}^nX_i\)</span> ~ <span class="math inline">\(N(n\mu,n\sigma^2)\)</span></p></li>
<li><p>â¦ and then, <span class="math inline">\(\frac{1}{n}\sum_{i=1}^nX_i\)</span> ~ <span class="math inline">\(N(\mu,\frac{\sigma^2}{n})\)</span></p></li>
</ol>
<div id="excerpt-from-lawrence-josephs-notes" class="section level4 hasAnchor" number="3.2.12.1">
<h4><span class="header-section-number">3.2.12.1</span> Excerpt from Lawrence Josephâs notes<a href="lecture-3-central-limit-theorem-and-inference-for-means.html#excerpt-from-lawrence-josephs-notes" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><img src="3_35.png" width="50%" /></p>
</div>
</div>
<div id="example-2-central-limit-theorem-in-action" class="section level3 hasAnchor" number="3.2.13">
<h3><span class="header-section-number">3.2.13</span> Example 2: Central Limit Theorem in action<a href="lecture-3-central-limit-theorem-and-inference-for-means.html#example-2-central-limit-theorem-in-action" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>What is the average time taken across the 50 students in the class?</li>
<li>R code to replicate</li>
</ul>
<p>x1 = rnorm(50,4,1) # walk to bus stop
x2 = runif(50,4,16) # wait for bus
x3 = rnorm(50,20,2) # bus ride
x4 = rgamma(50,shape=3/2,scale=2) # trudge up hill</p>
<p>par(mfrow=c(2,3))
hist(x1);hist(x2);hist(x3);hist(x4)
hist(x1+x2+x3+x4,xlab=âSum for 50 studentsâ,main=ââ)
hist((x1+x2+x3+x4)/4,xlab=âMean for 50 studentsâ,main=ââ)</p>
</div>
</div>
<div id="confidence-intervals-for-means" class="section level2 hasAnchor" number="3.3">
<h2><span class="header-section-number">3.3</span> Confidence intervals for means<a href="lecture-3-central-limit-theorem-and-inference-for-means.html#confidence-intervals-for-means" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="confidence-interval-estimation-for-a-single-mean" class="section level3 hasAnchor" number="3.3.1">
<h3><span class="header-section-number">3.3.1</span> Confidence interval estimation for a single mean<a href="lecture-3-central-limit-theorem-and-inference-for-means.html#confidence-interval-estimation-for-a-single-mean" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><img src="3_38.png" width="50%" /></p>
<ul>
<li>The construction of a confidence interval relies on the principal of the central limit theorem</li>
<li>If, we can reasonably assume that the sample mean follows a normal distribution with mean Âµ and standard deviation <span class="math inline">\(\frac{\sigma}{\sqrt n}\)</span></li>
<li>Then, across repeated samples, 95% of samplesâ means <span class="math inline">\((\bar x&#39;s)\)</span> lie in the interval <span class="math inline">\(\left(\mu-2\frac{\sigma}{\sqrt n},\mu+2\frac{\sigma}{\sqrt n}\right)\)</span></li>
<li>This implies that 95% of the intervals <span class="math inline">\(\left(\bar x-2\frac{\sigma}{\sqrt n},\bar x+2\frac{\sigma}{\sqrt n}\right)\)</span> will include <span class="math inline">\(\mu\)</span>. This interval is called the 95% confidence interval for Âµ</li>
<li>More generally, <span class="math inline">\((1-\alpha)\)</span>% of the intervals <span class="math inline">\(\left(\bar x-Z_{(1-\frac{\alpha}{2})}\frac{\sigma}{\sqrt n},\bar x+Z_{(1-\frac{\alpha}{2})}\frac{\sigma}{\sqrt n}\right)\)</span> will include <span class="math inline">\(\mu\)</span>.</li>
<li>This interval is called the (1-Î±)% equal-tailed confidence interval for Âµ, where <span class="math inline">\(Z_{(1-\frac{\alpha}{2})}\)</span> is the (1- Î±/2) quantile of the standard normal distribution</li>
<li>Equal-tailed refers to the fact that the probability of (1-Î±) is divided equally in the two tails of the distribution</li>
<li>Notice that the 95% or (1-Î±)% in the definition refers to a percentage across repeated experiments</li>
<li>We cannot say whether the 95% confidence interval estimated from the sample at hand is one of the ones that captured the true value of Âµ or not</li>
<li>The population standard deviation (Ï) is seldom known and must be substituted by the sample standard deviation (s)</li>
<li>Does the assumption of 95% confidence still hold? It turns out that it does but we must replace the quantile <span class="math inline">\(Z_{(1-\frac{\alpha}{2})}\)</span> from the normal distribution by the <span class="math inline">\(t_{(1-\frac{\alpha}{2})}\)</span> quantile from the Studentâs t-distribution (or t-distribution for short)</li>
<li>The resulting expression for the confidence interval is given by:</li>
</ul>
<p><span class="math display">\[\left(\bar x-t_{(1-\frac{\alpha}{2}),n-1}\frac{s}{\sqrt n},\bar x+t_{(1-\frac{\alpha}{2}),n-1}\frac{s}{\sqrt n}\right)\]</span></p>
<p>where <span class="math inline">\(t_{(1-\frac{\alpha}{2}),n-1}\)</span> is the (1- Î±/2) quantile of the t-distribution with n-1 degrees of freedom</p>
</div>
<div id="t-distribution" class="section level3 hasAnchor" number="3.3.2">
<h3><span class="header-section-number">3.3.2</span> t-distribution<a href="lecture-3-central-limit-theorem-and-inference-for-means.html#t-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><img src="3_41.png" width="50%" /></p>
<p>Image from Wikipedia</p>
<ul>
<li>The t-distribution was discovered by the British scientist W. S. Gossett who was employed by the Guiness Brewery.
<ul>
<li>He published his work in 1908 under the pseudonym Student</li>
</ul></li>
<li>The t-distribution is a bell-shaped, symmetrically distribution over the range -â to â. It resembles the normal distribution, but has a higher standard deviation.</li>
<li>The exact shape of the distribution depends on a quantity called the degrees of freedom (Î½ in the illustration). The higher the value of Î½ the closer it is to a normal distribution</li>
</ul>
<p>Probability density function centred at 0</p>
<p><span class="math display">\[f(x|v) = \frac{\Gamma\left(\frac{v+1}{2}\right)}{\sqrt {v\pi}\Gamma\left(\frac{v}{2}\right)}\left(1+\frac{x^2}{v}\right)^{-\frac{v+1}{2}},-\infty&lt;x&lt;\infty\]</span></p>
<p>Mean=0</p>
<p>Variance=<span class="math inline">\(\frac{v}{v-2}\)</span></p>
</div>
<div id="example-1-serum-potassium-concentration" class="section level3 hasAnchor" number="3.3.3">
<h3><span class="header-section-number">3.3.3</span> Example 1: Serum Potassium Concentration<a href="lecture-3-central-limit-theorem-and-inference-for-means.html#example-1-serum-potassium-concentration" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><img src="3_42.png" width="50%" /></p>
<ul>
<li>As part of a study of natural variation in blood chemistry, serum potassium concentrations were measured in 84 healthy women.</li>
<li>The mean concentration was 4.36 mEq/l, and the standard deviation was 0.42 mEq/l.</li>
<li>The table presents a frequency distribution of the data</li>
<li>Calculate the standard error of the mean</li>
<li>Construct a histogram of the data and indicate the intervals mean Â± SD and mean Â± SE</li>
<li>Construct a 95% confidence interval for the population mean. Interpret this confidence interval</li>
<li>Would this interval be suitable to define âreference limitsâ for serum potassium in healthy women, i.e.Â the limits within which we would expect to find 95% of healthy people?</li>
<li>Suppose a similar study is to be conducted the following year among 200 women. What would you predict would be
<ul>
<li>the SD of the new measurements?</li>
<li>the SE of the new measurements?</li>
</ul></li>
</ul>
</div>
<div id="example-1-histogram-of-the-data" class="section level3 hasAnchor" number="3.3.4">
<h3><span class="header-section-number">3.3.4</span> Example 1: Histogram of the data<a href="lecture-3-central-limit-theorem-and-inference-for-means.html#example-1-histogram-of-the-data" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><img src="3_44.png" width="50%" /></p>
</div>
<div id="verifying-assumptions-behind-the-t-distribution-confidence-interval" class="section level3 hasAnchor" number="3.3.5">
<h3><span class="header-section-number">3.3.5</span> Verifying assumptions behind the t-distribution confidence interval<a href="lecture-3-central-limit-theorem-and-inference-for-means.html#verifying-assumptions-behind-the-t-distribution-confidence-interval" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>Does the central limit theorem hold?</li>
<li>In other words, do at least one of the following conditions hold
<ul>
<li>the data follow an approximately normal distribution?</li>
<li>the sample size is large</li>
</ul></li>
<li>For the serum potassium example both conditions appear to hold</li>
</ul>
</div>
<div id="example-1-standard-error-and-95-confidence-interval" class="section level3 hasAnchor" number="3.3.6">
<h3><span class="header-section-number">3.3.6</span> Example 1: Standard Error and 95% confidence interval<a href="lecture-3-central-limit-theorem-and-inference-for-means.html#example-1-standard-error-and-95-confidence-interval" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>The standard error of the mean (SE)<br />
<span class="math inline">\(=\frac{SD}{\sqrt n}=\frac{0.42}{\sqrt {84}}=0.05\)</span> mEq/l, after rounding</li>
<li>The 95% confidence interval<br />
<span class="math inline">\(=\left(\bar x-t_{(1-\frac{\alpha}{2}),n-1}\frac{s}{\sqrt n},\bar x+t_{(1-\frac{\alpha}{2}),n-1}\frac{s}{\sqrt n}\right)\)</span><br />
<span class="math inline">\(=(4.36 â t_{0.975,84-1} 0.05, 4.36 + t_{0.975,84-1} 0.05)\)</span><br />
= (4.36 â 1.98 Ã 0.05, 4.36 + 1.98 Ã 0.05)<br />
= (4.26, 4.46) mEq/l</li>
</ul>
</div>
<div id="interpretation-of-the-95-confidence-interval" class="section level3 hasAnchor" number="3.3.7">
<h3><span class="header-section-number">3.3.7</span> Interpretation of the 95% confidence interval<a href="lecture-3-central-limit-theorem-and-inference-for-means.html#interpretation-of-the-95-confidence-interval" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>Assuming that the sample at hand is a random sample, there is a 95% probability that the procedure used to calculate the interval (4.26, 4.46) will capture the population mean serum potassium concentration</li>
<li>It would <strong>not</strong> be correct to say: There is a 95% probability that the population mean serum concentration lies between 4.26 and 4.46 mEq/l</li>
</ul>
</div>
<div id="confidence-level" class="section level3 hasAnchor" number="3.3.8">
<h3><span class="header-section-number">3.3.8</span> Confidence level<a href="lecture-3-central-limit-theorem-and-inference-for-means.html#confidence-level" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p>The higher the confidence level, the wider the confidence interval would be
<img src="3_48.png" width="100%" /></p></li>
<li><p>qt(prob,df) is the R function that returns the t-distribution quantile</p>
<ul>
<li>Arguments provided are the cumulative probability and the degrees of freedom</li>
</ul></li>
</ul>
</div>
<div id="example-1-distribution-of-the-data-with-intervals" class="section level3 hasAnchor" number="3.3.9">
<h3><span class="header-section-number">3.3.9</span> Example 1: Distribution of the data (with intervals)<a href="lecture-3-central-limit-theorem-and-inference-for-means.html#example-1-distribution-of-the-data-with-intervals" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><img src="3_49.png" width="50%" /></p>
</div>
<div id="interpreting-the-confidence-interval" class="section level3 hasAnchor" number="3.3.10">
<h3><span class="header-section-number">3.3.10</span> Interpreting the confidence interval<a href="lecture-3-central-limit-theorem-and-inference-for-means.html#interpreting-the-confidence-interval" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><em>Would the 95% confidence interval be suitable to define âreference limitsâ for serum potassium in healthy women, i.e.Â the limits within which we would expect to find 95% of healthy people?</em></li>
<li>No.Â The 95% interval attempts to captures the uncertainty in the <strong>mean</strong> of the distribution.</li>
<li>In the expression for the confidence interval, if we replaced the standard error by the standard deviation, we would get the desired reference limits</li>
</ul>
</div>
<div id="standard-error-vs-standard-deviation" class="section level3 hasAnchor" number="3.3.11">
<h3><span class="header-section-number">3.3.11</span> Standard error vs Standard deviation<a href="lecture-3-central-limit-theorem-and-inference-for-means.html#standard-error-vs-standard-deviation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><em>Suppose a similar study is to be conducted the following year among 200 women. What would you predict would be</em>
<ul>
<li><em>the SD of the new measurements?</em></li>
<li><em>the SE of the new measurements?</em></li>
</ul></li>
<li>Our best prediction for the SD would be the value in the smaller sample of 84, namely 0.42 mEq/l</li>
<li>However, the SE of the new measurements would decrease from 0.05 to <span class="math inline">\(\frac{0.42}{\sqrt {200}}\)</span> = 0.03 mEq/l</li>
</ul>
</div>
</div>
<div id="confidence-interval-for-the-difference-between-two-means" class="section level2 hasAnchor" number="3.4">
<h2><span class="header-section-number">3.4</span> Confidence interval for the difference between two means<a href="lecture-3-central-limit-theorem-and-inference-for-means.html#confidence-interval-for-the-difference-between-two-means" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="example-2-nck1-deficiency-and-adipogenesis" class="section level3 hasAnchor" number="3.4.1">
<h3><span class="header-section-number">3.4.1</span> Example 2: Nck1 deficiency and adipogenesis<a href="lecture-3-central-limit-theorem-and-inference-for-means.html#example-2-nck1-deficiency-and-adipogenesis" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><img src="3_53.png" width="50%" /></p>
<ul>
<li>Obesity results from an excessive expansion of white adipose tissue (WAT), which is still poorly understood from an etiologic-mechanistic perspective</li>
<li>A study from the MUHC-RI reported on the role of the Nck1 adaptor protein during WAT expansion and in vitro adipogenesis</li>
<li>Two outcomes of interest were body weight and adipose weight</li>
</ul>
<p><img src="3_54.png" width="50%" /></p>
<ul>
<li>Nck1 wild type (Nck1+/+) and knock-out mice (Nck1-/-) were compared at baseline and at 16 weeks</li>
<li>Two research questions of interest: Is there a difference in wild-type and knock-out mice in terms of
<ul>
<li>Body weight</li>
<li>Adipose weight</li>
</ul></li>
<li>What would be considered a meaningful change on these two outcomes?</li>
<li>In order to apply the Central Limit Theorem we would ask:
<ul>
<li>Is it reasonable to assume that body weight and adipose weight follow an approximately normal distribution?</li>
<li>If not, is the sample size sufficiently large?</li>
</ul></li>
<li>The sample size is not large, so the approximate normality must hold to construct a t-distribution-based confidence interval</li>
</ul>
<p><img src="3_55.png" width="100%" /></p>
</div>
<div id="confidence-interval-for-the-difference-between-means-from-two-independent-samples" class="section level3 hasAnchor" number="3.4.2">
<h3><span class="header-section-number">3.4.2</span> Confidence interval for the difference between means from two independent samples<a href="lecture-3-central-limit-theorem-and-inference-for-means.html#confidence-interval-for-the-difference-between-means-from-two-independent-samples" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The (1-Î±)% confidence interval comparing two means from independent samples is given by</p>
<p><span class="math display">\[\bar x_1-\bar x_2-t_{(1-\alpha/2),df}s_{diff},\bar x_1-\bar x_2+t_{(1-\alpha/2),df}s_{diff}\]</span></p>
<p>where</p>
<p><img src="3_56.png" width="50%" /></p>
</div>
<div id="variance-of-the-difference-in-means" class="section level3 hasAnchor" number="3.4.3">
<h3><span class="header-section-number">3.4.3</span> Variance of the difference in means<a href="lecture-3-central-limit-theorem-and-inference-for-means.html#variance-of-the-difference-in-means" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><img src="3_57.png" width="50%" /></p>
</div>
<div id="calculating-degrees-of-freedom-of-the-t-distribution-when-variances-are-not-equal" class="section level3 hasAnchor" number="3.4.4">
<h3><span class="header-section-number">3.4.4</span> Calculating degrees of freedom of the t-distribution when variances are not equal<a href="lecture-3-central-limit-theorem-and-inference-for-means.html#calculating-degrees-of-freedom-of-the-t-distribution-when-variances-are-not-equal" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>The degrees of freedom can be set to min(n1-1, n2-1), which is a conservative value. This is a useful approach if you are doing the t-test by hand</li>
<li>Alternatively, a computer program may use a more complex method called the Welchâs method or Satterthwaiteâs method to calculate the degrees of freedom as follows:</li>
</ul>
<p><span class="math display">\[\frac{(se_1^2+se_2^2)^2}{\frac{se_1^4}{n1-1}+\frac{se_2^4}{n2-1}},\]</span></p>
<p>where <span class="math inline">\(se_1 = se_1/\sqrt{n1}\)</span> and <span class="math inline">\(se_2 = se_2/\sqrt{n1}\)</span></p>
</div>
<div id="example-2-nck1-deficiency-and-adipogenesis-1" class="section level3 hasAnchor" number="3.4.5">
<h3><span class="header-section-number">3.4.5</span> Example 2: Nck1 deficiency and adipogenesis<a href="lecture-3-central-limit-theorem-and-inference-for-means.html#example-2-nck1-deficiency-and-adipogenesis-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>Based on the sample estimates, and perhaps from information gathered previously, it may be reasonable to assume that the variance is the same in both groups being compared</li>
<li>Since we are assuming that the variance is the same, it is reasonable to calculate a pooled variance that averages across both groups.</li>
</ul>
</div>
<div id="calculating-the-pooled-variance-for-body-weight" class="section level3 hasAnchor" number="3.4.6">
<h3><span class="header-section-number">3.4.6</span> Calculating the pooled variance for body weight<a href="lecture-3-central-limit-theorem-and-inference-for-means.html#calculating-the-pooled-variance-for-body-weight" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>The pooled variance is given by</li>
</ul>
<p><span class="math display">\[s_p^2=\frac{(n1-1)s_1^2+(n2-1)s_2^2}{n1+n2-2}=\frac{15*5.4*5.4+8*5.6*5.6}{16+9-2}=29.9\]</span></p>
<ul>
<li>Therefore the pooled standard deviation is given by the square root of 29.9 or <span class="math inline">\(s_p=5.5\)</span></li>
<li>The value of <span class="math inline">\(s_{diff}=s_p\sqrt{\frac{1}{n1}+\frac{1}{n2}}=5.5\sqrt{\frac{1}{16}+\frac{1}{9}}=2.3\)</span></li>
</ul>
</div>
<div id="confidence-interval-for-difference-in-body-weight" class="section level3 hasAnchor" number="3.4.7">
<h3><span class="header-section-number">3.4.7</span> Confidence interval for difference in body weight<a href="lecture-3-central-limit-theorem-and-inference-for-means.html#confidence-interval-for-difference-in-body-weight" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>The difference in mean body weight between Nck1+/+ and Nck1-/- mice is <span class="math inline">\(\bar y_1-\bar y_2=38.2-35.7=2.5\)</span></li>
<li>95% confidence interval for the difference in means is</li>
</ul>
<p><span class="math inline">\(\bar y_1-\bar y_2-t_{(1-\alpha/2),n1+n2-2}s_{diff},\bar y_1-\bar y_2+t_{(1-\alpha/2),n1+n2-2}s_{diff}\)</span></p>
<p>= (2.5 â 2.07 Ã 2.3, 2.5 + 2.07 Ã 2.3)</p>
<p>= (-2.3, 7.3)</p>
</div>
<div id="confidence-intervals-comparing-the-two-groups" class="section level3 hasAnchor" number="3.4.8">
<h3><span class="header-section-number">3.4.8</span> Confidence intervals comparing the two groups<a href="lecture-3-central-limit-theorem-and-inference-for-means.html#confidence-intervals-comparing-the-two-groups" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><img src="3_62.png" width="100%" /></p>
<ul>
<li>The assumption of unequal variance results in a lower value for the degrees of freedom and would typically be more conservative</li>
</ul>
</div>
<div id="interpreting-the-confidence-interval-1" class="section level3 hasAnchor" number="3.4.9">
<h3><span class="header-section-number">3.4.9</span> Interpreting the confidence interval<a href="lecture-3-central-limit-theorem-and-inference-for-means.html#interpreting-the-confidence-interval-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>As in the case of a single mean, we have 95% confidence in the procedure used to construct the interval.
<ul>
<li>We cannot say if this interval based on our sample includes the true mean difference between Nck1 +/+ and Nck1 -/- mice</li>
</ul></li>
<li>Say we consider 5g to be a meaningful difference in body weight
<ul>
<li>This implies, though the confidence interval includes 0, the upper limit crosses 5g suggesting we cannot eliminate the possibility there is a meaningful difference. Ideally, the study should be repeated to obtain a more precise estimate</li>
</ul></li>
<li>Say we consider a 0.5g to be a clinically meaningful difference in adipose weight
<ul>
<li>The interval provides evidence for a statistically significant difference, but does eliminate the possibility that the difference may not be clinically meaningful difference as the lower limit lies below 0.5g</li>
</ul></li>
</ul>
</div>
</div>
<div id="sample-size-calculations" class="section level2 hasAnchor" number="3.5">
<h2><span class="header-section-number">3.5</span> Sample size calculations<a href="lecture-3-central-limit-theorem-and-inference-for-means.html#sample-size-calculations" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ul>
<li>Before collecting data for a research study, it is wise to consider in advance whether the estimates generated from the data will be sufficiently precise.</li>
<li>It can be painful indeed to discover after a long and expensive study that the standard errors are so large that the primary questions addressed by the study cannot be answered.</li>
</ul>
<div id="an-illustration" class="section level3 hasAnchor" number="3.5.1">
<h3><span class="header-section-number">3.5.1</span> An illustration<a href="lecture-3-central-limit-theorem-and-inference-for-means.html#an-illustration" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><img src="3_66.png" width="50%" /></p>
<ul>
<li><a href="https://www.youtube.com/watch?v=PbODigCZqL8" class="uri">https://www.youtube.com/watch?v=PbODigCZqL8</a></li>
</ul>
</div>
<div id="sample-size-calculation" class="section level3 hasAnchor" number="3.5.2">
<h3><span class="header-section-number">3.5.2</span> Sample size calculation<a href="lecture-3-central-limit-theorem-and-inference-for-means.html#sample-size-calculation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>The method one uses for the sample size calculation depends on the plan for the statistical inference</li>
<li>Accordingly, depending on whether you intend to report a hypothesis test, or a confidence interval or a Bayesian analysis, your method for sample size calculation may change</li>
</ul>
</div>
<div id="sample-size-calculation-for-reporting-a-confidence-interval" class="section level3 hasAnchor" number="3.5.3">
<h3><span class="header-section-number">3.5.3</span> Sample size calculation for reporting a confidence interval<a href="lecture-3-central-limit-theorem-and-inference-for-means.html#sample-size-calculation-for-reporting-a-confidence-interval" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>This approach is relevant when we want to estimate a parameter within a certain precision, with a high level of confidence.</li>
<li>For example, we might want to estimate
<ul>
<li>mean change in body weight in mice within Â± 2.5g of the true value with 99% confidence</li>
<li>mean serum cholesterol in middle-aged men within Â± 6mg/dL of its true value with 90% confidence</li>
</ul></li>
</ul>
</div>
<div id="example-method-for-a-single-mean" class="section level3 hasAnchor" number="3.5.4">
<h3><span class="header-section-number">3.5.4</span> Example: Method for a single mean<a href="lecture-3-central-limit-theorem-and-inference-for-means.html#example-method-for-a-single-mean" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>A medical researcher proposes to estimate the mean serum cholesterol level of a certain population of middle-aged men, based on a random sample of the population.</li>
<li>He asks a statistician for advice. The ensuing discussion reveals that the researcher wants to estimate the population mean to within Î´ = Â±6 mg/dl or less, with 95% confidence.</li>
<li>Also, the researcher believes that the standard deviation of serum cholesterol in the population is probably about s=40 mg/dl.</li>
<li>How large a sample does the researcher need to take?</li>
</ul>
</div>
<div id="the-desired-precision-is-much-smaller-than-the-standard-deviation-of-the-variable" class="section level3 hasAnchor" number="3.5.5">
<h3><span class="header-section-number">3.5.5</span> The desired precision is much smaller than the standard deviation of the variable<a href="lecture-3-central-limit-theorem-and-inference-for-means.html#the-desired-precision-is-much-smaller-than-the-standard-deviation-of-the-variable" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><img src="3_70.png" width="50%" /></p>
</div>
<div id="example-method-for-a-single-mean-1" class="section level3 hasAnchor" number="3.5.6">
<h3><span class="header-section-number">3.5.6</span> Example: Method for a single mean<a href="lecture-3-central-limit-theorem-and-inference-for-means.html#example-method-for-a-single-mean-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>The research question can be re-expressed as</li>
</ul>
<p>âWhat is the sample size required to calculate a 95% confidence interval for the mean serum cholesterol which has half-width 6mg / dL?â</p>
<ul>
<li>Recall that the general expression for the (1- Î±)% confidence interval is</li>
</ul>
<p><span class="math display">\[\bar x-t_{(1-\alpha/2),n-1}\frac{s}{\sqrt n},\bar x+t_{(1-\alpha/2),n-1}\frac{s}{\sqrt n}\]</span></p>
<ul>
<li>In other words, we need to find out how large n should be so that</li>
</ul>
<p><span class="math display">\[t_{(1-\alpha/2),n-1}\frac{s}{\sqrt n}=\delta=6\]</span></p>
<ul>
<li>To solve this expression for n, we need to know the values of <span class="math inline">\(t_{(1-\alpha/2),n-1}\)</span> and the value of s, the standard deviation</li>
<li>Since <span class="math inline">\(t_{(1-\alpha/2),n-1}\)</span> itself depends on n, we cannot know its value without n! We therefore, replace it by the normal quantile <span class="math inline">\(Z_{(1-\alpha/2)}\)</span>. In our example, <span class="math inline">\(Z_{(1-\alpha/2)}=1.96\)</span></li>
<li>The value of s could be a guess value or determined from the literature or an earlier pilot study. In our example, s=40</li>
<li>Therefore, we wish to solve</li>
</ul>
<p><span class="math display">\[Z_{(1-\alpha/2)}\frac{s}{\sqrt n}=1.96\frac{40}{\sqrt n}=\delta=6\]</span></p>
<ul>
<li>This implies <span class="math inline">\(\sqrt n = Z_{(1-\alpha/2)}\frac{s}{\delta}=1.96\frac{40}{6}\)</span></li>
<li>Or <span class="math inline">\(n = (1.96\frac{40}{6})^2 \approx 171\)</span></li>
</ul>
</div>
<div id="alternative-values-of-Î±-s-and-Î´" class="section level3 hasAnchor" number="3.5.7">
<h3><span class="header-section-number">3.5.7</span> Alternative values of Î±, s and Î´<a href="lecture-3-central-limit-theorem-and-inference-for-means.html#alternative-values-of-Î±-s-and-Î´" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<table>
<thead>
<tr>
<th style="text-align:right;">
alpha
</th>
<th style="text-align:right;">
s
</th>
<th style="text-align:right;">
delta
</th>
<th style="text-align:right;">
n
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
0.05
</td>
<td style="text-align:right;">
40
</td>
<td style="text-align:right;">
6
</td>
<td style="text-align:right;">
171
</td>
</tr>
<tr>
<td style="text-align:right;">
0.01
</td>
<td style="text-align:right;">
40
</td>
<td style="text-align:right;">
6
</td>
<td style="text-align:right;">
240
</td>
</tr>
<tr>
<td style="text-align:right;">
0.05
</td>
<td style="text-align:right;">
30
</td>
<td style="text-align:right;">
6
</td>
<td style="text-align:right;">
96
</td>
</tr>
<tr>
<td style="text-align:right;">
0.01
</td>
<td style="text-align:right;">
30
</td>
<td style="text-align:right;">
6
</td>
<td style="text-align:right;">
135
</td>
</tr>
<tr>
<td style="text-align:right;">
0.05
</td>
<td style="text-align:right;">
40
</td>
<td style="text-align:right;">
12
</td>
<td style="text-align:right;">
43
</td>
</tr>
<tr>
<td style="text-align:right;">
0.01
</td>
<td style="text-align:right;">
40
</td>
<td style="text-align:right;">
12
</td>
<td style="text-align:right;">
60
</td>
</tr>
<tr>
<td style="text-align:right;">
0.05
</td>
<td style="text-align:right;">
30
</td>
<td style="text-align:right;">
12
</td>
<td style="text-align:right;">
24
</td>
</tr>
<tr>
<td style="text-align:right;">
0.01
</td>
<td style="text-align:right;">
30
</td>
<td style="text-align:right;">
12
</td>
<td style="text-align:right;">
24
</td>
</tr>
</tbody>
</table>
<ul>
<li>By varying the values of Î±, s and Î´ we can see how they impact the sample size</li>
<li>n increases if:<br />
Î± decreases, s increases or Î´ decreases<br />
</li>
<li>In practice, the sample size may be constrained by feasibility or cost. Using a table like this allows us to see how much precision we can âbuyâ with the available sample size</li>
</ul>
</div>
<div id="example-sample-size-calculation-for-comparing-two-means" class="section level3 hasAnchor" number="3.5.8">
<h3><span class="header-section-number">3.5.8</span> Example: Sample size calculation for comparing two means<a href="lecture-3-central-limit-theorem-and-inference-for-means.html#example-sample-size-calculation-for-comparing-two-means" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>Consider the study on body weight in Nck+/+ vs Nck-/- mice</li>
<li>Lets say we wish to repeat the earlier study so that we can show more convincingly that there is a clinically meaningful difference</li>
<li>Earlier in the lecture we found that the <strong>pooled</strong> standard deviation of the difference was <span class="math inline">\(s_p=5.5g\)</span></li>
<li>We desire to ensure that the observed mean change lies within Î´ = Â± 2.5 g of the true mean change with 95% confidence.</li>
<li>What is the sample size required in each group (assuming the sample size is equal in both groups)?</li>
</ul>
</div>
<div id="example-comparison-of-two-means" class="section level3 hasAnchor" number="3.5.9">
<h3><span class="header-section-number">3.5.9</span> Example: Comparison of two means<a href="lecture-3-central-limit-theorem-and-inference-for-means.html#example-comparison-of-two-means" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>To calculate the sample size required to estimate a 95% CI with adequate precision we need to solve<br />
<span class="math inline">\(Z_{(1-\alpha/2)}s_{diff}=Z_{(1-\alpha/2)}s_p\sqrt{\frac{1}{n}+\frac{1}{n}}=\delta\)</span><br />
or <span class="math inline">\(1.96\times 5.5\times \sqrt{\frac{1}{n}+\frac{1}{n}}=2.5\)</span></li>
<li>This implies <span class="math inline">\(\sqrt n =1.96\frac{5.5\times\sqrt 2}{2.5}\)</span></li>
<li>Or <span class="math inline">\(n = 2(1.96\frac{5.5}{2.5})^2 \approx 37\)</span> mice in each group</li>
</ul>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="lecture-2-types-of-variables-probability-and-probability-distributions.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="lecture-4-inference-for-means-continued.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/USERNAME/REPO/edit/BRANCH/Lecture_3.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["_main.pdf", "_main.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
